{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19101,"status":"ok","timestamp":1745002351136,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"BOlAMw9uJGeC","outputId":"ef4aa265-cb13-4c3e-fbe2-34182b5cbe6d"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbGhbM4-JWWS"},"outputs":[],"source":["%cp -r drive/MyDrive/ALBEF/* ."]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Entc5pcg46dn","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745003700924,"user_tz":360,"elapsed":60,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"}},"outputId":"c7d71142-de0c-45f3-9f7a-7749af23437b"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content/data\n"]}],"source":["%cd /content/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmHBrOd99IpD"},"outputs":[],"source":["!unzip -q train2014.zip & unzip -q test2015.zip & unzip -q val2014.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uABHbZCa9-PJ","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745003832821,"user_tz":360,"elapsed":74,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"}},"outputId":"1031233c-d382-4aaf-eb26-24d2f2ad96c2"},"outputs":[{"output_type":"stream","name":"stdout","text":["/content\n"]}],"source":["%cd /content"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"AzYHF4kTAIqc","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745003355165,"user_tz":360,"elapsed":10677,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"}},"outputId":"55be5cd9-7b65-4f23-8504-0b22f263effc"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting transformers==4.25.1\n","  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m8.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.32.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1)\n","  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.13.2)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2025.1.31)\n","Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m109.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m128.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.1\n","    Uninstalling tokenizers-0.21.1:\n","      Successfully uninstalled tokenizers-0.21.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.51.3\n","    Uninstalling transformers-4.51.3:\n","      Successfully uninstalled transformers-4.51.3\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.25.1\n"]}],"source":["!pip install transformers==4.25.1"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"HsSwP8RyCTX6","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745003358283,"user_tz":360,"elapsed":3117,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"}},"outputId":"c446888b-9f7d-4935-9211-d7388076b0a2"},"outputs":[{"output_type":"stream","name":"stdout","text":["Collecting ruamel.yaml==0.17.*\n","  Downloading ruamel.yaml-0.17.40-py3-none-any.whl.metadata (19 kB)\n","Collecting ruamel.yaml.clib>=0.2.7 (from ruamel.yaml==0.17.*)\n","  Downloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (2.7 kB)\n","Downloading ruamel.yaml-0.17.40-py3-none-any.whl (113 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m10.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading ruamel.yaml.clib-0.2.12-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (739 kB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m739.1/739.1 kB\u001b[0m \u001b[31m52.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ruamel.yaml.clib, ruamel.yaml\n","Successfully installed ruamel.yaml-0.17.40 ruamel.yaml.clib-0.2.12\n"]}],"source":["!pip install ruamel.yaml==0.17.*"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"U4aO73sdK9xE"},"outputs":[],"source":["import argparse\n","import os\n","import ruamel.yaml as yaml\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import json\n","from pathlib import Path\n","import subprocess\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torch.backends.cudnn as cudnn\n","import torch.distributed as dist\n","\n","from models.model_vqa import ALBEF\n","from models.vit import interpolate_pos_embed\n","from models.tokenization_bert import BertTokenizer\n","\n","import utils\n","from dataset.utils import save_result\n","from dataset import create_dataset, create_sampler, create_loader, vqa_collate_fn\n","\n","from scheduler import create_scheduler\n","from optim import create_optimizer"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"NJqXs_yTBK7C","colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"status":"ok","timestamp":1745003836130,"user_tz":360,"elapsed":77,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"}},"outputId":"d0cb9c1e-490d-485f-b580-fbbcd7ccc283"},"outputs":[{"output_type":"stream","name":"stdout","text":["The autoreload extension is already loaded. To reload it, use:\n","  %reload_ext autoreload\n"]}],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"3A3XLl-ALYDG"},"outputs":[],"source":["def train(model, data_loader, optimizer, tokenizer, epoch, warmup_steps, device, scheduler, config):\n","    # train\n","    model.train()\n","\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n","    metric_logger.add_meter('loss', utils.SmoothedValue(window_size=1, fmt='{value:.4f}'))\n","\n","    header = 'Train Epoch: [{}]'.format(epoch)\n","    print_freq = 50\n","    step_size = 100\n","    warmup_iterations = warmup_steps*step_size\n","\n","    for i,(image, question, answer, weights, n) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n","        image, weights = image.to(device,non_blocking=True), weights.to(device,non_blocking=True)\n","        question_input = tokenizer(question, padding='longest', truncation=True, max_length=25, return_tensors=\"pt\").to(device)\n","        answer_input = tokenizer(answer, padding='longest', return_tensors=\"pt\").to(device)\n","\n","        if epoch>0 or not config['warm_up']:\n","            alpha = config['alpha']\n","        else:\n","            alpha = config['alpha']*min(1,i/len(data_loader))\n","\n","        loss = model(image, question_input, answer_input, train=True, alpha=alpha, k=n, weights=weights)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        metric_logger.update(loss=loss.item())\n","        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n","\n","        if epoch==0 and i%step_size==0 and i<=warmup_iterations:\n","            scheduler.step(i//step_size)\n","\n","    # gather the stats from all processes\n","    metric_logger.synchronize_between_processes()\n","    print(\"Averaged stats:\", metric_logger.global_avg())\n","    return {k: \"{:.3f}\".format(meter.global_avg) for k, meter in metric_logger.meters.items()}"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"d5ug9dufNECg"},"outputs":[],"source":["@torch.no_grad()\n","def evaluation(model, data_loader, tokenizer, device, config) :\n","    # test\n","    model.eval()\n","\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    header = 'Generate VQA test result:'\n","    print_freq = 50\n","\n","    result = []\n","\n","    answer_list = [answer+config['eos'] for answer in data_loader.dataset.answer_list]\n","    answer_input = tokenizer(answer_list, padding='longest', return_tensors='pt').to(device)\n","\n","    for n, (image, question, question_id) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n","        image = image.to(device,non_blocking=True)\n","        question_input = tokenizer(question, padding='longest', return_tensors=\"pt\").to(device)\n","\n","        topk_ids, topk_probs = model(image, question_input, answer_input, train=False, k=config['k_test'])\n","\n","        for ques_id, topk_id, topk_prob in zip(question_id, topk_ids, topk_probs):\n","            ques_id = int(ques_id.item())\n","            _, pred = topk_prob.max(dim=0)\n","            result.append({\"question_id\":ques_id, \"answer\":data_loader.dataset.answer_list[topk_id[pred]]})\n","\n","    return result"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"WF3LfY8KNrb5"},"outputs":[],"source":["args = argparse.Namespace()\n","args.config = './configs/VQA.yaml'\n","args.checkpoint = './ALBEF_4M.pth'\n","args.output_dir = './output/vqa'\n","args.evaluate = False\n","args.text_encoder = 'bert-base-uncased'\n","args.text_decoder = 'bert-base-uncased'\n","args.device = 'cuda'\n","args.seed = 42\n","args.distributed = False\n","\n","config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"X6X0AQ1kQbMA"},"outputs":[],"source":["args.result_dir = os.path.join(args.output_dir, 'result')\n","\n","Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n","Path(args.result_dir).mkdir(parents=True, exist_ok=True)\n","\n","yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"t6hxLvhha5jF","colab":{"base_uri":"https://localhost:8080/","height":1000},"executionInfo":{"status":"error","timestamp":1745061224070,"user_tz":360,"elapsed":40131864,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"}},"outputId":"0121c0dd-0a24-4545-be4b-cfa69042bf4f"},"outputs":[{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Not using distributed mode\n","Creating vqa datasets\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/usr/local/lib/python3.11/dist-packages/huggingface_hub/file_download.py:896: FutureWarning: `resume_download` is deprecated and will be removed in version 1.0.0. Downloads always resume when possible. If you want to force a new download, use `force_download=True`.\n","  warnings.warn(\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Creating model\n","reshape position embedding from 256 to 576\n","reshape position embedding from 256 to 576\n","load checkpoint from ./ALBEF_4M.pth\n","_IncompatibleKeys(missing_keys=[], unexpected_keys=['temp', 'image_queue', 'text_queue', 'queue_ptr', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias', 'vision_proj_m.weight', 'vision_proj_m.bias', 'text_proj_m.weight', 'text_proj_m.bias', 'visual_encoder.blocks.6.norm1.weight', 'visual_encoder.blocks.6.norm1.bias', 'visual_encoder.blocks.6.attn.qkv.weight', 'visual_encoder.blocks.6.attn.qkv.bias', 'visual_encoder.blocks.6.attn.proj.weight', 'visual_encoder.blocks.6.attn.proj.bias', 'visual_encoder.blocks.6.norm2.weight', 'visual_encoder.blocks.6.norm2.bias', 'visual_encoder.blocks.6.mlp.fc1.weight', 'visual_encoder.blocks.6.mlp.fc1.bias', 'visual_encoder.blocks.6.mlp.fc2.weight', 'visual_encoder.blocks.6.mlp.fc2.bias', 'visual_encoder.blocks.7.norm1.weight', 'visual_encoder.blocks.7.norm1.bias', 'visual_encoder.blocks.7.attn.qkv.weight', 'visual_encoder.blocks.7.attn.qkv.bias', 'visual_encoder.blocks.7.attn.proj.weight', 'visual_encoder.blocks.7.attn.proj.bias', 'visual_encoder.blocks.7.norm2.weight', 'visual_encoder.blocks.7.norm2.bias', 'visual_encoder.blocks.7.mlp.fc1.weight', 'visual_encoder.blocks.7.mlp.fc1.bias', 'visual_encoder.blocks.7.mlp.fc2.weight', 'visual_encoder.blocks.7.mlp.fc2.bias', 'visual_encoder.blocks.8.norm1.weight', 'visual_encoder.blocks.8.norm1.bias', 'visual_encoder.blocks.8.attn.qkv.weight', 'visual_encoder.blocks.8.attn.qkv.bias', 'visual_encoder.blocks.8.attn.proj.weight', 'visual_encoder.blocks.8.attn.proj.bias', 'visual_encoder.blocks.8.norm2.weight', 'visual_encoder.blocks.8.norm2.bias', 'visual_encoder.blocks.8.mlp.fc1.weight', 'visual_encoder.blocks.8.mlp.fc1.bias', 'visual_encoder.blocks.8.mlp.fc2.weight', 'visual_encoder.blocks.8.mlp.fc2.bias', 'visual_encoder.blocks.9.norm1.weight', 'visual_encoder.blocks.9.norm1.bias', 'visual_encoder.blocks.9.attn.qkv.weight', 'visual_encoder.blocks.9.attn.qkv.bias', 'visual_encoder.blocks.9.attn.proj.weight', 'visual_encoder.blocks.9.attn.proj.bias', 'visual_encoder.blocks.9.norm2.weight', 'visual_encoder.blocks.9.norm2.bias', 'visual_encoder.blocks.9.mlp.fc1.weight', 'visual_encoder.blocks.9.mlp.fc1.bias', 'visual_encoder.blocks.9.mlp.fc2.weight', 'visual_encoder.blocks.9.mlp.fc2.bias', 'visual_encoder.blocks.10.norm1.weight', 'visual_encoder.blocks.10.norm1.bias', 'visual_encoder.blocks.10.attn.qkv.weight', 'visual_encoder.blocks.10.attn.qkv.bias', 'visual_encoder.blocks.10.attn.proj.weight', 'visual_encoder.blocks.10.attn.proj.bias', 'visual_encoder.blocks.10.norm2.weight', 'visual_encoder.blocks.10.norm2.bias', 'visual_encoder.blocks.10.mlp.fc1.weight', 'visual_encoder.blocks.10.mlp.fc1.bias', 'visual_encoder.blocks.10.mlp.fc2.weight', 'visual_encoder.blocks.10.mlp.fc2.bias', 'visual_encoder.blocks.11.norm1.weight', 'visual_encoder.blocks.11.norm1.bias', 'visual_encoder.blocks.11.attn.qkv.weight', 'visual_encoder.blocks.11.attn.qkv.bias', 'visual_encoder.blocks.11.attn.proj.weight', 'visual_encoder.blocks.11.attn.proj.bias', 'visual_encoder.blocks.11.norm2.weight', 'visual_encoder.blocks.11.norm2.bias', 'visual_encoder.blocks.11.mlp.fc1.weight', 'visual_encoder.blocks.11.mlp.fc1.bias', 'visual_encoder.blocks.11.mlp.fc2.weight', 'visual_encoder.blocks.11.mlp.fc2.bias', 'text_encoder.encoder.layer.3.attention.self.query.weight', 'text_encoder.encoder.layer.3.attention.self.query.bias', 'text_encoder.encoder.layer.3.attention.self.key.weight', 'text_encoder.encoder.layer.3.attention.self.key.bias', 'text_encoder.encoder.layer.3.attention.self.value.weight', 'text_encoder.encoder.layer.3.attention.self.value.bias', 'text_encoder.encoder.layer.3.attention.output.dense.weight', 'text_encoder.encoder.layer.3.attention.output.dense.bias', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.3.intermediate.dense.weight', 'text_encoder.encoder.layer.3.intermediate.dense.bias', 'text_encoder.encoder.layer.3.output.dense.weight', 'text_encoder.encoder.layer.3.output.dense.bias', 'text_encoder.encoder.layer.3.output.LayerNorm.weight', 'text_encoder.encoder.layer.3.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.attention.self.query.weight', 'text_encoder.encoder.layer.4.attention.self.query.bias', 'text_encoder.encoder.layer.4.attention.self.key.weight', 'text_encoder.encoder.layer.4.attention.self.key.bias', 'text_encoder.encoder.layer.4.attention.self.value.weight', 'text_encoder.encoder.layer.4.attention.self.value.bias', 'text_encoder.encoder.layer.4.attention.output.dense.weight', 'text_encoder.encoder.layer.4.attention.output.dense.bias', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.4.intermediate.dense.weight', 'text_encoder.encoder.layer.4.intermediate.dense.bias', 'text_encoder.encoder.layer.4.output.dense.weight', 'text_encoder.encoder.layer.4.output.dense.bias', 'text_encoder.encoder.layer.4.output.LayerNorm.weight', 'text_encoder.encoder.layer.4.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.attention.self.query.weight', 'text_encoder.encoder.layer.5.attention.self.query.bias', 'text_encoder.encoder.layer.5.attention.self.key.weight', 'text_encoder.encoder.layer.5.attention.self.key.bias', 'text_encoder.encoder.layer.5.attention.self.value.weight', 'text_encoder.encoder.layer.5.attention.self.value.bias', 'text_encoder.encoder.layer.5.attention.output.dense.weight', 'text_encoder.encoder.layer.5.attention.output.dense.bias', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.5.intermediate.dense.weight', 'text_encoder.encoder.layer.5.intermediate.dense.bias', 'text_encoder.encoder.layer.5.output.dense.weight', 'text_encoder.encoder.layer.5.output.dense.bias', 'text_encoder.encoder.layer.5.output.LayerNorm.weight', 'text_encoder.encoder.layer.5.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.attention.self.query.weight', 'text_encoder.encoder.layer.6.attention.self.query.bias', 'text_encoder.encoder.layer.6.attention.self.key.weight', 'text_encoder.encoder.layer.6.attention.self.key.bias', 'text_encoder.encoder.layer.6.attention.self.value.weight', 'text_encoder.encoder.layer.6.attention.self.value.bias', 'text_encoder.encoder.layer.6.attention.output.dense.weight', 'text_encoder.encoder.layer.6.attention.output.dense.bias', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.crossattention.self.query.weight', 'text_encoder.encoder.layer.6.crossattention.self.query.bias', 'text_encoder.encoder.layer.6.crossattention.self.key.weight', 'text_encoder.encoder.layer.6.crossattention.self.key.bias', 'text_encoder.encoder.layer.6.crossattention.self.value.weight', 'text_encoder.encoder.layer.6.crossattention.self.value.bias', 'text_encoder.encoder.layer.6.crossattention.output.dense.weight', 'text_encoder.encoder.layer.6.crossattention.output.dense.bias', 'text_encoder.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.6.intermediate.dense.weight', 'text_encoder.encoder.layer.6.intermediate.dense.bias', 'text_encoder.encoder.layer.6.output.dense.weight', 'text_encoder.encoder.layer.6.output.dense.bias', 'text_encoder.encoder.layer.6.output.LayerNorm.weight', 'text_encoder.encoder.layer.6.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.attention.self.query.weight', 'text_encoder.encoder.layer.7.attention.self.query.bias', 'text_encoder.encoder.layer.7.attention.self.key.weight', 'text_encoder.encoder.layer.7.attention.self.key.bias', 'text_encoder.encoder.layer.7.attention.self.value.weight', 'text_encoder.encoder.layer.7.attention.self.value.bias', 'text_encoder.encoder.layer.7.attention.output.dense.weight', 'text_encoder.encoder.layer.7.attention.output.dense.bias', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.crossattention.self.query.weight', 'text_encoder.encoder.layer.7.crossattention.self.query.bias', 'text_encoder.encoder.layer.7.crossattention.self.key.weight', 'text_encoder.encoder.layer.7.crossattention.self.key.bias', 'text_encoder.encoder.layer.7.crossattention.self.value.weight', 'text_encoder.encoder.layer.7.crossattention.self.value.bias', 'text_encoder.encoder.layer.7.crossattention.output.dense.weight', 'text_encoder.encoder.layer.7.crossattention.output.dense.bias', 'text_encoder.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.7.intermediate.dense.weight', 'text_encoder.encoder.layer.7.intermediate.dense.bias', 'text_encoder.encoder.layer.7.output.dense.weight', 'text_encoder.encoder.layer.7.output.dense.bias', 'text_encoder.encoder.layer.7.output.LayerNorm.weight', 'text_encoder.encoder.layer.7.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.attention.self.query.weight', 'text_encoder.encoder.layer.8.attention.self.query.bias', 'text_encoder.encoder.layer.8.attention.self.key.weight', 'text_encoder.encoder.layer.8.attention.self.key.bias', 'text_encoder.encoder.layer.8.attention.self.value.weight', 'text_encoder.encoder.layer.8.attention.self.value.bias', 'text_encoder.encoder.layer.8.attention.output.dense.weight', 'text_encoder.encoder.layer.8.attention.output.dense.bias', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.crossattention.self.query.weight', 'text_encoder.encoder.layer.8.crossattention.self.query.bias', 'text_encoder.encoder.layer.8.crossattention.self.key.weight', 'text_encoder.encoder.layer.8.crossattention.self.key.bias', 'text_encoder.encoder.layer.8.crossattention.self.value.weight', 'text_encoder.encoder.layer.8.crossattention.self.value.bias', 'text_encoder.encoder.layer.8.crossattention.output.dense.weight', 'text_encoder.encoder.layer.8.crossattention.output.dense.bias', 'text_encoder.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.8.intermediate.dense.weight', 'text_encoder.encoder.layer.8.intermediate.dense.bias', 'text_encoder.encoder.layer.8.output.dense.weight', 'text_encoder.encoder.layer.8.output.dense.bias', 'text_encoder.encoder.layer.8.output.LayerNorm.weight', 'text_encoder.encoder.layer.8.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.attention.self.query.weight', 'text_encoder.encoder.layer.9.attention.self.query.bias', 'text_encoder.encoder.layer.9.attention.self.key.weight', 'text_encoder.encoder.layer.9.attention.self.key.bias', 'text_encoder.encoder.layer.9.attention.self.value.weight', 'text_encoder.encoder.layer.9.attention.self.value.bias', 'text_encoder.encoder.layer.9.attention.output.dense.weight', 'text_encoder.encoder.layer.9.attention.output.dense.bias', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.crossattention.self.query.weight', 'text_encoder.encoder.layer.9.crossattention.self.query.bias', 'text_encoder.encoder.layer.9.crossattention.self.key.weight', 'text_encoder.encoder.layer.9.crossattention.self.key.bias', 'text_encoder.encoder.layer.9.crossattention.self.value.weight', 'text_encoder.encoder.layer.9.crossattention.self.value.bias', 'text_encoder.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.9.intermediate.dense.weight', 'text_encoder.encoder.layer.9.intermediate.dense.bias', 'text_encoder.encoder.layer.9.output.dense.weight', 'text_encoder.encoder.layer.9.output.dense.bias', 'text_encoder.encoder.layer.9.output.LayerNorm.weight', 'text_encoder.encoder.layer.9.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.attention.self.query.weight', 'text_encoder.encoder.layer.10.attention.self.query.bias', 'text_encoder.encoder.layer.10.attention.self.key.weight', 'text_encoder.encoder.layer.10.attention.self.key.bias', 'text_encoder.encoder.layer.10.attention.self.value.weight', 'text_encoder.encoder.layer.10.attention.self.value.bias', 'text_encoder.encoder.layer.10.attention.output.dense.weight', 'text_encoder.encoder.layer.10.attention.output.dense.bias', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.crossattention.self.query.weight', 'text_encoder.encoder.layer.10.crossattention.self.query.bias', 'text_encoder.encoder.layer.10.crossattention.self.key.weight', 'text_encoder.encoder.layer.10.crossattention.self.key.bias', 'text_encoder.encoder.layer.10.crossattention.self.value.weight', 'text_encoder.encoder.layer.10.crossattention.self.value.bias', 'text_encoder.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.10.intermediate.dense.weight', 'text_encoder.encoder.layer.10.intermediate.dense.bias', 'text_encoder.encoder.layer.10.output.dense.weight', 'text_encoder.encoder.layer.10.output.dense.bias', 'text_encoder.encoder.layer.10.output.LayerNorm.weight', 'text_encoder.encoder.layer.10.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.attention.self.query.weight', 'text_encoder.encoder.layer.11.attention.self.query.bias', 'text_encoder.encoder.layer.11.attention.self.key.weight', 'text_encoder.encoder.layer.11.attention.self.key.bias', 'text_encoder.encoder.layer.11.attention.self.value.weight', 'text_encoder.encoder.layer.11.attention.self.value.bias', 'text_encoder.encoder.layer.11.attention.output.dense.weight', 'text_encoder.encoder.layer.11.attention.output.dense.bias', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.crossattention.self.query.weight', 'text_encoder.encoder.layer.11.crossattention.self.query.bias', 'text_encoder.encoder.layer.11.crossattention.self.key.weight', 'text_encoder.encoder.layer.11.crossattention.self.key.bias', 'text_encoder.encoder.layer.11.crossattention.self.value.weight', 'text_encoder.encoder.layer.11.crossattention.self.value.bias', 'text_encoder.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder.encoder.layer.11.intermediate.dense.weight', 'text_encoder.encoder.layer.11.intermediate.dense.bias', 'text_encoder.encoder.layer.11.output.dense.weight', 'text_encoder.encoder.layer.11.output.dense.bias', 'text_encoder.encoder.layer.11.output.LayerNorm.weight', 'text_encoder.encoder.layer.11.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.3.attention.self.query.weight', 'text_decoder.bert.encoder.layer.3.attention.self.query.bias', 'text_decoder.bert.encoder.layer.3.attention.self.key.weight', 'text_decoder.bert.encoder.layer.3.attention.self.key.bias', 'text_decoder.bert.encoder.layer.3.attention.self.value.weight', 'text_decoder.bert.encoder.layer.3.attention.self.value.bias', 'text_decoder.bert.encoder.layer.3.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.3.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.3.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.3.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.3.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.3.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.3.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.3.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.3.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.3.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.3.output.dense.weight', 'text_decoder.bert.encoder.layer.3.output.dense.bias', 'text_decoder.bert.encoder.layer.3.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.3.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.4.attention.self.query.weight', 'text_decoder.bert.encoder.layer.4.attention.self.query.bias', 'text_decoder.bert.encoder.layer.4.attention.self.key.weight', 'text_decoder.bert.encoder.layer.4.attention.self.key.bias', 'text_decoder.bert.encoder.layer.4.attention.self.value.weight', 'text_decoder.bert.encoder.layer.4.attention.self.value.bias', 'text_decoder.bert.encoder.layer.4.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.4.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.4.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.4.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.4.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.4.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.4.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.4.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.4.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.4.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.4.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.4.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.4.output.dense.weight', 'text_decoder.bert.encoder.layer.4.output.dense.bias', 'text_decoder.bert.encoder.layer.4.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.4.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.5.attention.self.query.weight', 'text_decoder.bert.encoder.layer.5.attention.self.query.bias', 'text_decoder.bert.encoder.layer.5.attention.self.key.weight', 'text_decoder.bert.encoder.layer.5.attention.self.key.bias', 'text_decoder.bert.encoder.layer.5.attention.self.value.weight', 'text_decoder.bert.encoder.layer.5.attention.self.value.bias', 'text_decoder.bert.encoder.layer.5.attention.output.dense.weight', 'text_decoder.bert.encoder.layer.5.attention.output.dense.bias', 'text_decoder.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.5.crossattention.self.query.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.query.bias', 'text_decoder.bert.encoder.layer.5.crossattention.self.key.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.key.bias', 'text_decoder.bert.encoder.layer.5.crossattention.self.value.weight', 'text_decoder.bert.encoder.layer.5.crossattention.self.value.bias', 'text_decoder.bert.encoder.layer.5.crossattention.output.dense.weight', 'text_decoder.bert.encoder.layer.5.crossattention.output.dense.bias', 'text_decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'text_decoder.bert.encoder.layer.5.intermediate.dense.weight', 'text_decoder.bert.encoder.layer.5.intermediate.dense.bias', 'text_decoder.bert.encoder.layer.5.output.dense.weight', 'text_decoder.bert.encoder.layer.5.output.dense.bias', 'text_decoder.bert.encoder.layer.5.output.LayerNorm.weight', 'text_decoder.bert.encoder.layer.5.output.LayerNorm.bias', 'visual_encoder_m.blocks.6.norm1.weight', 'visual_encoder_m.blocks.6.norm1.bias', 'visual_encoder_m.blocks.6.attn.qkv.weight', 'visual_encoder_m.blocks.6.attn.qkv.bias', 'visual_encoder_m.blocks.6.attn.proj.weight', 'visual_encoder_m.blocks.6.attn.proj.bias', 'visual_encoder_m.blocks.6.norm2.weight', 'visual_encoder_m.blocks.6.norm2.bias', 'visual_encoder_m.blocks.6.mlp.fc1.weight', 'visual_encoder_m.blocks.6.mlp.fc1.bias', 'visual_encoder_m.blocks.6.mlp.fc2.weight', 'visual_encoder_m.blocks.6.mlp.fc2.bias', 'visual_encoder_m.blocks.7.norm1.weight', 'visual_encoder_m.blocks.7.norm1.bias', 'visual_encoder_m.blocks.7.attn.qkv.weight', 'visual_encoder_m.blocks.7.attn.qkv.bias', 'visual_encoder_m.blocks.7.attn.proj.weight', 'visual_encoder_m.blocks.7.attn.proj.bias', 'visual_encoder_m.blocks.7.norm2.weight', 'visual_encoder_m.blocks.7.norm2.bias', 'visual_encoder_m.blocks.7.mlp.fc1.weight', 'visual_encoder_m.blocks.7.mlp.fc1.bias', 'visual_encoder_m.blocks.7.mlp.fc2.weight', 'visual_encoder_m.blocks.7.mlp.fc2.bias', 'visual_encoder_m.blocks.8.norm1.weight', 'visual_encoder_m.blocks.8.norm1.bias', 'visual_encoder_m.blocks.8.attn.qkv.weight', 'visual_encoder_m.blocks.8.attn.qkv.bias', 'visual_encoder_m.blocks.8.attn.proj.weight', 'visual_encoder_m.blocks.8.attn.proj.bias', 'visual_encoder_m.blocks.8.norm2.weight', 'visual_encoder_m.blocks.8.norm2.bias', 'visual_encoder_m.blocks.8.mlp.fc1.weight', 'visual_encoder_m.blocks.8.mlp.fc1.bias', 'visual_encoder_m.blocks.8.mlp.fc2.weight', 'visual_encoder_m.blocks.8.mlp.fc2.bias', 'visual_encoder_m.blocks.9.norm1.weight', 'visual_encoder_m.blocks.9.norm1.bias', 'visual_encoder_m.blocks.9.attn.qkv.weight', 'visual_encoder_m.blocks.9.attn.qkv.bias', 'visual_encoder_m.blocks.9.attn.proj.weight', 'visual_encoder_m.blocks.9.attn.proj.bias', 'visual_encoder_m.blocks.9.norm2.weight', 'visual_encoder_m.blocks.9.norm2.bias', 'visual_encoder_m.blocks.9.mlp.fc1.weight', 'visual_encoder_m.blocks.9.mlp.fc1.bias', 'visual_encoder_m.blocks.9.mlp.fc2.weight', 'visual_encoder_m.blocks.9.mlp.fc2.bias', 'visual_encoder_m.blocks.10.norm1.weight', 'visual_encoder_m.blocks.10.norm1.bias', 'visual_encoder_m.blocks.10.attn.qkv.weight', 'visual_encoder_m.blocks.10.attn.qkv.bias', 'visual_encoder_m.blocks.10.attn.proj.weight', 'visual_encoder_m.blocks.10.attn.proj.bias', 'visual_encoder_m.blocks.10.norm2.weight', 'visual_encoder_m.blocks.10.norm2.bias', 'visual_encoder_m.blocks.10.mlp.fc1.weight', 'visual_encoder_m.blocks.10.mlp.fc1.bias', 'visual_encoder_m.blocks.10.mlp.fc2.weight', 'visual_encoder_m.blocks.10.mlp.fc2.bias', 'visual_encoder_m.blocks.11.norm1.weight', 'visual_encoder_m.blocks.11.norm1.bias', 'visual_encoder_m.blocks.11.attn.qkv.weight', 'visual_encoder_m.blocks.11.attn.qkv.bias', 'visual_encoder_m.blocks.11.attn.proj.weight', 'visual_encoder_m.blocks.11.attn.proj.bias', 'visual_encoder_m.blocks.11.norm2.weight', 'visual_encoder_m.blocks.11.norm2.bias', 'visual_encoder_m.blocks.11.mlp.fc1.weight', 'visual_encoder_m.blocks.11.mlp.fc1.bias', 'visual_encoder_m.blocks.11.mlp.fc2.weight', 'visual_encoder_m.blocks.11.mlp.fc2.bias', 'text_encoder_m.encoder.layer.3.attention.self.query.weight', 'text_encoder_m.encoder.layer.3.attention.self.query.bias', 'text_encoder_m.encoder.layer.3.attention.self.key.weight', 'text_encoder_m.encoder.layer.3.attention.self.key.bias', 'text_encoder_m.encoder.layer.3.attention.self.value.weight', 'text_encoder_m.encoder.layer.3.attention.self.value.bias', 'text_encoder_m.encoder.layer.3.attention.output.dense.weight', 'text_encoder_m.encoder.layer.3.attention.output.dense.bias', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.3.intermediate.dense.weight', 'text_encoder_m.encoder.layer.3.intermediate.dense.bias', 'text_encoder_m.encoder.layer.3.output.dense.weight', 'text_encoder_m.encoder.layer.3.output.dense.bias', 'text_encoder_m.encoder.layer.3.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.3.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.attention.self.query.weight', 'text_encoder_m.encoder.layer.4.attention.self.query.bias', 'text_encoder_m.encoder.layer.4.attention.self.key.weight', 'text_encoder_m.encoder.layer.4.attention.self.key.bias', 'text_encoder_m.encoder.layer.4.attention.self.value.weight', 'text_encoder_m.encoder.layer.4.attention.self.value.bias', 'text_encoder_m.encoder.layer.4.attention.output.dense.weight', 'text_encoder_m.encoder.layer.4.attention.output.dense.bias', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.4.intermediate.dense.weight', 'text_encoder_m.encoder.layer.4.intermediate.dense.bias', 'text_encoder_m.encoder.layer.4.output.dense.weight', 'text_encoder_m.encoder.layer.4.output.dense.bias', 'text_encoder_m.encoder.layer.4.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.4.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.attention.self.query.weight', 'text_encoder_m.encoder.layer.5.attention.self.query.bias', 'text_encoder_m.encoder.layer.5.attention.self.key.weight', 'text_encoder_m.encoder.layer.5.attention.self.key.bias', 'text_encoder_m.encoder.layer.5.attention.self.value.weight', 'text_encoder_m.encoder.layer.5.attention.self.value.bias', 'text_encoder_m.encoder.layer.5.attention.output.dense.weight', 'text_encoder_m.encoder.layer.5.attention.output.dense.bias', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.5.intermediate.dense.weight', 'text_encoder_m.encoder.layer.5.intermediate.dense.bias', 'text_encoder_m.encoder.layer.5.output.dense.weight', 'text_encoder_m.encoder.layer.5.output.dense.bias', 'text_encoder_m.encoder.layer.5.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.5.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.attention.self.query.weight', 'text_encoder_m.encoder.layer.6.attention.self.query.bias', 'text_encoder_m.encoder.layer.6.attention.self.key.weight', 'text_encoder_m.encoder.layer.6.attention.self.key.bias', 'text_encoder_m.encoder.layer.6.attention.self.value.weight', 'text_encoder_m.encoder.layer.6.attention.self.value.bias', 'text_encoder_m.encoder.layer.6.attention.output.dense.weight', 'text_encoder_m.encoder.layer.6.attention.output.dense.bias', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.6.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.6.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.6.intermediate.dense.weight', 'text_encoder_m.encoder.layer.6.intermediate.dense.bias', 'text_encoder_m.encoder.layer.6.output.dense.weight', 'text_encoder_m.encoder.layer.6.output.dense.bias', 'text_encoder_m.encoder.layer.6.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.6.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.attention.self.query.weight', 'text_encoder_m.encoder.layer.7.attention.self.query.bias', 'text_encoder_m.encoder.layer.7.attention.self.key.weight', 'text_encoder_m.encoder.layer.7.attention.self.key.bias', 'text_encoder_m.encoder.layer.7.attention.self.value.weight', 'text_encoder_m.encoder.layer.7.attention.self.value.bias', 'text_encoder_m.encoder.layer.7.attention.output.dense.weight', 'text_encoder_m.encoder.layer.7.attention.output.dense.bias', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.7.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.7.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.7.intermediate.dense.weight', 'text_encoder_m.encoder.layer.7.intermediate.dense.bias', 'text_encoder_m.encoder.layer.7.output.dense.weight', 'text_encoder_m.encoder.layer.7.output.dense.bias', 'text_encoder_m.encoder.layer.7.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.7.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.attention.self.query.weight', 'text_encoder_m.encoder.layer.8.attention.self.query.bias', 'text_encoder_m.encoder.layer.8.attention.self.key.weight', 'text_encoder_m.encoder.layer.8.attention.self.key.bias', 'text_encoder_m.encoder.layer.8.attention.self.value.weight', 'text_encoder_m.encoder.layer.8.attention.self.value.bias', 'text_encoder_m.encoder.layer.8.attention.output.dense.weight', 'text_encoder_m.encoder.layer.8.attention.output.dense.bias', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.8.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.8.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.8.intermediate.dense.weight', 'text_encoder_m.encoder.layer.8.intermediate.dense.bias', 'text_encoder_m.encoder.layer.8.output.dense.weight', 'text_encoder_m.encoder.layer.8.output.dense.bias', 'text_encoder_m.encoder.layer.8.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.8.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.attention.self.query.weight', 'text_encoder_m.encoder.layer.9.attention.self.query.bias', 'text_encoder_m.encoder.layer.9.attention.self.key.weight', 'text_encoder_m.encoder.layer.9.attention.self.key.bias', 'text_encoder_m.encoder.layer.9.attention.self.value.weight', 'text_encoder_m.encoder.layer.9.attention.self.value.bias', 'text_encoder_m.encoder.layer.9.attention.output.dense.weight', 'text_encoder_m.encoder.layer.9.attention.output.dense.bias', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.9.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.9.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.9.intermediate.dense.weight', 'text_encoder_m.encoder.layer.9.intermediate.dense.bias', 'text_encoder_m.encoder.layer.9.output.dense.weight', 'text_encoder_m.encoder.layer.9.output.dense.bias', 'text_encoder_m.encoder.layer.9.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.9.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.attention.self.query.weight', 'text_encoder_m.encoder.layer.10.attention.self.query.bias', 'text_encoder_m.encoder.layer.10.attention.self.key.weight', 'text_encoder_m.encoder.layer.10.attention.self.key.bias', 'text_encoder_m.encoder.layer.10.attention.self.value.weight', 'text_encoder_m.encoder.layer.10.attention.self.value.bias', 'text_encoder_m.encoder.layer.10.attention.output.dense.weight', 'text_encoder_m.encoder.layer.10.attention.output.dense.bias', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.10.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.10.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.10.intermediate.dense.weight', 'text_encoder_m.encoder.layer.10.intermediate.dense.bias', 'text_encoder_m.encoder.layer.10.output.dense.weight', 'text_encoder_m.encoder.layer.10.output.dense.bias', 'text_encoder_m.encoder.layer.10.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.10.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.attention.self.query.weight', 'text_encoder_m.encoder.layer.11.attention.self.query.bias', 'text_encoder_m.encoder.layer.11.attention.self.key.weight', 'text_encoder_m.encoder.layer.11.attention.self.key.bias', 'text_encoder_m.encoder.layer.11.attention.self.value.weight', 'text_encoder_m.encoder.layer.11.attention.self.value.bias', 'text_encoder_m.encoder.layer.11.attention.output.dense.weight', 'text_encoder_m.encoder.layer.11.attention.output.dense.bias', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.attention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.query.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.query.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.key.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.key.bias', 'text_encoder_m.encoder.layer.11.crossattention.self.value.weight', 'text_encoder_m.encoder.layer.11.crossattention.self.value.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.dense.bias', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.crossattention.output.LayerNorm.bias', 'text_encoder_m.encoder.layer.11.intermediate.dense.weight', 'text_encoder_m.encoder.layer.11.intermediate.dense.bias', 'text_encoder_m.encoder.layer.11.output.dense.weight', 'text_encoder_m.encoder.layer.11.output.dense.bias', 'text_encoder_m.encoder.layer.11.output.LayerNorm.weight', 'text_encoder_m.encoder.layer.11.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.3.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.3.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.3.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.3.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.3.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.3.output.dense.weight', 'text_decoder_m.bert.encoder.layer.3.output.dense.bias', 'text_decoder_m.bert.encoder.layer.3.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.3.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.4.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.4.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.4.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.4.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.4.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.4.output.dense.weight', 'text_decoder_m.bert.encoder.layer.4.output.dense.bias', 'text_decoder_m.bert.encoder.layer.4.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.4.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.query.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.query.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.key.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.key.bias', 'text_decoder_m.bert.encoder.layer.5.attention.self.value.weight', 'text_decoder_m.bert.encoder.layer.5.attention.self.value.bias', 'text_decoder_m.bert.encoder.layer.5.attention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.attention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.attention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.attention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.query.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.query.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.key.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.key.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.value.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.self.value.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.crossattention.output.LayerNorm.bias', 'text_decoder_m.bert.encoder.layer.5.intermediate.dense.weight', 'text_decoder_m.bert.encoder.layer.5.intermediate.dense.bias', 'text_decoder_m.bert.encoder.layer.5.output.dense.weight', 'text_decoder_m.bert.encoder.layer.5.output.dense.bias', 'text_decoder_m.bert.encoder.layer.5.output.LayerNorm.weight', 'text_decoder_m.bert.encoder.layer.5.output.LayerNorm.bias'])\n","Start training\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Epoch: [0]  [    0/20565]  eta: 20:49:13  lr: 0.000010  loss: 31.4302  time: 3.6447  data: 1.3974  max mem: 11759\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Epoch: [0]  [   50/20565]  eta: 2:10:36  lr: 0.000010  loss: 9.2759  time: 0.3159  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  100/20565]  eta: 1:59:07  lr: 0.000010  loss: 6.5193  time: 0.3162  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  150/20565]  eta: 1:55:07  lr: 0.000013  loss: 5.2038  time: 0.3165  data: 0.0003  max mem: 13312\n","Train Epoch: [0]  [  200/20565]  eta: 1:52:58  lr: 0.000013  loss: 7.9894  time: 0.3157  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  250/20565]  eta: 1:51:41  lr: 0.000015  loss: 6.0901  time: 0.3173  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  300/20565]  eta: 1:50:40  lr: 0.000015  loss: 6.1345  time: 0.3159  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  350/20565]  eta: 1:49:48  lr: 0.000018  loss: 5.0508  time: 0.3151  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  400/20565]  eta: 1:49:05  lr: 0.000018  loss: 5.6330  time: 0.3164  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  450/20565]  eta: 1:48:30  lr: 0.000020  loss: 4.7485  time: 0.3167  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  500/20565]  eta: 1:49:51  lr: 0.000020  loss: 5.3719  time: 0.3158  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  550/20565]  eta: 1:49:13  lr: 0.000020  loss: 4.5599  time: 0.3158  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  600/20565]  eta: 1:48:43  lr: 0.000020  loss: 6.5774  time: 0.3223  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  650/20565]  eta: 1:48:11  lr: 0.000020  loss: 6.4295  time: 0.3152  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  700/20565]  eta: 1:47:40  lr: 0.000020  loss: 6.2110  time: 0.3172  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  750/20565]  eta: 1:47:12  lr: 0.000020  loss: 4.2212  time: 0.3183  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  800/20565]  eta: 1:46:45  lr: 0.000020  loss: 5.4240  time: 0.3166  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  850/20565]  eta: 1:46:21  lr: 0.000020  loss: 5.8609  time: 0.3181  data: 0.0002  max mem: 13312\n","Train Epoch: [0]  [  900/20565]  eta: 1:45:58  lr: 0.000020  loss: 5.4905  time: 0.3164  data: 0.0002  max mem: 13315\n","Train Epoch: [0]  [  950/20565]  eta: 1:45:35  lr: 0.000020  loss: 5.5592  time: 0.3146  data: 0.0002  max mem: 13315\n","Train Epoch: [0]  [ 1000/20565]  eta: 1:45:13  lr: 0.000020  loss: 4.0974  time: 0.3158  data: 0.0002  max mem: 13315\n","Train Epoch: [0]  [ 1050/20565]  eta: 1:44:49  lr: 0.000020  loss: 5.9314  time: 0.3170  data: 0.0002  max mem: 13315\n","Train Epoch: [0]  [ 1100/20565]  eta: 1:44:27  lr: 0.000020  loss: 4.6718  time: 0.3150  data: 0.0002  max mem: 13315\n","Train Epoch: [0]  [ 1150/20565]  eta: 1:44:07  lr: 0.000020  loss: 4.7653  time: 0.3155  data: 0.0002  max mem: 13551\n","Train Epoch: [0]  [ 1200/20565]  eta: 1:43:47  lr: 0.000020  loss: 5.1380  time: 0.3158  data: 0.0002  max mem: 13551\n","Train Epoch: [0]  [ 1250/20565]  eta: 1:43:27  lr: 0.000020  loss: 4.7262  time: 0.3172  data: 0.0002  max mem: 13551\n","Train Epoch: [0]  [ 1300/20565]  eta: 1:43:07  lr: 0.000020  loss: 5.6948  time: 0.3171  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1350/20565]  eta: 1:42:47  lr: 0.000020  loss: 3.1120  time: 0.3158  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1400/20565]  eta: 1:42:27  lr: 0.000020  loss: 4.4061  time: 0.3117  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1450/20565]  eta: 1:42:08  lr: 0.000020  loss: 3.6114  time: 0.3192  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1500/20565]  eta: 1:41:49  lr: 0.000020  loss: 3.0203  time: 0.3149  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1550/20565]  eta: 1:41:30  lr: 0.000020  loss: 3.3417  time: 0.3159  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1600/20565]  eta: 1:41:12  lr: 0.000020  loss: 5.1598  time: 0.3147  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1650/20565]  eta: 1:40:52  lr: 0.000020  loss: 3.7493  time: 0.3132  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1700/20565]  eta: 1:40:34  lr: 0.000020  loss: 2.7157  time: 0.3147  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1750/20565]  eta: 1:40:16  lr: 0.000020  loss: 5.9312  time: 0.3146  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1800/20565]  eta: 1:39:58  lr: 0.000020  loss: 3.9696  time: 0.3173  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1850/20565]  eta: 1:39:40  lr: 0.000020  loss: 4.5027  time: 0.3133  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1900/20565]  eta: 1:39:22  lr: 0.000020  loss: 3.0101  time: 0.3153  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 1950/20565]  eta: 1:39:04  lr: 0.000020  loss: 3.8999  time: 0.3148  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2000/20565]  eta: 1:38:47  lr: 0.000020  loss: 4.5451  time: 0.3166  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2050/20565]  eta: 1:38:30  lr: 0.000020  loss: 4.3866  time: 0.3143  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2100/20565]  eta: 1:38:12  lr: 0.000020  loss: 4.1993  time: 0.3154  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2150/20565]  eta: 1:37:55  lr: 0.000020  loss: 3.1765  time: 0.3158  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2200/20565]  eta: 1:37:38  lr: 0.000020  loss: 5.1422  time: 0.3144  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2250/20565]  eta: 1:37:21  lr: 0.000020  loss: 3.6020  time: 0.3169  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2300/20565]  eta: 1:37:04  lr: 0.000020  loss: 4.0502  time: 0.3145  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2350/20565]  eta: 1:36:47  lr: 0.000020  loss: 3.5314  time: 0.3165  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2400/20565]  eta: 1:36:30  lr: 0.000020  loss: 5.6941  time: 0.3181  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2450/20565]  eta: 1:36:13  lr: 0.000020  loss: 4.8306  time: 0.3172  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2500/20565]  eta: 1:35:57  lr: 0.000020  loss: 5.1669  time: 0.3182  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2550/20565]  eta: 1:35:40  lr: 0.000020  loss: 2.7313  time: 0.3182  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2600/20565]  eta: 1:35:23  lr: 0.000020  loss: 3.5470  time: 0.3147  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2650/20565]  eta: 1:35:06  lr: 0.000020  loss: 3.7518  time: 0.3157  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2700/20565]  eta: 1:34:49  lr: 0.000020  loss: 4.4849  time: 0.3155  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2750/20565]  eta: 1:34:32  lr: 0.000020  loss: 4.2344  time: 0.3142  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2800/20565]  eta: 1:34:16  lr: 0.000020  loss: 3.8588  time: 0.3186  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2850/20565]  eta: 1:33:59  lr: 0.000020  loss: 2.9846  time: 0.3147  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2900/20565]  eta: 1:33:42  lr: 0.000020  loss: 4.3863  time: 0.3164  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 2950/20565]  eta: 1:33:25  lr: 0.000020  loss: 4.5338  time: 0.3144  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3000/20565]  eta: 1:33:09  lr: 0.000020  loss: 5.4229  time: 0.3167  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3050/20565]  eta: 1:32:53  lr: 0.000020  loss: 4.3630  time: 0.3184  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3100/20565]  eta: 1:32:36  lr: 0.000020  loss: 4.8445  time: 0.3152  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3150/20565]  eta: 1:32:20  lr: 0.000020  loss: 3.7663  time: 0.3168  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3200/20565]  eta: 1:32:03  lr: 0.000020  loss: 4.3308  time: 0.3171  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3250/20565]  eta: 1:31:47  lr: 0.000020  loss: 3.3175  time: 0.3192  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3300/20565]  eta: 1:31:30  lr: 0.000020  loss: 3.8342  time: 0.3177  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3350/20565]  eta: 1:31:14  lr: 0.000020  loss: 5.1883  time: 0.3157  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3400/20565]  eta: 1:30:57  lr: 0.000020  loss: 4.7419  time: 0.3175  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3450/20565]  eta: 1:30:41  lr: 0.000020  loss: 3.6210  time: 0.3157  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3500/20565]  eta: 1:30:24  lr: 0.000020  loss: 5.5758  time: 0.3163  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3550/20565]  eta: 1:30:08  lr: 0.000020  loss: 3.5215  time: 0.3140  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3600/20565]  eta: 1:29:51  lr: 0.000020  loss: 4.0928  time: 0.3150  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3650/20565]  eta: 1:29:35  lr: 0.000020  loss: 3.3218  time: 0.3141  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3700/20565]  eta: 1:29:18  lr: 0.000020  loss: 4.2350  time: 0.3140  data: 0.0002  max mem: 13601\n","Train Epoch: [0]  [ 3750/20565]  eta: 1:29:02  lr: 0.000020  loss: 3.4398  time: 0.3182  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 3800/20565]  eta: 1:28:46  lr: 0.000020  loss: 4.1640  time: 0.3148  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 3850/20565]  eta: 1:28:30  lr: 0.000020  loss: 3.7458  time: 0.3171  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 3900/20565]  eta: 1:28:13  lr: 0.000020  loss: 4.0737  time: 0.3154  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 3950/20565]  eta: 1:27:57  lr: 0.000020  loss: 3.4781  time: 0.3163  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4000/20565]  eta: 1:27:41  lr: 0.000020  loss: 4.8548  time: 0.3197  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4050/20565]  eta: 1:27:25  lr: 0.000020  loss: 3.0521  time: 0.3146  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4100/20565]  eta: 1:27:09  lr: 0.000020  loss: 4.0842  time: 0.3175  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4150/20565]  eta: 1:26:53  lr: 0.000020  loss: 2.9424  time: 0.3152  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4200/20565]  eta: 1:26:37  lr: 0.000020  loss: 3.5605  time: 0.3182  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4250/20565]  eta: 1:26:20  lr: 0.000020  loss: 4.7625  time: 0.3162  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4300/20565]  eta: 1:26:04  lr: 0.000020  loss: 4.7460  time: 0.3179  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4350/20565]  eta: 1:25:48  lr: 0.000020  loss: 4.6098  time: 0.3162  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4400/20565]  eta: 1:25:32  lr: 0.000020  loss: 4.4571  time: 0.3170  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4450/20565]  eta: 1:25:16  lr: 0.000020  loss: 6.6851  time: 0.3163  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4500/20565]  eta: 1:25:00  lr: 0.000020  loss: 3.1077  time: 0.3142  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4550/20565]  eta: 1:24:44  lr: 0.000020  loss: 4.5629  time: 0.3191  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4600/20565]  eta: 1:24:27  lr: 0.000020  loss: 5.6189  time: 0.3151  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4650/20565]  eta: 1:24:11  lr: 0.000020  loss: 4.2848  time: 0.3161  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4700/20565]  eta: 1:23:55  lr: 0.000020  loss: 3.0242  time: 0.3161  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4750/20565]  eta: 1:23:39  lr: 0.000020  loss: 4.6282  time: 0.3157  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4800/20565]  eta: 1:23:23  lr: 0.000020  loss: 3.1203  time: 0.3150  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4850/20565]  eta: 1:23:07  lr: 0.000020  loss: 3.0900  time: 0.3135  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4900/20565]  eta: 1:22:50  lr: 0.000020  loss: 4.1675  time: 0.3152  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 4950/20565]  eta: 1:22:34  lr: 0.000020  loss: 2.9139  time: 0.3117  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5000/20565]  eta: 1:22:18  lr: 0.000020  loss: 3.5097  time: 0.3161  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5050/20565]  eta: 1:22:02  lr: 0.000020  loss: 4.3775  time: 0.3142  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5100/20565]  eta: 1:21:46  lr: 0.000020  loss: 3.5223  time: 0.3177  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5150/20565]  eta: 1:21:30  lr: 0.000020  loss: 4.0210  time: 0.3164  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5200/20565]  eta: 1:21:14  lr: 0.000020  loss: 4.3716  time: 0.3160  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5250/20565]  eta: 1:20:58  lr: 0.000020  loss: 4.0961  time: 0.3160  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5300/20565]  eta: 1:20:42  lr: 0.000020  loss: 5.1659  time: 0.3152  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5350/20565]  eta: 1:20:26  lr: 0.000020  loss: 3.9076  time: 0.3173  data: 0.0003  max mem: 13720\n","Train Epoch: [0]  [ 5400/20565]  eta: 1:20:10  lr: 0.000020  loss: 4.5923  time: 0.3164  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5450/20565]  eta: 1:19:54  lr: 0.000020  loss: 3.8982  time: 0.3155  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5500/20565]  eta: 1:19:37  lr: 0.000020  loss: 3.2212  time: 0.3165  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5550/20565]  eta: 1:19:21  lr: 0.000020  loss: 3.2258  time: 0.3158  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5600/20565]  eta: 1:19:05  lr: 0.000020  loss: 2.6472  time: 0.3157  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5650/20565]  eta: 1:18:49  lr: 0.000020  loss: 3.0022  time: 0.3150  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5700/20565]  eta: 1:18:33  lr: 0.000020  loss: 4.2132  time: 0.3155  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5750/20565]  eta: 1:18:17  lr: 0.000020  loss: 3.8800  time: 0.3112  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5800/20565]  eta: 1:18:01  lr: 0.000020  loss: 3.3023  time: 0.3164  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5850/20565]  eta: 1:17:45  lr: 0.000020  loss: 4.5416  time: 0.3152  data: 0.0003  max mem: 13720\n","Train Epoch: [0]  [ 5900/20565]  eta: 1:17:29  lr: 0.000020  loss: 4.4764  time: 0.3150  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 5950/20565]  eta: 1:17:13  lr: 0.000020  loss: 2.4005  time: 0.3144  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6000/20565]  eta: 1:16:57  lr: 0.000020  loss: 4.3523  time: 0.3156  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6050/20565]  eta: 1:16:41  lr: 0.000020  loss: 4.1171  time: 0.3143  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6100/20565]  eta: 1:16:25  lr: 0.000020  loss: 4.5583  time: 0.3175  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6150/20565]  eta: 1:16:09  lr: 0.000020  loss: 3.7852  time: 0.3149  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6200/20565]  eta: 1:15:53  lr: 0.000020  loss: 4.5072  time: 0.3171  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6250/20565]  eta: 1:15:37  lr: 0.000020  loss: 3.1737  time: 0.3177  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6300/20565]  eta: 1:15:21  lr: 0.000020  loss: 4.1494  time: 0.3164  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6350/20565]  eta: 1:15:05  lr: 0.000020  loss: 4.4646  time: 0.3144  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6400/20565]  eta: 1:14:49  lr: 0.000020  loss: 2.9390  time: 0.3173  data: 0.0002  max mem: 13720\n","Train Epoch: [0]  [ 6450/20565]  eta: 1:14:33  lr: 0.000020  loss: 3.4460  time: 0.3163  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6500/20565]  eta: 1:14:17  lr: 0.000020  loss: 3.3714  time: 0.3125  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6550/20565]  eta: 1:14:01  lr: 0.000020  loss: 4.3160  time: 0.3120  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6600/20565]  eta: 1:13:45  lr: 0.000020  loss: 3.5455  time: 0.3179  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6650/20565]  eta: 1:13:29  lr: 0.000020  loss: 3.1329  time: 0.3139  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6700/20565]  eta: 1:13:13  lr: 0.000020  loss: 3.7660  time: 0.3139  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6750/20565]  eta: 1:12:57  lr: 0.000020  loss: 2.9075  time: 0.3151  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6800/20565]  eta: 1:12:41  lr: 0.000020  loss: 3.2530  time: 0.3168  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6850/20565]  eta: 1:12:25  lr: 0.000020  loss: 3.9800  time: 0.3150  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6900/20565]  eta: 1:12:09  lr: 0.000020  loss: 4.4923  time: 0.3163  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 6950/20565]  eta: 1:11:53  lr: 0.000020  loss: 2.6618  time: 0.3157  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7000/20565]  eta: 1:11:37  lr: 0.000020  loss: 4.0008  time: 0.3164  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7050/20565]  eta: 1:11:22  lr: 0.000020  loss: 3.3958  time: 0.3174  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7100/20565]  eta: 1:11:06  lr: 0.000020  loss: 3.6814  time: 0.3151  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7150/20565]  eta: 1:10:50  lr: 0.000020  loss: 3.4504  time: 0.3156  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7200/20565]  eta: 1:10:34  lr: 0.000020  loss: 3.3151  time: 0.3153  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7250/20565]  eta: 1:10:18  lr: 0.000020  loss: 4.2354  time: 0.3158  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7300/20565]  eta: 1:10:02  lr: 0.000020  loss: 3.6689  time: 0.3179  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7350/20565]  eta: 1:09:46  lr: 0.000020  loss: 4.4559  time: 0.3161  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7400/20565]  eta: 1:09:30  lr: 0.000020  loss: 4.1565  time: 0.3161  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7450/20565]  eta: 1:09:14  lr: 0.000020  loss: 3.4676  time: 0.3176  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7500/20565]  eta: 1:08:58  lr: 0.000020  loss: 3.9880  time: 0.3166  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7550/20565]  eta: 1:08:43  lr: 0.000020  loss: 3.9599  time: 0.3158  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7600/20565]  eta: 1:08:27  lr: 0.000020  loss: 2.3076  time: 0.3131  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7650/20565]  eta: 1:08:11  lr: 0.000020  loss: 3.1764  time: 0.3168  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7700/20565]  eta: 1:07:55  lr: 0.000020  loss: 3.5234  time: 0.3170  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7750/20565]  eta: 1:07:39  lr: 0.000020  loss: 3.4081  time: 0.3146  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7800/20565]  eta: 1:07:23  lr: 0.000020  loss: 4.8374  time: 0.3164  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7850/20565]  eta: 1:07:07  lr: 0.000020  loss: 3.9608  time: 0.3175  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7900/20565]  eta: 1:06:51  lr: 0.000020  loss: 4.0816  time: 0.3184  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 7950/20565]  eta: 1:06:35  lr: 0.000020  loss: 4.3882  time: 0.3183  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8000/20565]  eta: 1:06:20  lr: 0.000020  loss: 2.8084  time: 0.3141  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8050/20565]  eta: 1:06:04  lr: 0.000020  loss: 2.7692  time: 0.3190  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8100/20565]  eta: 1:05:48  lr: 0.000020  loss: 3.1891  time: 0.3166  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8150/20565]  eta: 1:05:32  lr: 0.000020  loss: 2.8852  time: 0.3147  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8200/20565]  eta: 1:05:16  lr: 0.000020  loss: 4.1145  time: 0.3159  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8250/20565]  eta: 1:05:00  lr: 0.000020  loss: 2.4708  time: 0.3162  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8300/20565]  eta: 1:04:44  lr: 0.000020  loss: 4.5366  time: 0.3151  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8350/20565]  eta: 1:04:29  lr: 0.000020  loss: 3.7401  time: 0.3214  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8400/20565]  eta: 1:04:13  lr: 0.000020  loss: 5.5846  time: 0.3189  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8450/20565]  eta: 1:03:57  lr: 0.000020  loss: 3.3132  time: 0.3136  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8500/20565]  eta: 1:03:41  lr: 0.000020  loss: 3.6409  time: 0.3154  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8550/20565]  eta: 1:03:25  lr: 0.000020  loss: 3.4564  time: 0.3162  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8600/20565]  eta: 1:03:09  lr: 0.000020  loss: 4.2318  time: 0.3160  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8650/20565]  eta: 1:02:53  lr: 0.000020  loss: 3.2410  time: 0.3183  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8700/20565]  eta: 1:02:37  lr: 0.000020  loss: 4.6939  time: 0.3158  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8750/20565]  eta: 1:02:21  lr: 0.000020  loss: 3.2705  time: 0.3146  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8800/20565]  eta: 1:02:05  lr: 0.000020  loss: 3.6640  time: 0.3151  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8850/20565]  eta: 1:01:50  lr: 0.000020  loss: 3.6887  time: 0.3161  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8900/20565]  eta: 1:01:34  lr: 0.000020  loss: 4.7649  time: 0.3157  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 8950/20565]  eta: 1:01:18  lr: 0.000020  loss: 3.1844  time: 0.3137  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9000/20565]  eta: 1:01:02  lr: 0.000020  loss: 3.9034  time: 0.3156  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9050/20565]  eta: 1:00:46  lr: 0.000020  loss: 2.5953  time: 0.3157  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9100/20565]  eta: 1:00:30  lr: 0.000020  loss: 4.3099  time: 0.3161  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9150/20565]  eta: 1:00:14  lr: 0.000020  loss: 3.7958  time: 0.3171  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9200/20565]  eta: 0:59:58  lr: 0.000020  loss: 3.1693  time: 0.3149  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9250/20565]  eta: 0:59:43  lr: 0.000020  loss: 3.4832  time: 0.3130  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9300/20565]  eta: 0:59:27  lr: 0.000020  loss: 3.8935  time: 0.3160  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9350/20565]  eta: 0:59:11  lr: 0.000020  loss: 3.6159  time: 0.3150  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9400/20565]  eta: 0:58:55  lr: 0.000020  loss: 3.9950  time: 0.3133  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9450/20565]  eta: 0:58:39  lr: 0.000020  loss: 3.0752  time: 0.3193  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9500/20565]  eta: 0:58:23  lr: 0.000020  loss: 2.9034  time: 0.3153  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9550/20565]  eta: 0:58:07  lr: 0.000020  loss: 3.6112  time: 0.3132  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9600/20565]  eta: 0:57:51  lr: 0.000020  loss: 3.4539  time: 0.3126  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9650/20565]  eta: 0:57:35  lr: 0.000020  loss: 3.8525  time: 0.3165  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9700/20565]  eta: 0:57:19  lr: 0.000020  loss: 3.8430  time: 0.3165  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9750/20565]  eta: 0:57:03  lr: 0.000020  loss: 3.4348  time: 0.3127  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9800/20565]  eta: 0:56:48  lr: 0.000020  loss: 3.9500  time: 0.3171  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9850/20565]  eta: 0:56:32  lr: 0.000020  loss: 2.6240  time: 0.3137  data: 0.0003  max mem: 14126\n","Train Epoch: [0]  [ 9900/20565]  eta: 0:56:16  lr: 0.000020  loss: 5.0711  time: 0.3171  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [ 9950/20565]  eta: 0:56:00  lr: 0.000020  loss: 2.8914  time: 0.3150  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10000/20565]  eta: 0:55:44  lr: 0.000020  loss: 3.4146  time: 0.3162  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10050/20565]  eta: 0:55:28  lr: 0.000020  loss: 4.5894  time: 0.3164  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10100/20565]  eta: 0:55:12  lr: 0.000020  loss: 4.2901  time: 0.3161  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10150/20565]  eta: 0:54:57  lr: 0.000020  loss: 3.7516  time: 0.3148  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10200/20565]  eta: 0:54:41  lr: 0.000020  loss: 2.8006  time: 0.3164  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10250/20565]  eta: 0:54:25  lr: 0.000020  loss: 3.8702  time: 0.3154  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10300/20565]  eta: 0:54:09  lr: 0.000020  loss: 2.6368  time: 0.3166  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10350/20565]  eta: 0:53:53  lr: 0.000020  loss: 2.6304  time: 0.3153  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10400/20565]  eta: 0:53:37  lr: 0.000020  loss: 5.2740  time: 0.3161  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10450/20565]  eta: 0:53:21  lr: 0.000020  loss: 3.0179  time: 0.3164  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10500/20565]  eta: 0:53:06  lr: 0.000020  loss: 4.2752  time: 0.3134  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10550/20565]  eta: 0:52:50  lr: 0.000020  loss: 2.8444  time: 0.3162  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10600/20565]  eta: 0:52:34  lr: 0.000020  loss: 3.2978  time: 0.3148  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10650/20565]  eta: 0:52:18  lr: 0.000020  loss: 3.0420  time: 0.3166  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10700/20565]  eta: 0:52:02  lr: 0.000020  loss: 2.6055  time: 0.3138  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10750/20565]  eta: 0:51:46  lr: 0.000020  loss: 3.7431  time: 0.3135  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10800/20565]  eta: 0:51:30  lr: 0.000020  loss: 4.9704  time: 0.3137  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10850/20565]  eta: 0:51:14  lr: 0.000020  loss: 3.1471  time: 0.3156  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10900/20565]  eta: 0:50:59  lr: 0.000020  loss: 4.7252  time: 0.3150  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [10950/20565]  eta: 0:50:43  lr: 0.000020  loss: 6.1069  time: 0.3145  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11000/20565]  eta: 0:50:27  lr: 0.000020  loss: 3.7214  time: 0.3178  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11050/20565]  eta: 0:50:11  lr: 0.000020  loss: 3.6089  time: 0.3142  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11100/20565]  eta: 0:49:55  lr: 0.000020  loss: 4.0193  time: 0.3159  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11150/20565]  eta: 0:49:39  lr: 0.000020  loss: 5.1814  time: 0.3141  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11200/20565]  eta: 0:49:23  lr: 0.000020  loss: 3.4923  time: 0.3170  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11250/20565]  eta: 0:49:08  lr: 0.000020  loss: 3.3377  time: 0.3210  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11300/20565]  eta: 0:48:52  lr: 0.000020  loss: 3.0199  time: 0.3160  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11350/20565]  eta: 0:48:36  lr: 0.000020  loss: 4.6527  time: 0.3208  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11400/20565]  eta: 0:48:20  lr: 0.000020  loss: 3.6377  time: 0.3176  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11450/20565]  eta: 0:48:04  lr: 0.000020  loss: 2.4324  time: 0.3134  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11500/20565]  eta: 0:47:48  lr: 0.000020  loss: 3.2976  time: 0.3195  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11550/20565]  eta: 0:47:33  lr: 0.000020  loss: 3.4782  time: 0.3135  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11600/20565]  eta: 0:47:17  lr: 0.000020  loss: 2.6112  time: 0.3152  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11650/20565]  eta: 0:47:01  lr: 0.000020  loss: 3.0158  time: 0.3164  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11700/20565]  eta: 0:46:45  lr: 0.000020  loss: 4.6542  time: 0.3175  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11750/20565]  eta: 0:46:29  lr: 0.000020  loss: 2.4287  time: 0.3147  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11800/20565]  eta: 0:46:13  lr: 0.000020  loss: 3.9693  time: 0.3150  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11850/20565]  eta: 0:45:57  lr: 0.000020  loss: 3.7958  time: 0.3122  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11900/20565]  eta: 0:45:42  lr: 0.000020  loss: 3.8852  time: 0.3142  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [11950/20565]  eta: 0:45:26  lr: 0.000020  loss: 2.4941  time: 0.3154  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12000/20565]  eta: 0:45:10  lr: 0.000020  loss: 5.2101  time: 0.3177  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12050/20565]  eta: 0:44:54  lr: 0.000020  loss: 3.5073  time: 0.3145  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12100/20565]  eta: 0:44:38  lr: 0.000020  loss: 4.5043  time: 0.3160  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12150/20565]  eta: 0:44:22  lr: 0.000020  loss: 2.7583  time: 0.3147  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12200/20565]  eta: 0:44:07  lr: 0.000020  loss: 4.4997  time: 0.3173  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12250/20565]  eta: 0:43:51  lr: 0.000020  loss: 3.0024  time: 0.3127  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12300/20565]  eta: 0:43:35  lr: 0.000020  loss: 2.8249  time: 0.3169  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12350/20565]  eta: 0:43:19  lr: 0.000020  loss: 3.4525  time: 0.3116  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12400/20565]  eta: 0:43:03  lr: 0.000020  loss: 3.2057  time: 0.3166  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12450/20565]  eta: 0:42:47  lr: 0.000020  loss: 3.9226  time: 0.3143  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12500/20565]  eta: 0:42:31  lr: 0.000020  loss: 2.7960  time: 0.3158  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12550/20565]  eta: 0:42:16  lr: 0.000020  loss: 4.5578  time: 0.3143  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12600/20565]  eta: 0:42:00  lr: 0.000020  loss: 4.6146  time: 0.3165  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12650/20565]  eta: 0:41:44  lr: 0.000020  loss: 3.4939  time: 0.3137  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12700/20565]  eta: 0:41:28  lr: 0.000020  loss: 1.7813  time: 0.3132  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12750/20565]  eta: 0:41:12  lr: 0.000020  loss: 5.3659  time: 0.3210  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12800/20565]  eta: 0:40:56  lr: 0.000020  loss: 3.3003  time: 0.3170  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12850/20565]  eta: 0:40:41  lr: 0.000020  loss: 3.3636  time: 0.3124  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12900/20565]  eta: 0:40:25  lr: 0.000020  loss: 3.1713  time: 0.3183  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [12950/20565]  eta: 0:40:09  lr: 0.000020  loss: 3.8147  time: 0.3172  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13000/20565]  eta: 0:39:53  lr: 0.000020  loss: 3.2699  time: 0.3180  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13050/20565]  eta: 0:39:37  lr: 0.000020  loss: 2.3094  time: 0.3172  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13100/20565]  eta: 0:39:22  lr: 0.000020  loss: 3.6306  time: 0.3154  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13150/20565]  eta: 0:39:06  lr: 0.000020  loss: 2.7884  time: 0.3160  data: 0.0003  max mem: 14126\n","Train Epoch: [0]  [13200/20565]  eta: 0:38:50  lr: 0.000020  loss: 3.2428  time: 0.3166  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13250/20565]  eta: 0:38:34  lr: 0.000020  loss: 4.0989  time: 0.3172  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13300/20565]  eta: 0:38:18  lr: 0.000020  loss: 3.3395  time: 0.3182  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13350/20565]  eta: 0:38:02  lr: 0.000020  loss: 4.0284  time: 0.3194  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13400/20565]  eta: 0:37:47  lr: 0.000020  loss: 3.6122  time: 0.3146  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13450/20565]  eta: 0:37:31  lr: 0.000020  loss: 3.1060  time: 0.3143  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13500/20565]  eta: 0:37:15  lr: 0.000020  loss: 3.1004  time: 0.3169  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13550/20565]  eta: 0:36:59  lr: 0.000020  loss: 4.6909  time: 0.3168  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13600/20565]  eta: 0:36:43  lr: 0.000020  loss: 5.4020  time: 0.3156  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13650/20565]  eta: 0:36:27  lr: 0.000020  loss: 2.6946  time: 0.3130  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13700/20565]  eta: 0:36:11  lr: 0.000020  loss: 3.4929  time: 0.3127  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13750/20565]  eta: 0:35:56  lr: 0.000020  loss: 3.5270  time: 0.3163  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13800/20565]  eta: 0:35:40  lr: 0.000020  loss: 4.7299  time: 0.3173  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13850/20565]  eta: 0:35:24  lr: 0.000020  loss: 3.4671  time: 0.3142  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13900/20565]  eta: 0:35:08  lr: 0.000020  loss: 4.1250  time: 0.3175  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [13950/20565]  eta: 0:34:52  lr: 0.000020  loss: 3.6081  time: 0.3170  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14000/20565]  eta: 0:34:36  lr: 0.000020  loss: 3.1130  time: 0.3157  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14050/20565]  eta: 0:34:21  lr: 0.000020  loss: 4.3518  time: 0.3158  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14100/20565]  eta: 0:34:05  lr: 0.000020  loss: 2.9311  time: 0.3136  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14150/20565]  eta: 0:33:49  lr: 0.000020  loss: 3.9253  time: 0.3146  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14200/20565]  eta: 0:33:33  lr: 0.000020  loss: 4.6862  time: 0.3152  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14250/20565]  eta: 0:33:17  lr: 0.000020  loss: 3.6751  time: 0.3167  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14300/20565]  eta: 0:33:01  lr: 0.000020  loss: 4.4862  time: 0.3170  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14350/20565]  eta: 0:32:46  lr: 0.000020  loss: 3.9700  time: 0.3152  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14400/20565]  eta: 0:32:30  lr: 0.000020  loss: 3.0629  time: 0.3159  data: 0.0002  max mem: 14126\n","Train Epoch: [0]  [14450/20565]  eta: 0:32:14  lr: 0.000020  loss: 4.1311  time: 0.3196  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14500/20565]  eta: 0:31:58  lr: 0.000020  loss: 4.2232  time: 0.3142  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14550/20565]  eta: 0:31:42  lr: 0.000020  loss: 4.0312  time: 0.3209  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14600/20565]  eta: 0:31:27  lr: 0.000020  loss: 2.8895  time: 0.3164  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14650/20565]  eta: 0:31:11  lr: 0.000020  loss: 3.0780  time: 0.3148  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14700/20565]  eta: 0:30:55  lr: 0.000020  loss: 3.3303  time: 0.3166  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14750/20565]  eta: 0:30:39  lr: 0.000020  loss: 3.0131  time: 0.3168  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14800/20565]  eta: 0:30:23  lr: 0.000020  loss: 2.9622  time: 0.3170  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14850/20565]  eta: 0:30:07  lr: 0.000020  loss: 2.6850  time: 0.3164  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14900/20565]  eta: 0:29:52  lr: 0.000020  loss: 3.1800  time: 0.3154  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [14950/20565]  eta: 0:29:36  lr: 0.000020  loss: 3.6362  time: 0.3150  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15000/20565]  eta: 0:29:20  lr: 0.000020  loss: 3.0127  time: 0.3187  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15050/20565]  eta: 0:29:04  lr: 0.000020  loss: 3.3196  time: 0.3158  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15100/20565]  eta: 0:28:48  lr: 0.000020  loss: 4.1456  time: 0.3139  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15150/20565]  eta: 0:28:32  lr: 0.000020  loss: 3.5862  time: 0.3170  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15200/20565]  eta: 0:28:17  lr: 0.000020  loss: 4.4260  time: 0.3179  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15250/20565]  eta: 0:28:01  lr: 0.000020  loss: 3.5533  time: 0.3172  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15300/20565]  eta: 0:27:45  lr: 0.000020  loss: 2.6886  time: 0.3163  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15350/20565]  eta: 0:27:29  lr: 0.000020  loss: 4.7799  time: 0.3135  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15400/20565]  eta: 0:27:13  lr: 0.000020  loss: 3.3324  time: 0.3166  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15450/20565]  eta: 0:26:58  lr: 0.000020  loss: 3.1752  time: 0.3168  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15500/20565]  eta: 0:26:42  lr: 0.000020  loss: 4.0077  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15550/20565]  eta: 0:26:26  lr: 0.000020  loss: 4.1679  time: 0.3188  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15600/20565]  eta: 0:26:10  lr: 0.000020  loss: 4.2197  time: 0.3162  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15650/20565]  eta: 0:25:54  lr: 0.000020  loss: 4.1837  time: 0.3179  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15700/20565]  eta: 0:25:38  lr: 0.000020  loss: 2.6650  time: 0.3154  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15750/20565]  eta: 0:25:23  lr: 0.000020  loss: 4.4216  time: 0.3153  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15800/20565]  eta: 0:25:07  lr: 0.000020  loss: 3.7078  time: 0.3174  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15850/20565]  eta: 0:24:51  lr: 0.000020  loss: 3.5470  time: 0.3160  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15900/20565]  eta: 0:24:35  lr: 0.000020  loss: 3.0744  time: 0.3145  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [15950/20565]  eta: 0:24:19  lr: 0.000020  loss: 2.9066  time: 0.3168  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16000/20565]  eta: 0:24:04  lr: 0.000020  loss: 4.2701  time: 0.3140  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16050/20565]  eta: 0:23:48  lr: 0.000020  loss: 5.2948  time: 0.3187  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16100/20565]  eta: 0:23:32  lr: 0.000020  loss: 4.1526  time: 0.3158  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16150/20565]  eta: 0:23:16  lr: 0.000020  loss: 4.1951  time: 0.3140  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16200/20565]  eta: 0:23:00  lr: 0.000020  loss: 4.0142  time: 0.3163  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16250/20565]  eta: 0:22:44  lr: 0.000020  loss: 4.0055  time: 0.3150  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16300/20565]  eta: 0:22:29  lr: 0.000020  loss: 3.8406  time: 0.3138  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16350/20565]  eta: 0:22:13  lr: 0.000020  loss: 3.6177  time: 0.3171  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16400/20565]  eta: 0:21:57  lr: 0.000020  loss: 3.5435  time: 0.3139  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16450/20565]  eta: 0:21:41  lr: 0.000020  loss: 3.9933  time: 0.3183  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16500/20565]  eta: 0:21:25  lr: 0.000020  loss: 3.2738  time: 0.3187  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16550/20565]  eta: 0:21:10  lr: 0.000020  loss: 3.3618  time: 0.3189  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16600/20565]  eta: 0:20:54  lr: 0.000020  loss: 3.7857  time: 0.3135  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16650/20565]  eta: 0:20:38  lr: 0.000020  loss: 4.6627  time: 0.3172  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16700/20565]  eta: 0:20:22  lr: 0.000020  loss: 5.9710  time: 0.3163  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16750/20565]  eta: 0:20:06  lr: 0.000020  loss: 2.9138  time: 0.3144  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16800/20565]  eta: 0:19:50  lr: 0.000020  loss: 3.9061  time: 0.3178  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16850/20565]  eta: 0:19:35  lr: 0.000020  loss: 4.4843  time: 0.3184  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16900/20565]  eta: 0:19:19  lr: 0.000020  loss: 3.0707  time: 0.3168  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [16950/20565]  eta: 0:19:03  lr: 0.000020  loss: 3.8068  time: 0.3161  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17000/20565]  eta: 0:18:47  lr: 0.000020  loss: 3.3959  time: 0.3135  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17050/20565]  eta: 0:18:31  lr: 0.000020  loss: 3.0421  time: 0.3170  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17100/20565]  eta: 0:18:15  lr: 0.000020  loss: 2.5443  time: 0.3137  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17150/20565]  eta: 0:18:00  lr: 0.000020  loss: 4.5911  time: 0.3137  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17200/20565]  eta: 0:17:44  lr: 0.000020  loss: 4.2009  time: 0.3168  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17250/20565]  eta: 0:17:28  lr: 0.000020  loss: 3.0948  time: 0.3159  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17300/20565]  eta: 0:17:12  lr: 0.000020  loss: 4.4472  time: 0.3175  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17350/20565]  eta: 0:16:56  lr: 0.000020  loss: 2.7698  time: 0.3150  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17400/20565]  eta: 0:16:41  lr: 0.000020  loss: 4.4674  time: 0.3175  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17450/20565]  eta: 0:16:25  lr: 0.000020  loss: 2.9024  time: 0.3149  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17500/20565]  eta: 0:16:09  lr: 0.000020  loss: 5.4761  time: 0.3148  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17550/20565]  eta: 0:15:53  lr: 0.000020  loss: 3.9410  time: 0.3174  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17600/20565]  eta: 0:15:37  lr: 0.000020  loss: 4.5762  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17650/20565]  eta: 0:15:21  lr: 0.000020  loss: 3.7875  time: 0.3145  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17700/20565]  eta: 0:15:06  lr: 0.000020  loss: 2.7414  time: 0.3160  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17750/20565]  eta: 0:14:50  lr: 0.000020  loss: 2.8979  time: 0.3156  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17800/20565]  eta: 0:14:34  lr: 0.000020  loss: 3.0767  time: 0.3147  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17850/20565]  eta: 0:14:18  lr: 0.000020  loss: 3.4164  time: 0.3148  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17900/20565]  eta: 0:14:02  lr: 0.000020  loss: 3.1278  time: 0.3146  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [17950/20565]  eta: 0:13:47  lr: 0.000020  loss: 2.4391  time: 0.3166  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18000/20565]  eta: 0:13:31  lr: 0.000020  loss: 4.2986  time: 0.3179  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18050/20565]  eta: 0:13:15  lr: 0.000020  loss: 4.1294  time: 0.3124  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18100/20565]  eta: 0:12:59  lr: 0.000020  loss: 2.9754  time: 0.3148  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18150/20565]  eta: 0:12:43  lr: 0.000020  loss: 3.1828  time: 0.3154  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18200/20565]  eta: 0:12:27  lr: 0.000020  loss: 3.3345  time: 0.3143  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18250/20565]  eta: 0:12:12  lr: 0.000020  loss: 2.7241  time: 0.3150  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18300/20565]  eta: 0:11:56  lr: 0.000020  loss: 3.6922  time: 0.3136  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18350/20565]  eta: 0:11:40  lr: 0.000020  loss: 3.6308  time: 0.3160  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18400/20565]  eta: 0:11:24  lr: 0.000020  loss: 3.9981  time: 0.3153  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18450/20565]  eta: 0:11:08  lr: 0.000020  loss: 3.9865  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18500/20565]  eta: 0:10:53  lr: 0.000020  loss: 3.0556  time: 0.3142  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18550/20565]  eta: 0:10:37  lr: 0.000020  loss: 2.9354  time: 0.3145  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18600/20565]  eta: 0:10:21  lr: 0.000020  loss: 4.3472  time: 0.3171  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18650/20565]  eta: 0:10:05  lr: 0.000020  loss: 3.8888  time: 0.3152  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18700/20565]  eta: 0:09:49  lr: 0.000020  loss: 3.7880  time: 0.3148  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18750/20565]  eta: 0:09:33  lr: 0.000020  loss: 3.9133  time: 0.3167  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18800/20565]  eta: 0:09:18  lr: 0.000020  loss: 3.7769  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18850/20565]  eta: 0:09:02  lr: 0.000020  loss: 3.3447  time: 0.3145  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18900/20565]  eta: 0:08:46  lr: 0.000020  loss: 3.5177  time: 0.3146  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [18950/20565]  eta: 0:08:30  lr: 0.000020  loss: 4.8431  time: 0.3146  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19000/20565]  eta: 0:08:14  lr: 0.000020  loss: 2.6055  time: 0.3132  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19050/20565]  eta: 0:07:59  lr: 0.000020  loss: 2.2283  time: 0.3121  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19100/20565]  eta: 0:07:43  lr: 0.000020  loss: 3.4028  time: 0.3168  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19150/20565]  eta: 0:07:27  lr: 0.000020  loss: 2.4401  time: 0.3144  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19200/20565]  eta: 0:07:11  lr: 0.000020  loss: 3.8127  time: 0.3164  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19250/20565]  eta: 0:06:55  lr: 0.000020  loss: 3.0720  time: 0.3140  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19300/20565]  eta: 0:06:39  lr: 0.000020  loss: 3.1174  time: 0.3192  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19350/20565]  eta: 0:06:24  lr: 0.000020  loss: 4.4298  time: 0.3173  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19400/20565]  eta: 0:06:08  lr: 0.000020  loss: 2.9495  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19450/20565]  eta: 0:05:52  lr: 0.000020  loss: 2.9681  time: 0.3141  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19500/20565]  eta: 0:05:36  lr: 0.000020  loss: 3.0742  time: 0.3168  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19550/20565]  eta: 0:05:20  lr: 0.000020  loss: 3.8624  time: 0.3154  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19600/20565]  eta: 0:05:05  lr: 0.000020  loss: 3.1020  time: 0.3183  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19650/20565]  eta: 0:04:49  lr: 0.000020  loss: 3.4663  time: 0.3152  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19700/20565]  eta: 0:04:33  lr: 0.000020  loss: 3.3720  time: 0.3150  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19750/20565]  eta: 0:04:17  lr: 0.000020  loss: 3.2496  time: 0.3139  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19800/20565]  eta: 0:04:01  lr: 0.000020  loss: 3.9406  time: 0.3178  data: 0.0003  max mem: 14556\n","Train Epoch: [0]  [19850/20565]  eta: 0:03:46  lr: 0.000020  loss: 3.4691  time: 0.3171  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19900/20565]  eta: 0:03:30  lr: 0.000020  loss: 3.3949  time: 0.3162  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [19950/20565]  eta: 0:03:14  lr: 0.000020  loss: 4.3724  time: 0.3165  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20000/20565]  eta: 0:02:58  lr: 0.000020  loss: 5.5635  time: 0.3181  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20050/20565]  eta: 0:02:42  lr: 0.000020  loss: 4.2790  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20100/20565]  eta: 0:02:27  lr: 0.000020  loss: 3.1776  time: 0.3140  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20150/20565]  eta: 0:02:11  lr: 0.000020  loss: 3.0754  time: 0.3165  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20200/20565]  eta: 0:01:55  lr: 0.000020  loss: 4.1502  time: 0.3164  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20250/20565]  eta: 0:01:39  lr: 0.000020  loss: 2.3695  time: 0.3145  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20300/20565]  eta: 0:01:23  lr: 0.000020  loss: 3.2692  time: 0.3184  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20350/20565]  eta: 0:01:07  lr: 0.000020  loss: 4.3025  time: 0.3160  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20400/20565]  eta: 0:00:52  lr: 0.000020  loss: 3.3183  time: 0.3210  data: 0.0003  max mem: 14556\n","Train Epoch: [0]  [20450/20565]  eta: 0:00:36  lr: 0.000020  loss: 5.4493  time: 0.3187  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20500/20565]  eta: 0:00:20  lr: 0.000020  loss: 2.5094  time: 0.3171  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20550/20565]  eta: 0:00:04  lr: 0.000020  loss: 2.5368  time: 0.3143  data: 0.0002  max mem: 14556\n","Train Epoch: [0]  [20564/20565]  eta: 0:00:00  lr: 0.000020  loss: 2.5708  time: 0.3165  data: 0.0029  max mem: 14556\n","Train Epoch: [0] Total time: 1:48:23 (0.3162 s / it)\n","Averaged stats: lr: 0.0000  loss: 3.9032\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Epoch: [1]  [    0/20565]  eta: 8:53:59  lr: 0.000019  loss: 4.8544  time: 1.5580  data: 1.1907  max mem: 14556\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Epoch: [1]  [   50/20565]  eta: 1:57:16  lr: 0.000019  loss: 2.6268  time: 0.3178  data: 0.0003  max mem: 14556\n","Train Epoch: [1]  [  100/20565]  eta: 1:52:59  lr: 0.000019  loss: 3.2184  time: 0.3187  data: 0.0003  max mem: 14556\n","Train Epoch: [1]  [  150/20565]  eta: 1:51:01  lr: 0.000019  loss: 3.7658  time: 0.3168  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  200/20565]  eta: 1:49:58  lr: 0.000019  loss: 2.6658  time: 0.3159  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  250/20565]  eta: 1:49:12  lr: 0.000019  loss: 3.3373  time: 0.3173  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  300/20565]  eta: 1:48:37  lr: 0.000019  loss: 3.1671  time: 0.3146  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  350/20565]  eta: 1:48:07  lr: 0.000019  loss: 3.2101  time: 0.3188  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  400/20565]  eta: 1:47:39  lr: 0.000019  loss: 3.5128  time: 0.3190  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  450/20565]  eta: 1:47:17  lr: 0.000019  loss: 4.1940  time: 0.3184  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  500/20565]  eta: 1:46:49  lr: 0.000019  loss: 2.7023  time: 0.3136  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  550/20565]  eta: 1:46:29  lr: 0.000019  loss: 3.5898  time: 0.3192  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  600/20565]  eta: 1:46:06  lr: 0.000019  loss: 4.0360  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  650/20565]  eta: 1:45:49  lr: 0.000019  loss: 2.9622  time: 0.3169  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  700/20565]  eta: 1:45:30  lr: 0.000019  loss: 4.0423  time: 0.3162  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  750/20565]  eta: 1:45:11  lr: 0.000019  loss: 5.1488  time: 0.3148  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  800/20565]  eta: 1:44:50  lr: 0.000019  loss: 3.3191  time: 0.3140  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  850/20565]  eta: 1:44:32  lr: 0.000019  loss: 3.5046  time: 0.3157  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  900/20565]  eta: 1:44:13  lr: 0.000019  loss: 2.9044  time: 0.3161  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [  950/20565]  eta: 1:43:55  lr: 0.000019  loss: 2.7234  time: 0.3164  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1000/20565]  eta: 1:43:38  lr: 0.000019  loss: 2.9408  time: 0.3182  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1050/20565]  eta: 1:43:23  lr: 0.000019  loss: 3.0704  time: 0.3185  data: 0.0003  max mem: 14556\n","Train Epoch: [1]  [ 1100/20565]  eta: 1:43:06  lr: 0.000019  loss: 2.8872  time: 0.3159  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1150/20565]  eta: 1:42:48  lr: 0.000019  loss: 3.1889  time: 0.3166  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1200/20565]  eta: 1:42:31  lr: 0.000019  loss: 3.2606  time: 0.3153  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1250/20565]  eta: 1:42:14  lr: 0.000019  loss: 3.8409  time: 0.3178  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1300/20565]  eta: 1:41:57  lr: 0.000019  loss: 3.1925  time: 0.3132  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1350/20565]  eta: 1:41:40  lr: 0.000019  loss: 6.2380  time: 0.3178  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1400/20565]  eta: 1:41:24  lr: 0.000019  loss: 2.7425  time: 0.3156  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1450/20565]  eta: 1:41:08  lr: 0.000019  loss: 3.5588  time: 0.3150  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1500/20565]  eta: 1:40:50  lr: 0.000019  loss: 3.1547  time: 0.3143  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1550/20565]  eta: 1:40:34  lr: 0.000019  loss: 2.5574  time: 0.3154  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1600/20565]  eta: 1:40:19  lr: 0.000019  loss: 3.9106  time: 0.3193  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1650/20565]  eta: 1:40:03  lr: 0.000019  loss: 3.2061  time: 0.3165  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1700/20565]  eta: 1:39:46  lr: 0.000019  loss: 3.0113  time: 0.3179  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1750/20565]  eta: 1:39:29  lr: 0.000019  loss: 4.0319  time: 0.3158  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1800/20565]  eta: 1:39:13  lr: 0.000019  loss: 2.9365  time: 0.3162  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1850/20565]  eta: 1:38:56  lr: 0.000019  loss: 3.2807  time: 0.3159  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1900/20565]  eta: 1:38:40  lr: 0.000019  loss: 2.2696  time: 0.3135  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 1950/20565]  eta: 1:38:24  lr: 0.000019  loss: 3.8198  time: 0.3155  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2000/20565]  eta: 1:38:07  lr: 0.000019  loss: 4.0842  time: 0.3167  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2050/20565]  eta: 1:37:51  lr: 0.000019  loss: 3.2603  time: 0.3163  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2100/20565]  eta: 1:37:35  lr: 0.000019  loss: 3.6276  time: 0.3159  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2150/20565]  eta: 1:37:18  lr: 0.000019  loss: 3.6563  time: 0.3174  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2200/20565]  eta: 1:37:02  lr: 0.000019  loss: 3.0714  time: 0.3157  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2250/20565]  eta: 1:36:45  lr: 0.000019  loss: 3.8949  time: 0.3142  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2300/20565]  eta: 1:36:30  lr: 0.000019  loss: 3.4621  time: 0.3188  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2350/20565]  eta: 1:36:13  lr: 0.000019  loss: 3.7836  time: 0.3170  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2400/20565]  eta: 1:35:58  lr: 0.000019  loss: 3.1364  time: 0.3180  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2450/20565]  eta: 1:35:41  lr: 0.000019  loss: 4.7351  time: 0.3165  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2500/20565]  eta: 1:35:25  lr: 0.000019  loss: 3.7426  time: 0.3161  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2550/20565]  eta: 1:35:09  lr: 0.000019  loss: 3.7360  time: 0.3158  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2600/20565]  eta: 1:34:52  lr: 0.000019  loss: 4.6478  time: 0.3140  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2650/20565]  eta: 1:34:37  lr: 0.000019  loss: 3.4150  time: 0.3194  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2700/20565]  eta: 1:34:21  lr: 0.000019  loss: 3.8456  time: 0.3145  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2750/20565]  eta: 1:34:04  lr: 0.000019  loss: 3.5117  time: 0.3129  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2800/20565]  eta: 1:33:48  lr: 0.000019  loss: 2.6111  time: 0.3167  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2850/20565]  eta: 1:33:32  lr: 0.000019  loss: 2.8950  time: 0.3158  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2900/20565]  eta: 1:33:17  lr: 0.000019  loss: 3.4062  time: 0.3170  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 2950/20565]  eta: 1:33:01  lr: 0.000019  loss: 3.8445  time: 0.3145  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3000/20565]  eta: 1:32:45  lr: 0.000019  loss: 2.5496  time: 0.3144  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3050/20565]  eta: 1:32:29  lr: 0.000019  loss: 3.5794  time: 0.3176  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3100/20565]  eta: 1:32:13  lr: 0.000019  loss: 4.1525  time: 0.3172  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3150/20565]  eta: 1:31:57  lr: 0.000019  loss: 2.2961  time: 0.3163  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3200/20565]  eta: 1:31:41  lr: 0.000019  loss: 3.5751  time: 0.3180  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3250/20565]  eta: 1:31:25  lr: 0.000019  loss: 3.8395  time: 0.3147  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3300/20565]  eta: 1:31:09  lr: 0.000019  loss: 3.2845  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3350/20565]  eta: 1:30:52  lr: 0.000019  loss: 2.5842  time: 0.3136  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3400/20565]  eta: 1:30:36  lr: 0.000019  loss: 4.4494  time: 0.3168  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3450/20565]  eta: 1:30:21  lr: 0.000019  loss: 3.0739  time: 0.3163  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3500/20565]  eta: 1:30:05  lr: 0.000019  loss: 3.5020  time: 0.3165  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3550/20565]  eta: 1:29:49  lr: 0.000019  loss: 3.4865  time: 0.3181  data: 0.0003  max mem: 14556\n","Train Epoch: [1]  [ 3600/20565]  eta: 1:29:33  lr: 0.000019  loss: 3.0466  time: 0.3164  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3650/20565]  eta: 1:29:17  lr: 0.000019  loss: 3.4890  time: 0.3174  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3700/20565]  eta: 1:29:01  lr: 0.000019  loss: 3.8153  time: 0.3170  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3750/20565]  eta: 1:28:45  lr: 0.000019  loss: 3.7595  time: 0.3152  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3800/20565]  eta: 1:28:29  lr: 0.000019  loss: 2.6491  time: 0.3185  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3850/20565]  eta: 1:28:14  lr: 0.000019  loss: 3.1846  time: 0.3161  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3900/20565]  eta: 1:27:58  lr: 0.000019  loss: 4.0061  time: 0.3155  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 3950/20565]  eta: 1:27:42  lr: 0.000019  loss: 2.7347  time: 0.3188  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4000/20565]  eta: 1:27:27  lr: 0.000019  loss: 3.7671  time: 0.3174  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4050/20565]  eta: 1:27:11  lr: 0.000019  loss: 4.2122  time: 0.3145  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4100/20565]  eta: 1:26:55  lr: 0.000019  loss: 3.3972  time: 0.3134  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4150/20565]  eta: 1:26:38  lr: 0.000019  loss: 2.5762  time: 0.3143  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4200/20565]  eta: 1:26:22  lr: 0.000019  loss: 4.2683  time: 0.3176  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4250/20565]  eta: 1:26:07  lr: 0.000019  loss: 2.7221  time: 0.3166  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4300/20565]  eta: 1:25:51  lr: 0.000019  loss: 3.4112  time: 0.3146  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4350/20565]  eta: 1:25:35  lr: 0.000019  loss: 3.4876  time: 0.3157  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4400/20565]  eta: 1:25:19  lr: 0.000019  loss: 4.0944  time: 0.3189  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4450/20565]  eta: 1:25:03  lr: 0.000019  loss: 3.2324  time: 0.3170  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4500/20565]  eta: 1:24:47  lr: 0.000019  loss: 2.5159  time: 0.3161  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4550/20565]  eta: 1:24:32  lr: 0.000019  loss: 3.7713  time: 0.3163  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4600/20565]  eta: 1:24:16  lr: 0.000019  loss: 3.7396  time: 0.3166  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4650/20565]  eta: 1:24:00  lr: 0.000019  loss: 3.4136  time: 0.3158  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4700/20565]  eta: 1:23:44  lr: 0.000019  loss: 3.3733  time: 0.3165  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4750/20565]  eta: 1:23:28  lr: 0.000019  loss: 3.0580  time: 0.3158  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4800/20565]  eta: 1:23:12  lr: 0.000019  loss: 3.6638  time: 0.3175  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4850/20565]  eta: 1:22:56  lr: 0.000019  loss: 4.7232  time: 0.3189  data: 0.0003  max mem: 14556\n","Train Epoch: [1]  [ 4900/20565]  eta: 1:22:40  lr: 0.000019  loss: 2.7460  time: 0.3159  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 4950/20565]  eta: 1:22:24  lr: 0.000019  loss: 2.3898  time: 0.3157  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5000/20565]  eta: 1:22:09  lr: 0.000019  loss: 3.3340  time: 0.3175  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5050/20565]  eta: 1:21:53  lr: 0.000019  loss: 3.2243  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5100/20565]  eta: 1:21:37  lr: 0.000019  loss: 2.2959  time: 0.3151  data: 0.0003  max mem: 14556\n","Train Epoch: [1]  [ 5150/20565]  eta: 1:21:21  lr: 0.000019  loss: 3.3696  time: 0.3171  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5200/20565]  eta: 1:21:05  lr: 0.000019  loss: 2.6560  time: 0.3148  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5250/20565]  eta: 1:20:49  lr: 0.000019  loss: 3.2875  time: 0.3184  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5300/20565]  eta: 1:20:33  lr: 0.000019  loss: 5.9217  time: 0.3153  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5350/20565]  eta: 1:20:17  lr: 0.000019  loss: 2.9952  time: 0.3130  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5400/20565]  eta: 1:20:01  lr: 0.000019  loss: 3.4757  time: 0.3166  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5450/20565]  eta: 1:19:46  lr: 0.000019  loss: 3.0661  time: 0.3182  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5500/20565]  eta: 1:19:30  lr: 0.000019  loss: 3.0681  time: 0.3192  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5550/20565]  eta: 1:19:14  lr: 0.000019  loss: 2.8112  time: 0.3191  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5600/20565]  eta: 1:18:59  lr: 0.000019  loss: 4.1727  time: 0.3159  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5650/20565]  eta: 1:18:43  lr: 0.000019  loss: 2.9653  time: 0.3155  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5700/20565]  eta: 1:18:27  lr: 0.000019  loss: 3.7691  time: 0.3131  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5750/20565]  eta: 1:18:11  lr: 0.000019  loss: 4.0146  time: 0.3155  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5800/20565]  eta: 1:17:55  lr: 0.000019  loss: 3.6852  time: 0.3204  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5850/20565]  eta: 1:17:39  lr: 0.000019  loss: 4.0705  time: 0.3169  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5900/20565]  eta: 1:17:23  lr: 0.000019  loss: 3.5077  time: 0.3145  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 5950/20565]  eta: 1:17:07  lr: 0.000019  loss: 3.8798  time: 0.3186  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6000/20565]  eta: 1:16:52  lr: 0.000019  loss: 4.0353  time: 0.3188  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6050/20565]  eta: 1:16:36  lr: 0.000019  loss: 2.1161  time: 0.3158  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6100/20565]  eta: 1:16:20  lr: 0.000019  loss: 3.4528  time: 0.3185  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6150/20565]  eta: 1:16:04  lr: 0.000019  loss: 2.1646  time: 0.3143  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6200/20565]  eta: 1:15:48  lr: 0.000019  loss: 2.5139  time: 0.3146  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6250/20565]  eta: 1:15:32  lr: 0.000019  loss: 2.8153  time: 0.3146  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6300/20565]  eta: 1:15:16  lr: 0.000019  loss: 3.6581  time: 0.3163  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6350/20565]  eta: 1:15:00  lr: 0.000019  loss: 4.1982  time: 0.3180  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6400/20565]  eta: 1:14:44  lr: 0.000019  loss: 3.8768  time: 0.3143  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6450/20565]  eta: 1:14:28  lr: 0.000019  loss: 3.0233  time: 0.3169  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6500/20565]  eta: 1:14:12  lr: 0.000019  loss: 3.1380  time: 0.3163  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6550/20565]  eta: 1:13:56  lr: 0.000019  loss: 3.6988  time: 0.3131  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6600/20565]  eta: 1:13:40  lr: 0.000019  loss: 2.3567  time: 0.3159  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6650/20565]  eta: 1:13:25  lr: 0.000019  loss: 3.2169  time: 0.3151  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6700/20565]  eta: 1:13:09  lr: 0.000019  loss: 3.0251  time: 0.3144  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6750/20565]  eta: 1:12:53  lr: 0.000019  loss: 3.4470  time: 0.3175  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6800/20565]  eta: 1:12:37  lr: 0.000019  loss: 3.2741  time: 0.3181  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6850/20565]  eta: 1:12:21  lr: 0.000019  loss: 3.0807  time: 0.3150  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6900/20565]  eta: 1:12:05  lr: 0.000019  loss: 3.4650  time: 0.3129  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 6950/20565]  eta: 1:11:49  lr: 0.000019  loss: 3.3226  time: 0.3150  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7000/20565]  eta: 1:11:33  lr: 0.000019  loss: 3.4470  time: 0.3161  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7050/20565]  eta: 1:11:17  lr: 0.000019  loss: 3.8679  time: 0.3161  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7100/20565]  eta: 1:11:02  lr: 0.000019  loss: 4.3924  time: 0.3155  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7150/20565]  eta: 1:10:46  lr: 0.000019  loss: 3.2554  time: 0.3148  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7200/20565]  eta: 1:10:30  lr: 0.000019  loss: 3.5888  time: 0.3155  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7250/20565]  eta: 1:10:14  lr: 0.000019  loss: 3.6907  time: 0.3171  data: 0.0003  max mem: 14556\n","Train Epoch: [1]  [ 7300/20565]  eta: 1:09:58  lr: 0.000019  loss: 3.2618  time: 0.3214  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7350/20565]  eta: 1:09:42  lr: 0.000019  loss: 3.2917  time: 0.3178  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7400/20565]  eta: 1:09:27  lr: 0.000019  loss: 5.1259  time: 0.3196  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7450/20565]  eta: 1:09:11  lr: 0.000019  loss: 2.3752  time: 0.3173  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7500/20565]  eta: 1:08:55  lr: 0.000019  loss: 4.2103  time: 0.3180  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7550/20565]  eta: 1:08:39  lr: 0.000019  loss: 3.9554  time: 0.3156  data: 0.0002  max mem: 14556\n","Train Epoch: [1]  [ 7600/20565]  eta: 1:08:24  lr: 0.000019  loss: 4.1406  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 7650/20565]  eta: 1:08:08  lr: 0.000019  loss: 3.1249  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 7700/20565]  eta: 1:07:52  lr: 0.000019  loss: 2.9622  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 7750/20565]  eta: 1:07:36  lr: 0.000019  loss: 2.6271  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 7800/20565]  eta: 1:07:20  lr: 0.000019  loss: 3.7386  time: 0.3190  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 7850/20565]  eta: 1:07:05  lr: 0.000019  loss: 3.3748  time: 0.3188  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 7900/20565]  eta: 1:06:49  lr: 0.000019  loss: 5.0892  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 7950/20565]  eta: 1:06:33  lr: 0.000019  loss: 2.8795  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8000/20565]  eta: 1:06:17  lr: 0.000019  loss: 2.1149  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8050/20565]  eta: 1:06:01  lr: 0.000019  loss: 4.8676  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8100/20565]  eta: 1:05:46  lr: 0.000019  loss: 3.4720  time: 0.3195  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8150/20565]  eta: 1:05:30  lr: 0.000019  loss: 2.7709  time: 0.3200  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8200/20565]  eta: 1:05:14  lr: 0.000019  loss: 2.9491  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8250/20565]  eta: 1:04:58  lr: 0.000019  loss: 3.5273  time: 0.3154  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [ 8300/20565]  eta: 1:04:46  lr: 0.000019  loss: 2.9602  time: 0.4573  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8350/20565]  eta: 1:04:31  lr: 0.000019  loss: 3.7800  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8400/20565]  eta: 1:04:15  lr: 0.000019  loss: 3.5735  time: 0.3150  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [ 8450/20565]  eta: 1:03:59  lr: 0.000019  loss: 4.4334  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8500/20565]  eta: 1:03:43  lr: 0.000019  loss: 3.4392  time: 0.3176  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8550/20565]  eta: 1:03:27  lr: 0.000019  loss: 3.3359  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8600/20565]  eta: 1:03:11  lr: 0.000019  loss: 2.6990  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8650/20565]  eta: 1:02:55  lr: 0.000019  loss: 2.9743  time: 0.3149  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [ 8700/20565]  eta: 1:02:39  lr: 0.000019  loss: 2.7834  time: 0.3125  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [ 8750/20565]  eta: 1:02:23  lr: 0.000019  loss: 3.2905  time: 0.3137  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8800/20565]  eta: 1:02:07  lr: 0.000019  loss: 3.7426  time: 0.3187  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8850/20565]  eta: 1:01:52  lr: 0.000019  loss: 3.1460  time: 0.3201  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8900/20565]  eta: 1:01:36  lr: 0.000019  loss: 4.0075  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 8950/20565]  eta: 1:01:20  lr: 0.000019  loss: 4.5684  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9000/20565]  eta: 1:01:04  lr: 0.000019  loss: 4.4001  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9050/20565]  eta: 1:00:48  lr: 0.000019  loss: 3.3030  time: 0.3181  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9100/20565]  eta: 1:00:32  lr: 0.000019  loss: 2.9595  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9150/20565]  eta: 1:00:16  lr: 0.000019  loss: 3.1656  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9200/20565]  eta: 1:00:00  lr: 0.000019  loss: 3.5243  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9250/20565]  eta: 0:59:44  lr: 0.000019  loss: 3.5642  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9300/20565]  eta: 0:59:28  lr: 0.000019  loss: 2.5341  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9350/20565]  eta: 0:59:12  lr: 0.000019  loss: 3.1702  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9400/20565]  eta: 0:58:57  lr: 0.000019  loss: 2.5114  time: 0.3130  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9450/20565]  eta: 0:58:41  lr: 0.000019  loss: 3.0705  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9500/20565]  eta: 0:58:25  lr: 0.000019  loss: 4.4256  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9550/20565]  eta: 0:58:09  lr: 0.000019  loss: 3.3620  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9600/20565]  eta: 0:57:53  lr: 0.000019  loss: 3.4211  time: 0.3183  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9650/20565]  eta: 0:57:37  lr: 0.000019  loss: 5.3949  time: 0.3183  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9700/20565]  eta: 0:57:21  lr: 0.000019  loss: 2.7697  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9750/20565]  eta: 0:57:06  lr: 0.000019  loss: 4.7077  time: 0.3182  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9800/20565]  eta: 0:56:50  lr: 0.000019  loss: 5.5766  time: 0.3184  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9850/20565]  eta: 0:56:34  lr: 0.000019  loss: 4.1128  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9900/20565]  eta: 0:56:18  lr: 0.000019  loss: 3.6097  time: 0.3186  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [ 9950/20565]  eta: 0:56:02  lr: 0.000019  loss: 4.6145  time: 0.3155  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [10000/20565]  eta: 0:55:46  lr: 0.000019  loss: 3.8764  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10050/20565]  eta: 0:55:30  lr: 0.000019  loss: 2.5150  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10100/20565]  eta: 0:55:14  lr: 0.000019  loss: 3.4027  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10150/20565]  eta: 0:54:58  lr: 0.000019  loss: 3.1140  time: 0.3154  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [10200/20565]  eta: 0:54:43  lr: 0.000019  loss: 3.0355  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10250/20565]  eta: 0:54:27  lr: 0.000019  loss: 2.9334  time: 0.3137  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10300/20565]  eta: 0:54:11  lr: 0.000019  loss: 3.2904  time: 0.3176  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10350/20565]  eta: 0:53:55  lr: 0.000019  loss: 3.9398  time: 0.3175  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10400/20565]  eta: 0:53:39  lr: 0.000019  loss: 3.5083  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10450/20565]  eta: 0:53:23  lr: 0.000019  loss: 3.2246  time: 0.3138  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [10500/20565]  eta: 0:53:07  lr: 0.000019  loss: 3.9247  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10550/20565]  eta: 0:52:51  lr: 0.000019  loss: 3.6698  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10600/20565]  eta: 0:52:36  lr: 0.000019  loss: 3.3407  time: 0.3187  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10650/20565]  eta: 0:52:20  lr: 0.000019  loss: 2.9253  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10700/20565]  eta: 0:52:04  lr: 0.000019  loss: 3.0197  time: 0.3191  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10750/20565]  eta: 0:51:48  lr: 0.000019  loss: 3.3490  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10800/20565]  eta: 0:51:32  lr: 0.000019  loss: 3.0672  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10850/20565]  eta: 0:51:16  lr: 0.000019  loss: 2.5791  time: 0.3179  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10900/20565]  eta: 0:51:01  lr: 0.000019  loss: 3.3024  time: 0.3175  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [10950/20565]  eta: 0:50:45  lr: 0.000019  loss: 3.0836  time: 0.3166  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11000/20565]  eta: 0:50:29  lr: 0.000019  loss: 2.5331  time: 0.3178  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11050/20565]  eta: 0:50:13  lr: 0.000019  loss: 3.3029  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11100/20565]  eta: 0:49:57  lr: 0.000019  loss: 2.7946  time: 0.3189  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11150/20565]  eta: 0:49:41  lr: 0.000019  loss: 3.3354  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11200/20565]  eta: 0:49:26  lr: 0.000019  loss: 3.5305  time: 0.3130  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11250/20565]  eta: 0:49:10  lr: 0.000019  loss: 3.0926  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11300/20565]  eta: 0:48:54  lr: 0.000019  loss: 3.3222  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11350/20565]  eta: 0:48:38  lr: 0.000019  loss: 2.5933  time: 0.3176  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11400/20565]  eta: 0:48:22  lr: 0.000019  loss: 4.0272  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11450/20565]  eta: 0:48:06  lr: 0.000019  loss: 4.1775  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11500/20565]  eta: 0:47:50  lr: 0.000019  loss: 3.7176  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11550/20565]  eta: 0:47:34  lr: 0.000019  loss: 2.4443  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11600/20565]  eta: 0:47:19  lr: 0.000019  loss: 3.0229  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11650/20565]  eta: 0:47:03  lr: 0.000019  loss: 3.2719  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11700/20565]  eta: 0:46:47  lr: 0.000019  loss: 3.9269  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11750/20565]  eta: 0:46:31  lr: 0.000019  loss: 1.6150  time: 0.3132  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11800/20565]  eta: 0:46:15  lr: 0.000019  loss: 2.4158  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11850/20565]  eta: 0:45:59  lr: 0.000019  loss: 3.7286  time: 0.3180  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11900/20565]  eta: 0:45:44  lr: 0.000019  loss: 2.8963  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [11950/20565]  eta: 0:45:28  lr: 0.000019  loss: 3.2350  time: 0.3177  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [12000/20565]  eta: 0:45:12  lr: 0.000019  loss: 2.2377  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12050/20565]  eta: 0:44:56  lr: 0.000019  loss: 2.7819  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12100/20565]  eta: 0:44:40  lr: 0.000019  loss: 4.1224  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12150/20565]  eta: 0:44:24  lr: 0.000019  loss: 2.6352  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12200/20565]  eta: 0:44:08  lr: 0.000019  loss: 2.7373  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12250/20565]  eta: 0:43:53  lr: 0.000019  loss: 3.0465  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12300/20565]  eta: 0:43:37  lr: 0.000019  loss: 3.0743  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12350/20565]  eta: 0:43:21  lr: 0.000019  loss: 2.9522  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12400/20565]  eta: 0:43:05  lr: 0.000019  loss: 2.2627  time: 0.3118  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12450/20565]  eta: 0:42:49  lr: 0.000019  loss: 3.6623  time: 0.3193  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12500/20565]  eta: 0:42:33  lr: 0.000019  loss: 3.0628  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12550/20565]  eta: 0:42:18  lr: 0.000019  loss: 3.1214  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12600/20565]  eta: 0:42:02  lr: 0.000019  loss: 3.1707  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12650/20565]  eta: 0:41:46  lr: 0.000019  loss: 3.6819  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12700/20565]  eta: 0:41:30  lr: 0.000019  loss: 2.7659  time: 0.3134  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12750/20565]  eta: 0:41:14  lr: 0.000019  loss: 3.6133  time: 0.3193  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [12800/20565]  eta: 0:40:58  lr: 0.000019  loss: 4.4943  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12850/20565]  eta: 0:40:43  lr: 0.000019  loss: 4.3781  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12900/20565]  eta: 0:40:27  lr: 0.000019  loss: 3.5468  time: 0.3191  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [12950/20565]  eta: 0:40:11  lr: 0.000019  loss: 4.1395  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13000/20565]  eta: 0:39:55  lr: 0.000019  loss: 3.0297  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13050/20565]  eta: 0:39:39  lr: 0.000019  loss: 3.8807  time: 0.3180  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13100/20565]  eta: 0:39:23  lr: 0.000019  loss: 2.7812  time: 0.3178  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13150/20565]  eta: 0:39:08  lr: 0.000019  loss: 3.7940  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13200/20565]  eta: 0:38:52  lr: 0.000019  loss: 2.8090  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13250/20565]  eta: 0:38:36  lr: 0.000019  loss: 2.2285  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13300/20565]  eta: 0:38:20  lr: 0.000019  loss: 3.7215  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13350/20565]  eta: 0:38:04  lr: 0.000019  loss: 4.6007  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13400/20565]  eta: 0:37:48  lr: 0.000019  loss: 3.2734  time: 0.3203  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13450/20565]  eta: 0:37:32  lr: 0.000019  loss: 3.3645  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13500/20565]  eta: 0:37:17  lr: 0.000019  loss: 4.1125  time: 0.3137  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13550/20565]  eta: 0:37:01  lr: 0.000019  loss: 3.0267  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13600/20565]  eta: 0:36:45  lr: 0.000019  loss: 2.9992  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13650/20565]  eta: 0:36:29  lr: 0.000019  loss: 3.4801  time: 0.3159  data: 0.0003  max mem: 14698\n","Train Epoch: [1]  [13700/20565]  eta: 0:36:13  lr: 0.000019  loss: 3.8766  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13750/20565]  eta: 0:35:57  lr: 0.000019  loss: 2.9821  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13800/20565]  eta: 0:35:42  lr: 0.000019  loss: 2.6735  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13850/20565]  eta: 0:35:26  lr: 0.000019  loss: 2.7912  time: 0.3176  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13900/20565]  eta: 0:35:10  lr: 0.000019  loss: 4.4817  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [13950/20565]  eta: 0:34:54  lr: 0.000019  loss: 3.0741  time: 0.3166  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14000/20565]  eta: 0:34:38  lr: 0.000019  loss: 3.0742  time: 0.3133  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14050/20565]  eta: 0:34:22  lr: 0.000019  loss: 3.1605  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14100/20565]  eta: 0:34:07  lr: 0.000019  loss: 4.6146  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14150/20565]  eta: 0:33:51  lr: 0.000019  loss: 2.8043  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14200/20565]  eta: 0:33:35  lr: 0.000019  loss: 4.2303  time: 0.3175  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14250/20565]  eta: 0:33:19  lr: 0.000019  loss: 2.9623  time: 0.3130  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14300/20565]  eta: 0:33:03  lr: 0.000019  loss: 3.2531  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14350/20565]  eta: 0:32:47  lr: 0.000019  loss: 3.3891  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14400/20565]  eta: 0:32:31  lr: 0.000019  loss: 2.9312  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14450/20565]  eta: 0:32:15  lr: 0.000019  loss: 3.1417  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14500/20565]  eta: 0:32:00  lr: 0.000019  loss: 3.6773  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14550/20565]  eta: 0:31:44  lr: 0.000019  loss: 3.4815  time: 0.3205  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14600/20565]  eta: 0:31:28  lr: 0.000019  loss: 4.0085  time: 0.3123  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14650/20565]  eta: 0:31:12  lr: 0.000019  loss: 2.6307  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14700/20565]  eta: 0:30:56  lr: 0.000019  loss: 3.9098  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14750/20565]  eta: 0:30:40  lr: 0.000019  loss: 2.7022  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14800/20565]  eta: 0:30:24  lr: 0.000019  loss: 4.0240  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14850/20565]  eta: 0:30:09  lr: 0.000019  loss: 2.4647  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14900/20565]  eta: 0:29:53  lr: 0.000019  loss: 3.7634  time: 0.3122  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [14950/20565]  eta: 0:29:37  lr: 0.000019  loss: 2.7624  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15000/20565]  eta: 0:29:21  lr: 0.000019  loss: 3.6753  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15050/20565]  eta: 0:29:05  lr: 0.000019  loss: 2.6834  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15100/20565]  eta: 0:28:49  lr: 0.000019  loss: 3.6398  time: 0.3133  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15150/20565]  eta: 0:28:34  lr: 0.000019  loss: 3.2225  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15200/20565]  eta: 0:28:18  lr: 0.000019  loss: 2.7096  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15250/20565]  eta: 0:28:02  lr: 0.000019  loss: 3.5934  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15300/20565]  eta: 0:27:46  lr: 0.000019  loss: 3.7434  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15350/20565]  eta: 0:27:30  lr: 0.000019  loss: 4.4015  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15400/20565]  eta: 0:27:14  lr: 0.000019  loss: 3.8174  time: 0.3169  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15450/20565]  eta: 0:26:59  lr: 0.000019  loss: 3.4394  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15500/20565]  eta: 0:26:43  lr: 0.000019  loss: 3.7147  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15550/20565]  eta: 0:26:27  lr: 0.000019  loss: 3.7130  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15600/20565]  eta: 0:26:11  lr: 0.000019  loss: 5.0236  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15650/20565]  eta: 0:25:55  lr: 0.000019  loss: 2.5062  time: 0.3137  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15700/20565]  eta: 0:25:39  lr: 0.000019  loss: 3.2526  time: 0.3178  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15750/20565]  eta: 0:25:23  lr: 0.000019  loss: 3.2148  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15800/20565]  eta: 0:25:08  lr: 0.000019  loss: 3.6046  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15850/20565]  eta: 0:24:52  lr: 0.000019  loss: 2.3137  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15900/20565]  eta: 0:24:36  lr: 0.000019  loss: 3.2823  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [15950/20565]  eta: 0:24:20  lr: 0.000019  loss: 3.8601  time: 0.3183  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16000/20565]  eta: 0:24:04  lr: 0.000019  loss: 3.4497  time: 0.3186  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16050/20565]  eta: 0:23:49  lr: 0.000019  loss: 3.2882  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16100/20565]  eta: 0:23:33  lr: 0.000019  loss: 3.0651  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16150/20565]  eta: 0:23:17  lr: 0.000019  loss: 3.7201  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16200/20565]  eta: 0:23:01  lr: 0.000019  loss: 2.2816  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16250/20565]  eta: 0:22:45  lr: 0.000019  loss: 2.8610  time: 0.3181  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16300/20565]  eta: 0:22:29  lr: 0.000019  loss: 3.5513  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16350/20565]  eta: 0:22:14  lr: 0.000019  loss: 3.5593  time: 0.3183  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16400/20565]  eta: 0:21:58  lr: 0.000019  loss: 3.0489  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16450/20565]  eta: 0:21:42  lr: 0.000019  loss: 4.0225  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16500/20565]  eta: 0:21:26  lr: 0.000019  loss: 3.4957  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16550/20565]  eta: 0:21:10  lr: 0.000019  loss: 3.1693  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16600/20565]  eta: 0:20:54  lr: 0.000019  loss: 2.7804  time: 0.3126  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16650/20565]  eta: 0:20:38  lr: 0.000019  loss: 2.5180  time: 0.3122  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16700/20565]  eta: 0:20:23  lr: 0.000019  loss: 3.1127  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16750/20565]  eta: 0:20:07  lr: 0.000019  loss: 2.8817  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16800/20565]  eta: 0:19:51  lr: 0.000019  loss: 3.2206  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16850/20565]  eta: 0:19:35  lr: 0.000019  loss: 3.6566  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16900/20565]  eta: 0:19:19  lr: 0.000019  loss: 3.2311  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [16950/20565]  eta: 0:19:04  lr: 0.000019  loss: 3.2789  time: 0.3183  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17000/20565]  eta: 0:18:48  lr: 0.000019  loss: 3.2259  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17050/20565]  eta: 0:18:32  lr: 0.000019  loss: 2.7420  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17100/20565]  eta: 0:18:16  lr: 0.000019  loss: 3.7093  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17150/20565]  eta: 0:18:00  lr: 0.000019  loss: 3.7188  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17200/20565]  eta: 0:17:44  lr: 0.000019  loss: 3.9528  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17250/20565]  eta: 0:17:29  lr: 0.000019  loss: 2.8157  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17300/20565]  eta: 0:17:13  lr: 0.000019  loss: 2.7915  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17350/20565]  eta: 0:16:57  lr: 0.000019  loss: 3.2443  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17400/20565]  eta: 0:16:41  lr: 0.000019  loss: 3.7364  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17450/20565]  eta: 0:16:25  lr: 0.000019  loss: 3.6916  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17500/20565]  eta: 0:16:09  lr: 0.000019  loss: 3.3393  time: 0.3119  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17550/20565]  eta: 0:15:54  lr: 0.000019  loss: 3.6401  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17600/20565]  eta: 0:15:38  lr: 0.000019  loss: 3.6635  time: 0.3179  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17650/20565]  eta: 0:15:22  lr: 0.000019  loss: 3.4656  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17700/20565]  eta: 0:15:06  lr: 0.000019  loss: 2.7466  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17750/20565]  eta: 0:14:50  lr: 0.000019  loss: 3.4072  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17800/20565]  eta: 0:14:34  lr: 0.000019  loss: 3.9240  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17850/20565]  eta: 0:14:19  lr: 0.000019  loss: 3.0111  time: 0.3131  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17900/20565]  eta: 0:14:03  lr: 0.000019  loss: 3.1944  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [17950/20565]  eta: 0:13:47  lr: 0.000019  loss: 3.3053  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18000/20565]  eta: 0:13:31  lr: 0.000019  loss: 3.4829  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18050/20565]  eta: 0:13:15  lr: 0.000019  loss: 2.5095  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18100/20565]  eta: 0:12:59  lr: 0.000019  loss: 3.2245  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18150/20565]  eta: 0:12:44  lr: 0.000019  loss: 4.3556  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18200/20565]  eta: 0:12:28  lr: 0.000019  loss: 3.3279  time: 0.3179  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18250/20565]  eta: 0:12:12  lr: 0.000019  loss: 3.8195  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18300/20565]  eta: 0:11:56  lr: 0.000019  loss: 2.2373  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18350/20565]  eta: 0:11:40  lr: 0.000019  loss: 2.7326  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18400/20565]  eta: 0:11:24  lr: 0.000019  loss: 3.7807  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18450/20565]  eta: 0:11:09  lr: 0.000019  loss: 3.8726  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18500/20565]  eta: 0:10:53  lr: 0.000019  loss: 3.4400  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18550/20565]  eta: 0:10:37  lr: 0.000019  loss: 2.8276  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18600/20565]  eta: 0:10:21  lr: 0.000019  loss: 4.7805  time: 0.3192  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18650/20565]  eta: 0:10:05  lr: 0.000019  loss: 2.5105  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18700/20565]  eta: 0:09:50  lr: 0.000019  loss: 3.6898  time: 0.3181  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18750/20565]  eta: 0:09:34  lr: 0.000019  loss: 4.1234  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18800/20565]  eta: 0:09:18  lr: 0.000019  loss: 3.1898  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18850/20565]  eta: 0:09:02  lr: 0.000019  loss: 2.5622  time: 0.3193  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18900/20565]  eta: 0:08:46  lr: 0.000019  loss: 3.5427  time: 0.3120  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [18950/20565]  eta: 0:08:30  lr: 0.000019  loss: 3.3691  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19000/20565]  eta: 0:08:15  lr: 0.000019  loss: 2.7516  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19050/20565]  eta: 0:07:59  lr: 0.000019  loss: 3.4388  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19100/20565]  eta: 0:07:43  lr: 0.000019  loss: 2.5091  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19150/20565]  eta: 0:07:27  lr: 0.000019  loss: 2.7390  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19200/20565]  eta: 0:07:11  lr: 0.000019  loss: 3.8180  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19250/20565]  eta: 0:06:55  lr: 0.000019  loss: 2.8816  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19300/20565]  eta: 0:06:40  lr: 0.000019  loss: 3.0073  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19350/20565]  eta: 0:06:24  lr: 0.000019  loss: 4.4945  time: 0.3167  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19400/20565]  eta: 0:06:08  lr: 0.000019  loss: 3.5910  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19450/20565]  eta: 0:05:52  lr: 0.000019  loss: 2.9793  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19500/20565]  eta: 0:05:36  lr: 0.000019  loss: 4.5687  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19550/20565]  eta: 0:05:21  lr: 0.000019  loss: 3.7427  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19600/20565]  eta: 0:05:05  lr: 0.000019  loss: 2.5296  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19650/20565]  eta: 0:04:49  lr: 0.000019  loss: 4.1801  time: 0.3118  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19700/20565]  eta: 0:04:33  lr: 0.000019  loss: 3.4360  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19750/20565]  eta: 0:04:17  lr: 0.000019  loss: 2.6084  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19800/20565]  eta: 0:04:01  lr: 0.000019  loss: 3.9038  time: 0.3204  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19850/20565]  eta: 0:03:46  lr: 0.000019  loss: 2.6228  time: 0.3118  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19900/20565]  eta: 0:03:30  lr: 0.000019  loss: 2.8916  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [19950/20565]  eta: 0:03:14  lr: 0.000019  loss: 3.9975  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20000/20565]  eta: 0:02:58  lr: 0.000019  loss: 2.9660  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20050/20565]  eta: 0:02:42  lr: 0.000019  loss: 2.8680  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20100/20565]  eta: 0:02:27  lr: 0.000019  loss: 4.1522  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20150/20565]  eta: 0:02:11  lr: 0.000019  loss: 3.8692  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20200/20565]  eta: 0:01:55  lr: 0.000019  loss: 3.2374  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20250/20565]  eta: 0:01:39  lr: 0.000019  loss: 2.8002  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20300/20565]  eta: 0:01:23  lr: 0.000019  loss: 3.3260  time: 0.3183  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20350/20565]  eta: 0:01:07  lr: 0.000019  loss: 2.6337  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20400/20565]  eta: 0:00:52  lr: 0.000019  loss: 3.3289  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20450/20565]  eta: 0:00:36  lr: 0.000019  loss: 2.9835  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20500/20565]  eta: 0:00:20  lr: 0.000019  loss: 3.7103  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20550/20565]  eta: 0:00:04  lr: 0.000019  loss: 3.9003  time: 0.3184  data: 0.0002  max mem: 14698\n","Train Epoch: [1]  [20564/20565]  eta: 0:00:00  lr: 0.000019  loss: 2.4203  time: 0.3183  data: 0.0025  max mem: 14698\n","Train Epoch: [1] Total time: 1:48:24 (0.3163 s / it)\n","Averaged stats: lr: 0.0000  loss: 3.4089\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"metadata":{"tags":null},"name":"stdout","output_type":"stream","text":["Train Epoch: [2]  [    0/20565]  eta: 8:18:44  lr: 0.000017  loss: 3.5431  time: 1.4551  data: 1.0996  max mem: 14698\n"]},{"metadata":{"tags":null},"name":"stderr","output_type":"stream","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [2]  [   50/20565]  eta: 1:56:13  lr: 0.000017  loss: 3.5246  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  100/20565]  eta: 1:51:59  lr: 0.000017  loss: 3.8082  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  150/20565]  eta: 1:49:59  lr: 0.000017  loss: 3.5631  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  200/20565]  eta: 1:49:07  lr: 0.000017  loss: 3.1120  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  250/20565]  eta: 1:48:17  lr: 0.000017  loss: 3.3682  time: 0.3119  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  300/20565]  eta: 1:47:42  lr: 0.000017  loss: 3.5582  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  350/20565]  eta: 1:47:14  lr: 0.000017  loss: 4.6747  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  400/20565]  eta: 1:46:48  lr: 0.000017  loss: 2.6109  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  450/20565]  eta: 1:46:22  lr: 0.000017  loss: 3.7168  time: 0.3137  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  500/20565]  eta: 1:46:05  lr: 0.000017  loss: 4.4896  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  550/20565]  eta: 1:45:46  lr: 0.000017  loss: 2.7817  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  600/20565]  eta: 1:45:26  lr: 0.000017  loss: 3.5997  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  650/20565]  eta: 1:45:05  lr: 0.000017  loss: 2.6697  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  700/20565]  eta: 1:44:47  lr: 0.000017  loss: 3.7796  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  750/20565]  eta: 1:44:29  lr: 0.000017  loss: 2.8551  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  800/20565]  eta: 1:44:14  lr: 0.000017  loss: 3.0166  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  850/20565]  eta: 1:43:56  lr: 0.000017  loss: 2.4105  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  900/20565]  eta: 1:43:36  lr: 0.000017  loss: 3.6241  time: 0.3117  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [  950/20565]  eta: 1:43:19  lr: 0.000017  loss: 3.1517  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1000/20565]  eta: 1:43:03  lr: 0.000017  loss: 3.5139  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1050/20565]  eta: 1:42:48  lr: 0.000017  loss: 2.9354  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1100/20565]  eta: 1:42:31  lr: 0.000017  loss: 3.2707  time: 0.3194  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1150/20565]  eta: 1:42:15  lr: 0.000017  loss: 3.6339  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1200/20565]  eta: 1:41:57  lr: 0.000017  loss: 3.5441  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1250/20565]  eta: 1:41:39  lr: 0.000017  loss: 2.6784  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1300/20565]  eta: 1:41:23  lr: 0.000017  loss: 2.9684  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1350/20565]  eta: 1:41:07  lr: 0.000017  loss: 3.4059  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1400/20565]  eta: 1:40:50  lr: 0.000017  loss: 2.6017  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1450/20565]  eta: 1:40:33  lr: 0.000017  loss: 3.9697  time: 0.3120  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1500/20565]  eta: 1:40:17  lr: 0.000017  loss: 3.6838  time: 0.3131  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1550/20565]  eta: 1:40:02  lr: 0.000017  loss: 3.1152  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1600/20565]  eta: 1:39:46  lr: 0.000017  loss: 3.6329  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1650/20565]  eta: 1:39:30  lr: 0.000017  loss: 2.0641  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1700/20565]  eta: 1:39:13  lr: 0.000017  loss: 3.2402  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1750/20565]  eta: 1:38:57  lr: 0.000017  loss: 3.2365  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1800/20565]  eta: 1:38:42  lr: 0.000017  loss: 3.0238  time: 0.3186  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1850/20565]  eta: 1:38:26  lr: 0.000017  loss: 3.4754  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1900/20565]  eta: 1:38:09  lr: 0.000017  loss: 3.9524  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 1950/20565]  eta: 1:37:54  lr: 0.000017  loss: 2.5839  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2000/20565]  eta: 1:37:37  lr: 0.000017  loss: 2.8147  time: 0.3127  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2050/20565]  eta: 1:37:22  lr: 0.000017  loss: 3.2442  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2100/20565]  eta: 1:37:06  lr: 0.000017  loss: 3.0586  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2150/20565]  eta: 1:36:49  lr: 0.000017  loss: 2.6176  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2200/20565]  eta: 1:36:33  lr: 0.000017  loss: 2.8651  time: 0.3169  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2250/20565]  eta: 1:36:17  lr: 0.000017  loss: 3.3179  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2300/20565]  eta: 1:36:01  lr: 0.000017  loss: 3.8317  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2350/20565]  eta: 1:35:46  lr: 0.000017  loss: 3.6004  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2400/20565]  eta: 1:35:30  lr: 0.000017  loss: 4.8883  time: 0.3182  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2450/20565]  eta: 1:35:14  lr: 0.000017  loss: 2.5904  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2500/20565]  eta: 1:34:58  lr: 0.000017  loss: 2.0634  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2550/20565]  eta: 1:34:43  lr: 0.000017  loss: 4.2000  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2600/20565]  eta: 1:34:27  lr: 0.000017  loss: 3.2220  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2650/20565]  eta: 1:34:11  lr: 0.000017  loss: 3.9479  time: 0.3131  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2700/20565]  eta: 1:33:56  lr: 0.000017  loss: 2.9172  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2750/20565]  eta: 1:33:40  lr: 0.000017  loss: 3.8588  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2800/20565]  eta: 1:33:24  lr: 0.000017  loss: 3.6881  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2850/20565]  eta: 1:33:08  lr: 0.000017  loss: 2.5319  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2900/20565]  eta: 1:32:52  lr: 0.000017  loss: 3.4971  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 2950/20565]  eta: 1:32:36  lr: 0.000017  loss: 2.6045  time: 0.3134  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3000/20565]  eta: 1:32:20  lr: 0.000017  loss: 2.9773  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3050/20565]  eta: 1:32:04  lr: 0.000017  loss: 3.7765  time: 0.3124  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3100/20565]  eta: 1:31:48  lr: 0.000017  loss: 2.5097  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3150/20565]  eta: 1:31:32  lr: 0.000017  loss: 4.7617  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3200/20565]  eta: 1:31:17  lr: 0.000017  loss: 2.9161  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3250/20565]  eta: 1:31:01  lr: 0.000017  loss: 2.9657  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3300/20565]  eta: 1:30:45  lr: 0.000017  loss: 3.6976  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3350/20565]  eta: 1:30:29  lr: 0.000017  loss: 3.1134  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3400/20565]  eta: 1:30:14  lr: 0.000017  loss: 3.7136  time: 0.3179  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3450/20565]  eta: 1:29:58  lr: 0.000017  loss: 2.7995  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3500/20565]  eta: 1:29:42  lr: 0.000017  loss: 3.6225  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3550/20565]  eta: 1:29:26  lr: 0.000017  loss: 3.0203  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3600/20565]  eta: 1:29:10  lr: 0.000017  loss: 3.9476  time: 0.3132  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3650/20565]  eta: 1:28:55  lr: 0.000017  loss: 4.2623  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3700/20565]  eta: 1:28:39  lr: 0.000017  loss: 3.5611  time: 0.3166  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3750/20565]  eta: 1:28:24  lr: 0.000017  loss: 3.4561  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3800/20565]  eta: 1:28:08  lr: 0.000017  loss: 3.1595  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3850/20565]  eta: 1:27:52  lr: 0.000017  loss: 3.6439  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3900/20565]  eta: 1:27:37  lr: 0.000017  loss: 3.5497  time: 0.3169  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 3950/20565]  eta: 1:27:21  lr: 0.000017  loss: 3.5098  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4000/20565]  eta: 1:27:05  lr: 0.000017  loss: 2.4769  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4050/20565]  eta: 1:26:49  lr: 0.000017  loss: 4.1488  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4100/20565]  eta: 1:26:33  lr: 0.000017  loss: 3.4403  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4150/20565]  eta: 1:26:18  lr: 0.000017  loss: 4.3645  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4200/20565]  eta: 1:26:02  lr: 0.000017  loss: 3.2721  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4250/20565]  eta: 1:25:46  lr: 0.000017  loss: 3.3899  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4300/20565]  eta: 1:25:30  lr: 0.000017  loss: 3.4575  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4350/20565]  eta: 1:25:15  lr: 0.000017  loss: 3.9052  time: 0.3127  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4400/20565]  eta: 1:24:59  lr: 0.000017  loss: 3.5929  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4450/20565]  eta: 1:24:44  lr: 0.000017  loss: 3.0792  time: 0.3176  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4500/20565]  eta: 1:24:28  lr: 0.000017  loss: 4.4423  time: 0.3134  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4550/20565]  eta: 1:24:12  lr: 0.000017  loss: 2.8354  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4600/20565]  eta: 1:23:56  lr: 0.000017  loss: 2.9419  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4650/20565]  eta: 1:23:41  lr: 0.000017  loss: 1.9862  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4700/20565]  eta: 1:23:25  lr: 0.000017  loss: 3.8784  time: 0.3185  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4750/20565]  eta: 1:23:09  lr: 0.000017  loss: 3.6195  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4800/20565]  eta: 1:22:53  lr: 0.000017  loss: 2.6973  time: 0.3137  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4850/20565]  eta: 1:22:38  lr: 0.000017  loss: 3.3831  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4900/20565]  eta: 1:22:22  lr: 0.000017  loss: 3.6998  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 4950/20565]  eta: 1:22:06  lr: 0.000017  loss: 4.5037  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5000/20565]  eta: 1:21:50  lr: 0.000017  loss: 4.6647  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5050/20565]  eta: 1:21:34  lr: 0.000017  loss: 3.9648  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5100/20565]  eta: 1:21:19  lr: 0.000017  loss: 3.0337  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5150/20565]  eta: 1:21:03  lr: 0.000017  loss: 3.6975  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5200/20565]  eta: 1:20:47  lr: 0.000017  loss: 3.1222  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5250/20565]  eta: 1:20:31  lr: 0.000017  loss: 3.9204  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5300/20565]  eta: 1:20:15  lr: 0.000017  loss: 2.8937  time: 0.3137  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5350/20565]  eta: 1:20:00  lr: 0.000017  loss: 2.6342  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5400/20565]  eta: 1:19:44  lr: 0.000017  loss: 3.3809  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5450/20565]  eta: 1:19:28  lr: 0.000017  loss: 3.2074  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5500/20565]  eta: 1:19:12  lr: 0.000017  loss: 2.6452  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5550/20565]  eta: 1:18:57  lr: 0.000017  loss: 3.3223  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5600/20565]  eta: 1:18:41  lr: 0.000017  loss: 3.3295  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5650/20565]  eta: 1:18:25  lr: 0.000017  loss: 3.0389  time: 0.3120  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5700/20565]  eta: 1:18:09  lr: 0.000017  loss: 3.6411  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5750/20565]  eta: 1:17:54  lr: 0.000017  loss: 3.3919  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5800/20565]  eta: 1:17:38  lr: 0.000017  loss: 3.4396  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5850/20565]  eta: 1:17:22  lr: 0.000017  loss: 3.0892  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5900/20565]  eta: 1:17:06  lr: 0.000017  loss: 2.6926  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 5950/20565]  eta: 1:16:50  lr: 0.000017  loss: 3.2477  time: 0.3133  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6000/20565]  eta: 1:16:35  lr: 0.000017  loss: 2.1093  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6050/20565]  eta: 1:16:19  lr: 0.000017  loss: 3.3044  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6100/20565]  eta: 1:16:03  lr: 0.000017  loss: 3.5715  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6150/20565]  eta: 1:15:47  lr: 0.000017  loss: 2.0617  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6200/20565]  eta: 1:15:31  lr: 0.000017  loss: 2.9728  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6250/20565]  eta: 1:15:15  lr: 0.000017  loss: 3.7354  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6300/20565]  eta: 1:15:00  lr: 0.000017  loss: 3.1746  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6350/20565]  eta: 1:14:44  lr: 0.000017  loss: 3.8160  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6400/20565]  eta: 1:14:28  lr: 0.000017  loss: 2.9983  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6450/20565]  eta: 1:14:12  lr: 0.000017  loss: 2.4134  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6500/20565]  eta: 1:13:56  lr: 0.000017  loss: 3.3081  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6550/20565]  eta: 1:13:41  lr: 0.000017  loss: 2.6605  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6600/20565]  eta: 1:13:25  lr: 0.000017  loss: 2.9207  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6650/20565]  eta: 1:13:09  lr: 0.000017  loss: 2.6375  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6700/20565]  eta: 1:12:54  lr: 0.000017  loss: 3.9434  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6750/20565]  eta: 1:12:38  lr: 0.000017  loss: 2.1597  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6800/20565]  eta: 1:12:22  lr: 0.000017  loss: 2.6000  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6850/20565]  eta: 1:12:06  lr: 0.000017  loss: 2.9037  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6900/20565]  eta: 1:11:50  lr: 0.000017  loss: 4.5628  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 6950/20565]  eta: 1:11:35  lr: 0.000017  loss: 3.7039  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7000/20565]  eta: 1:11:19  lr: 0.000017  loss: 3.0977  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7050/20565]  eta: 1:11:03  lr: 0.000017  loss: 3.4050  time: 0.3124  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7100/20565]  eta: 1:10:47  lr: 0.000017  loss: 3.1940  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7150/20565]  eta: 1:10:31  lr: 0.000017  loss: 3.0109  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7200/20565]  eta: 1:10:16  lr: 0.000017  loss: 2.6832  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7250/20565]  eta: 1:10:00  lr: 0.000017  loss: 4.1634  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7300/20565]  eta: 1:09:44  lr: 0.000017  loss: 3.7923  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7350/20565]  eta: 1:09:28  lr: 0.000017  loss: 3.4238  time: 0.3188  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7400/20565]  eta: 1:09:12  lr: 0.000017  loss: 3.2039  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7450/20565]  eta: 1:08:57  lr: 0.000017  loss: 3.3137  time: 0.3130  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7500/20565]  eta: 1:08:41  lr: 0.000017  loss: 3.9847  time: 0.3169  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7550/20565]  eta: 1:08:25  lr: 0.000017  loss: 2.2052  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7600/20565]  eta: 1:08:09  lr: 0.000017  loss: 3.7660  time: 0.3185  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7650/20565]  eta: 1:07:54  lr: 0.000017  loss: 3.3036  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7700/20565]  eta: 1:07:38  lr: 0.000017  loss: 3.0098  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7750/20565]  eta: 1:07:22  lr: 0.000017  loss: 3.2284  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7800/20565]  eta: 1:07:06  lr: 0.000017  loss: 2.7574  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7850/20565]  eta: 1:06:50  lr: 0.000017  loss: 3.4409  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7900/20565]  eta: 1:06:35  lr: 0.000017  loss: 3.7278  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 7950/20565]  eta: 1:06:19  lr: 0.000017  loss: 2.8027  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8000/20565]  eta: 1:06:03  lr: 0.000017  loss: 4.1809  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8050/20565]  eta: 1:05:47  lr: 0.000017  loss: 2.7109  time: 0.3166  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8100/20565]  eta: 1:05:32  lr: 0.000017  loss: 4.4527  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8150/20565]  eta: 1:05:16  lr: 0.000017  loss: 4.8367  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8200/20565]  eta: 1:05:00  lr: 0.000017  loss: 3.0801  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8250/20565]  eta: 1:04:44  lr: 0.000017  loss: 2.2821  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8300/20565]  eta: 1:04:29  lr: 0.000017  loss: 3.8376  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8350/20565]  eta: 1:04:13  lr: 0.000017  loss: 3.3487  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8400/20565]  eta: 1:03:57  lr: 0.000017  loss: 2.6626  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8450/20565]  eta: 1:03:41  lr: 0.000017  loss: 2.8286  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8500/20565]  eta: 1:03:26  lr: 0.000017  loss: 3.5686  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8550/20565]  eta: 1:03:10  lr: 0.000017  loss: 3.7097  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8600/20565]  eta: 1:02:54  lr: 0.000017  loss: 2.6725  time: 0.3184  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8650/20565]  eta: 1:02:38  lr: 0.000017  loss: 2.7216  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8700/20565]  eta: 1:02:23  lr: 0.000017  loss: 4.0678  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8750/20565]  eta: 1:02:07  lr: 0.000017  loss: 3.3475  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8800/20565]  eta: 1:01:51  lr: 0.000017  loss: 3.0182  time: 0.3184  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8850/20565]  eta: 1:01:35  lr: 0.000017  loss: 3.1966  time: 0.3122  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8900/20565]  eta: 1:01:19  lr: 0.000017  loss: 2.6858  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 8950/20565]  eta: 1:01:04  lr: 0.000017  loss: 3.1448  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9000/20565]  eta: 1:00:48  lr: 0.000017  loss: 3.0396  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9050/20565]  eta: 1:00:32  lr: 0.000017  loss: 4.7550  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9100/20565]  eta: 1:00:16  lr: 0.000017  loss: 3.3272  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9150/20565]  eta: 1:00:01  lr: 0.000017  loss: 3.8358  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9200/20565]  eta: 0:59:45  lr: 0.000017  loss: 3.4488  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9250/20565]  eta: 0:59:29  lr: 0.000017  loss: 3.6452  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9300/20565]  eta: 0:59:14  lr: 0.000017  loss: 4.2190  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9350/20565]  eta: 0:58:58  lr: 0.000017  loss: 3.5527  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9400/20565]  eta: 0:58:42  lr: 0.000017  loss: 3.4349  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9450/20565]  eta: 0:58:26  lr: 0.000017  loss: 3.9504  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9500/20565]  eta: 0:58:10  lr: 0.000017  loss: 3.2956  time: 0.3131  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9550/20565]  eta: 0:57:55  lr: 0.000017  loss: 2.9587  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9600/20565]  eta: 0:57:39  lr: 0.000017  loss: 3.0025  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9650/20565]  eta: 0:57:23  lr: 0.000017  loss: 3.1024  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9700/20565]  eta: 0:57:07  lr: 0.000017  loss: 3.6111  time: 0.3179  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9750/20565]  eta: 0:56:52  lr: 0.000017  loss: 3.0977  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9800/20565]  eta: 0:56:36  lr: 0.000017  loss: 3.3071  time: 0.3183  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9850/20565]  eta: 0:56:20  lr: 0.000017  loss: 2.6195  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9900/20565]  eta: 0:56:04  lr: 0.000017  loss: 3.3235  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [ 9950/20565]  eta: 0:55:48  lr: 0.000017  loss: 3.8000  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10000/20565]  eta: 0:55:33  lr: 0.000017  loss: 2.8704  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10050/20565]  eta: 0:55:17  lr: 0.000017  loss: 3.2039  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10100/20565]  eta: 0:55:01  lr: 0.000017  loss: 4.1985  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10150/20565]  eta: 0:54:45  lr: 0.000017  loss: 4.0207  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10200/20565]  eta: 0:54:29  lr: 0.000017  loss: 3.3674  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10250/20565]  eta: 0:54:14  lr: 0.000017  loss: 2.8939  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10300/20565]  eta: 0:53:58  lr: 0.000017  loss: 4.3353  time: 0.3188  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10350/20565]  eta: 0:53:42  lr: 0.000017  loss: 2.8185  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10400/20565]  eta: 0:53:26  lr: 0.000017  loss: 3.5650  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10450/20565]  eta: 0:53:11  lr: 0.000017  loss: 3.0320  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10500/20565]  eta: 0:52:55  lr: 0.000017  loss: 3.0336  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10550/20565]  eta: 0:52:39  lr: 0.000017  loss: 4.1466  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10600/20565]  eta: 0:52:23  lr: 0.000017  loss: 3.2861  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10650/20565]  eta: 0:52:07  lr: 0.000017  loss: 3.3657  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10700/20565]  eta: 0:51:52  lr: 0.000017  loss: 3.9450  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10750/20565]  eta: 0:51:36  lr: 0.000017  loss: 2.7440  time: 0.3176  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10800/20565]  eta: 0:51:20  lr: 0.000017  loss: 2.9563  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10850/20565]  eta: 0:51:04  lr: 0.000017  loss: 2.7284  time: 0.3166  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10900/20565]  eta: 0:50:48  lr: 0.000017  loss: 3.7236  time: 0.3195  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [10950/20565]  eta: 0:50:33  lr: 0.000017  loss: 2.9228  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11000/20565]  eta: 0:50:17  lr: 0.000017  loss: 3.1910  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11050/20565]  eta: 0:50:01  lr: 0.000017  loss: 2.1244  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11100/20565]  eta: 0:49:45  lr: 0.000017  loss: 4.0690  time: 0.3137  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11150/20565]  eta: 0:49:30  lr: 0.000017  loss: 2.6312  time: 0.3169  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11200/20565]  eta: 0:49:14  lr: 0.000017  loss: 2.3436  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11250/20565]  eta: 0:48:58  lr: 0.000017  loss: 2.3513  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11300/20565]  eta: 0:48:42  lr: 0.000017  loss: 2.9693  time: 0.3166  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11350/20565]  eta: 0:48:26  lr: 0.000017  loss: 3.6107  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11400/20565]  eta: 0:48:11  lr: 0.000017  loss: 3.6138  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11450/20565]  eta: 0:47:55  lr: 0.000017  loss: 3.1992  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11500/20565]  eta: 0:47:39  lr: 0.000017  loss: 2.4969  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11550/20565]  eta: 0:47:23  lr: 0.000017  loss: 2.6223  time: 0.3175  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11600/20565]  eta: 0:47:08  lr: 0.000017  loss: 3.6933  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11650/20565]  eta: 0:46:52  lr: 0.000017  loss: 1.9110  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11700/20565]  eta: 0:46:36  lr: 0.000017  loss: 4.5473  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11750/20565]  eta: 0:46:20  lr: 0.000017  loss: 3.3231  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11800/20565]  eta: 0:46:05  lr: 0.000017  loss: 2.8184  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11850/20565]  eta: 0:45:49  lr: 0.000017  loss: 3.7466  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11900/20565]  eta: 0:45:33  lr: 0.000017  loss: 3.6039  time: 0.3179  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [11950/20565]  eta: 0:45:17  lr: 0.000017  loss: 3.6031  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12000/20565]  eta: 0:45:01  lr: 0.000017  loss: 3.1884  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12050/20565]  eta: 0:44:46  lr: 0.000017  loss: 3.6689  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12100/20565]  eta: 0:44:30  lr: 0.000017  loss: 2.7071  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12150/20565]  eta: 0:44:14  lr: 0.000017  loss: 3.9377  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12200/20565]  eta: 0:43:58  lr: 0.000017  loss: 3.5257  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12250/20565]  eta: 0:43:43  lr: 0.000017  loss: 4.5122  time: 0.3169  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12300/20565]  eta: 0:43:27  lr: 0.000017  loss: 3.2978  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12350/20565]  eta: 0:43:11  lr: 0.000017  loss: 2.8462  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12400/20565]  eta: 0:42:55  lr: 0.000017  loss: 2.8221  time: 0.3124  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12450/20565]  eta: 0:42:39  lr: 0.000017  loss: 3.8113  time: 0.3120  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12500/20565]  eta: 0:42:24  lr: 0.000017  loss: 3.3963  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12550/20565]  eta: 0:42:08  lr: 0.000017  loss: 3.4958  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12600/20565]  eta: 0:41:52  lr: 0.000017  loss: 2.7128  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12650/20565]  eta: 0:41:36  lr: 0.000017  loss: 2.8964  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12700/20565]  eta: 0:41:20  lr: 0.000017  loss: 2.8427  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12750/20565]  eta: 0:41:05  lr: 0.000017  loss: 3.1627  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12800/20565]  eta: 0:40:49  lr: 0.000017  loss: 2.7681  time: 0.3142  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12850/20565]  eta: 0:40:33  lr: 0.000017  loss: 4.0561  time: 0.3185  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12900/20565]  eta: 0:40:17  lr: 0.000017  loss: 2.2786  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [12950/20565]  eta: 0:40:02  lr: 0.000017  loss: 3.8035  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13000/20565]  eta: 0:39:46  lr: 0.000017  loss: 2.9906  time: 0.3133  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13050/20565]  eta: 0:39:30  lr: 0.000017  loss: 3.4647  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13100/20565]  eta: 0:39:14  lr: 0.000017  loss: 5.7532  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13150/20565]  eta: 0:38:59  lr: 0.000017  loss: 2.9842  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13200/20565]  eta: 0:38:43  lr: 0.000017  loss: 2.6785  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13250/20565]  eta: 0:38:27  lr: 0.000017  loss: 3.4135  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13300/20565]  eta: 0:38:11  lr: 0.000017  loss: 2.5594  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13350/20565]  eta: 0:37:56  lr: 0.000017  loss: 2.7369  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13400/20565]  eta: 0:37:40  lr: 0.000017  loss: 3.2338  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13450/20565]  eta: 0:37:24  lr: 0.000017  loss: 2.6913  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13500/20565]  eta: 0:37:08  lr: 0.000017  loss: 3.0053  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13550/20565]  eta: 0:36:52  lr: 0.000017  loss: 3.4669  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13600/20565]  eta: 0:36:37  lr: 0.000017  loss: 2.6183  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13650/20565]  eta: 0:36:21  lr: 0.000017  loss: 2.8411  time: 0.3186  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13700/20565]  eta: 0:36:05  lr: 0.000017  loss: 2.6719  time: 0.3118  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13750/20565]  eta: 0:35:49  lr: 0.000017  loss: 3.8339  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13800/20565]  eta: 0:35:34  lr: 0.000017  loss: 2.4738  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13850/20565]  eta: 0:35:18  lr: 0.000017  loss: 2.9174  time: 0.3199  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13900/20565]  eta: 0:35:02  lr: 0.000017  loss: 2.5610  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [13950/20565]  eta: 0:34:46  lr: 0.000017  loss: 5.0776  time: 0.3176  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14000/20565]  eta: 0:34:31  lr: 0.000017  loss: 3.7050  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14050/20565]  eta: 0:34:15  lr: 0.000017  loss: 3.5091  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14100/20565]  eta: 0:33:59  lr: 0.000017  loss: 2.3372  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14150/20565]  eta: 0:33:43  lr: 0.000017  loss: 3.0392  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14200/20565]  eta: 0:33:27  lr: 0.000017  loss: 2.9005  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14250/20565]  eta: 0:33:12  lr: 0.000017  loss: 3.3167  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14300/20565]  eta: 0:32:56  lr: 0.000017  loss: 2.5925  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14350/20565]  eta: 0:32:40  lr: 0.000017  loss: 4.1615  time: 0.3176  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14400/20565]  eta: 0:32:24  lr: 0.000017  loss: 3.7470  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14450/20565]  eta: 0:32:09  lr: 0.000017  loss: 3.2869  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14500/20565]  eta: 0:31:53  lr: 0.000017  loss: 2.7227  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14550/20565]  eta: 0:31:37  lr: 0.000017  loss: 3.7092  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14600/20565]  eta: 0:31:21  lr: 0.000017  loss: 2.6112  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14650/20565]  eta: 0:31:06  lr: 0.000017  loss: 2.7765  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14700/20565]  eta: 0:30:50  lr: 0.000017  loss: 3.3879  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14750/20565]  eta: 0:30:34  lr: 0.000017  loss: 4.0163  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14800/20565]  eta: 0:30:18  lr: 0.000017  loss: 3.0841  time: 0.3127  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14850/20565]  eta: 0:30:02  lr: 0.000017  loss: 4.3090  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14900/20565]  eta: 0:29:47  lr: 0.000017  loss: 4.3080  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [14950/20565]  eta: 0:29:31  lr: 0.000017  loss: 4.0824  time: 0.3131  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15000/20565]  eta: 0:29:15  lr: 0.000017  loss: 3.5566  time: 0.3175  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15050/20565]  eta: 0:28:59  lr: 0.000017  loss: 5.1092  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15100/20565]  eta: 0:28:44  lr: 0.000017  loss: 3.3075  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15150/20565]  eta: 0:28:28  lr: 0.000017  loss: 3.3019  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15200/20565]  eta: 0:28:12  lr: 0.000017  loss: 3.7321  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15250/20565]  eta: 0:27:56  lr: 0.000017  loss: 3.2341  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15300/20565]  eta: 0:27:41  lr: 0.000017  loss: 3.6654  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15350/20565]  eta: 0:27:25  lr: 0.000017  loss: 3.4507  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15400/20565]  eta: 0:27:09  lr: 0.000017  loss: 2.7533  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15450/20565]  eta: 0:26:53  lr: 0.000017  loss: 3.8462  time: 0.3179  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15500/20565]  eta: 0:26:37  lr: 0.000017  loss: 2.1703  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15550/20565]  eta: 0:26:22  lr: 0.000017  loss: 3.7110  time: 0.3124  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15600/20565]  eta: 0:26:06  lr: 0.000017  loss: 3.3481  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15650/20565]  eta: 0:25:50  lr: 0.000017  loss: 3.0365  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15700/20565]  eta: 0:25:34  lr: 0.000017  loss: 3.7430  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15750/20565]  eta: 0:25:19  lr: 0.000017  loss: 2.8653  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15800/20565]  eta: 0:25:03  lr: 0.000017  loss: 3.2624  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15850/20565]  eta: 0:24:47  lr: 0.000017  loss: 3.3895  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15900/20565]  eta: 0:24:31  lr: 0.000017  loss: 3.3948  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [15950/20565]  eta: 0:24:15  lr: 0.000017  loss: 2.1050  time: 0.3117  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16000/20565]  eta: 0:24:00  lr: 0.000017  loss: 2.8495  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16050/20565]  eta: 0:23:44  lr: 0.000017  loss: 2.5309  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16100/20565]  eta: 0:23:28  lr: 0.000017  loss: 2.7867  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16150/20565]  eta: 0:23:12  lr: 0.000017  loss: 3.9432  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16200/20565]  eta: 0:22:57  lr: 0.000017  loss: 2.5764  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16250/20565]  eta: 0:22:41  lr: 0.000017  loss: 2.8794  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16300/20565]  eta: 0:22:25  lr: 0.000017  loss: 3.2180  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16350/20565]  eta: 0:22:09  lr: 0.000017  loss: 3.5628  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16400/20565]  eta: 0:21:53  lr: 0.000017  loss: 3.9595  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16450/20565]  eta: 0:21:38  lr: 0.000017  loss: 2.9068  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16500/20565]  eta: 0:21:22  lr: 0.000017  loss: 3.4932  time: 0.3192  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16550/20565]  eta: 0:21:06  lr: 0.000017  loss: 2.9835  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16600/20565]  eta: 0:20:50  lr: 0.000017  loss: 3.5980  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16650/20565]  eta: 0:20:35  lr: 0.000017  loss: 3.4541  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16700/20565]  eta: 0:20:19  lr: 0.000017  loss: 2.6286  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16750/20565]  eta: 0:20:04  lr: 0.000017  loss: 2.9621  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16800/20565]  eta: 0:19:48  lr: 0.000017  loss: 3.3173  time: 0.3166  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16850/20565]  eta: 0:19:32  lr: 0.000017  loss: 3.4285  time: 0.3157  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16900/20565]  eta: 0:19:16  lr: 0.000017  loss: 3.3662  time: 0.3123  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [16950/20565]  eta: 0:19:00  lr: 0.000017  loss: 2.8447  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17000/20565]  eta: 0:18:45  lr: 0.000017  loss: 3.3387  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17050/20565]  eta: 0:18:29  lr: 0.000017  loss: 2.6002  time: 0.3113  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17100/20565]  eta: 0:18:13  lr: 0.000017  loss: 2.8186  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17150/20565]  eta: 0:17:57  lr: 0.000017  loss: 3.7044  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17200/20565]  eta: 0:17:42  lr: 0.000017  loss: 2.9608  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17250/20565]  eta: 0:17:26  lr: 0.000017  loss: 2.8355  time: 0.3186  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17300/20565]  eta: 0:17:10  lr: 0.000017  loss: 4.0420  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17350/20565]  eta: 0:16:54  lr: 0.000017  loss: 2.6896  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17400/20565]  eta: 0:16:38  lr: 0.000017  loss: 3.6872  time: 0.3166  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17450/20565]  eta: 0:16:23  lr: 0.000017  loss: 3.0951  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17500/20565]  eta: 0:16:07  lr: 0.000017  loss: 3.3463  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17550/20565]  eta: 0:15:51  lr: 0.000017  loss: 3.7695  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17600/20565]  eta: 0:15:35  lr: 0.000017  loss: 3.6849  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17650/20565]  eta: 0:15:20  lr: 0.000017  loss: 3.5805  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17700/20565]  eta: 0:15:04  lr: 0.000017  loss: 2.3786  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17750/20565]  eta: 0:14:48  lr: 0.000017  loss: 3.1333  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17800/20565]  eta: 0:14:32  lr: 0.000017  loss: 3.3988  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17850/20565]  eta: 0:14:16  lr: 0.000017  loss: 3.9195  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17900/20565]  eta: 0:14:01  lr: 0.000017  loss: 2.9901  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [17950/20565]  eta: 0:13:45  lr: 0.000017  loss: 2.0359  time: 0.3194  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18000/20565]  eta: 0:13:29  lr: 0.000017  loss: 3.9187  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18050/20565]  eta: 0:13:13  lr: 0.000017  loss: 4.4445  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18100/20565]  eta: 0:12:57  lr: 0.000017  loss: 3.5297  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18150/20565]  eta: 0:12:42  lr: 0.000017  loss: 2.8532  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18200/20565]  eta: 0:12:26  lr: 0.000017  loss: 2.4012  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18250/20565]  eta: 0:12:10  lr: 0.000017  loss: 3.0271  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18300/20565]  eta: 0:11:54  lr: 0.000017  loss: 3.6606  time: 0.3122  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18350/20565]  eta: 0:11:39  lr: 0.000017  loss: 2.2133  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18400/20565]  eta: 0:11:23  lr: 0.000017  loss: 2.7450  time: 0.3127  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18450/20565]  eta: 0:11:07  lr: 0.000017  loss: 2.8623  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18500/20565]  eta: 0:10:51  lr: 0.000017  loss: 3.5579  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18550/20565]  eta: 0:10:35  lr: 0.000017  loss: 3.5985  time: 0.3131  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18600/20565]  eta: 0:10:20  lr: 0.000017  loss: 1.9903  time: 0.3174  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18650/20565]  eta: 0:10:04  lr: 0.000017  loss: 3.7700  time: 0.3179  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18700/20565]  eta: 0:09:48  lr: 0.000017  loss: 2.8156  time: 0.3132  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18750/20565]  eta: 0:09:32  lr: 0.000017  loss: 3.9925  time: 0.3169  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18800/20565]  eta: 0:09:17  lr: 0.000017  loss: 2.3871  time: 0.3133  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18850/20565]  eta: 0:09:01  lr: 0.000017  loss: 3.8567  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18900/20565]  eta: 0:08:45  lr: 0.000017  loss: 3.0710  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [18950/20565]  eta: 0:08:29  lr: 0.000017  loss: 3.7295  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19000/20565]  eta: 0:08:13  lr: 0.000017  loss: 2.5849  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19050/20565]  eta: 0:07:58  lr: 0.000017  loss: 2.4287  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19100/20565]  eta: 0:07:42  lr: 0.000017  loss: 4.4593  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19150/20565]  eta: 0:07:26  lr: 0.000017  loss: 2.7560  time: 0.3168  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19200/20565]  eta: 0:07:10  lr: 0.000017  loss: 3.9841  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19250/20565]  eta: 0:06:55  lr: 0.000017  loss: 4.1820  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19300/20565]  eta: 0:06:39  lr: 0.000017  loss: 3.6073  time: 0.3175  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19350/20565]  eta: 0:06:23  lr: 0.000017  loss: 3.0409  time: 0.3127  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19400/20565]  eta: 0:06:07  lr: 0.000017  loss: 3.6602  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19450/20565]  eta: 0:05:51  lr: 0.000017  loss: 3.0591  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19500/20565]  eta: 0:05:36  lr: 0.000017  loss: 3.4571  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19550/20565]  eta: 0:05:20  lr: 0.000017  loss: 3.3495  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19600/20565]  eta: 0:05:04  lr: 0.000017  loss: 3.8084  time: 0.3145  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19650/20565]  eta: 0:04:48  lr: 0.000017  loss: 2.8874  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19700/20565]  eta: 0:04:32  lr: 0.000017  loss: 3.1068  time: 0.3131  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19750/20565]  eta: 0:04:17  lr: 0.000017  loss: 4.4434  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19800/20565]  eta: 0:04:01  lr: 0.000017  loss: 3.5241  time: 0.3143  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19850/20565]  eta: 0:03:45  lr: 0.000017  loss: 2.7785  time: 0.3161  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19900/20565]  eta: 0:03:29  lr: 0.000017  loss: 3.1932  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [19950/20565]  eta: 0:03:14  lr: 0.000017  loss: 4.0035  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20000/20565]  eta: 0:02:58  lr: 0.000017  loss: 3.9743  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20050/20565]  eta: 0:02:42  lr: 0.000017  loss: 4.8563  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20100/20565]  eta: 0:02:26  lr: 0.000017  loss: 3.2056  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20150/20565]  eta: 0:02:10  lr: 0.000017  loss: 2.8754  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20200/20565]  eta: 0:01:55  lr: 0.000017  loss: 2.2657  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20250/20565]  eta: 0:01:39  lr: 0.000017  loss: 3.4548  time: 0.3197  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20300/20565]  eta: 0:01:23  lr: 0.000017  loss: 3.2264  time: 0.3137  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20350/20565]  eta: 0:01:07  lr: 0.000017  loss: 3.7065  time: 0.3180  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20400/20565]  eta: 0:00:52  lr: 0.000017  loss: 3.4634  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20450/20565]  eta: 0:00:36  lr: 0.000017  loss: 2.9914  time: 0.3130  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20500/20565]  eta: 0:00:20  lr: 0.000017  loss: 2.1050  time: 0.3134  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20550/20565]  eta: 0:00:04  lr: 0.000017  loss: 3.4635  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [2]  [20564/20565]  eta: 0:00:00  lr: 0.000017  loss: 2.7184  time: 0.3176  data: 0.0024  max mem: 14698\n","Train Epoch: [2] Total time: 1:48:10 (0.3156 s / it)\n","Averaged stats: lr: 0.0000  loss: 3.2584\n"]},{"output_type":"stream","name":"stderr","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [3]  [    0/20565]  eta: 8:15:22  lr: 0.000014  loss: 3.0966  time: 1.4453  data: 1.0913  max mem: 14698\n","Train Epoch: [3]  [   50/20565]  eta: 1:56:25  lr: 0.000014  loss: 3.0405  time: 0.3184  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  100/20565]  eta: 1:51:58  lr: 0.000014  loss: 2.3241  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  150/20565]  eta: 1:50:17  lr: 0.000014  loss: 3.1893  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  200/20565]  eta: 1:49:19  lr: 0.000014  loss: 2.8479  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  250/20565]  eta: 1:48:31  lr: 0.000014  loss: 2.6318  time: 0.3126  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  300/20565]  eta: 1:47:56  lr: 0.000014  loss: 2.2076  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  350/20565]  eta: 1:47:28  lr: 0.000014  loss: 2.4531  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  400/20565]  eta: 1:47:05  lr: 0.000014  loss: 2.8807  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  450/20565]  eta: 1:46:48  lr: 0.000014  loss: 2.8803  time: 0.3193  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  500/20565]  eta: 1:46:24  lr: 0.000014  loss: 3.9422  time: 0.3167  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  550/20565]  eta: 1:46:04  lr: 0.000014  loss: 3.0427  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  600/20565]  eta: 1:45:47  lr: 0.000014  loss: 2.3894  time: 0.3182  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  650/20565]  eta: 1:45:26  lr: 0.000014  loss: 2.6385  time: 0.3139  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  700/20565]  eta: 1:45:06  lr: 0.000014  loss: 4.2956  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  750/20565]  eta: 1:44:46  lr: 0.000014  loss: 3.0529  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  800/20565]  eta: 1:44:29  lr: 0.000014  loss: 3.6434  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  850/20565]  eta: 1:44:11  lr: 0.000014  loss: 3.9555  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  900/20565]  eta: 1:43:51  lr: 0.000014  loss: 2.8911  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [  950/20565]  eta: 1:43:35  lr: 0.000014  loss: 2.8620  time: 0.3183  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1000/20565]  eta: 1:43:18  lr: 0.000014  loss: 2.2901  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1050/20565]  eta: 1:43:02  lr: 0.000014  loss: 3.0325  time: 0.3171  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1100/20565]  eta: 1:42:44  lr: 0.000014  loss: 3.5344  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1150/20565]  eta: 1:42:27  lr: 0.000014  loss: 2.4155  time: 0.3129  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1200/20565]  eta: 1:42:10  lr: 0.000014  loss: 2.9193  time: 0.3166  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1250/20565]  eta: 1:41:53  lr: 0.000014  loss: 2.2403  time: 0.3170  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1300/20565]  eta: 1:41:36  lr: 0.000014  loss: 2.9784  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1350/20565]  eta: 1:41:19  lr: 0.000014  loss: 3.1530  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1400/20565]  eta: 1:41:02  lr: 0.000014  loss: 3.3524  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1450/20565]  eta: 1:40:46  lr: 0.000014  loss: 2.5622  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1500/20565]  eta: 1:40:28  lr: 0.000014  loss: 3.7244  time: 0.3135  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1550/20565]  eta: 1:40:12  lr: 0.000014  loss: 2.4347  time: 0.3148  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1600/20565]  eta: 1:39:56  lr: 0.000014  loss: 3.0145  time: 0.3126  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1650/20565]  eta: 1:39:40  lr: 0.000014  loss: 3.4168  time: 0.3167  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1700/20565]  eta: 1:39:24  lr: 0.000014  loss: 3.0264  time: 0.3173  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1750/20565]  eta: 1:39:07  lr: 0.000014  loss: 2.2464  time: 0.3125  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1800/20565]  eta: 1:38:51  lr: 0.000014  loss: 2.2649  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1850/20565]  eta: 1:38:34  lr: 0.000014  loss: 2.9952  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1900/20565]  eta: 1:38:17  lr: 0.000014  loss: 2.3813  time: 0.3136  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 1950/20565]  eta: 1:38:00  lr: 0.000014  loss: 2.8449  time: 0.3119  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2000/20565]  eta: 1:37:43  lr: 0.000014  loss: 3.5381  time: 0.3151  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2050/20565]  eta: 1:37:27  lr: 0.000014  loss: 2.9941  time: 0.3164  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2100/20565]  eta: 1:37:10  lr: 0.000014  loss: 4.4153  time: 0.3154  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2150/20565]  eta: 1:36:54  lr: 0.000014  loss: 3.5315  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2200/20565]  eta: 1:36:39  lr: 0.000014  loss: 3.4044  time: 0.3180  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2250/20565]  eta: 1:36:23  lr: 0.000014  loss: 3.2830  time: 0.3156  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2300/20565]  eta: 1:36:06  lr: 0.000014  loss: 3.4847  time: 0.3123  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2350/20565]  eta: 1:35:51  lr: 0.000014  loss: 3.1766  time: 0.3140  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2400/20565]  eta: 1:35:34  lr: 0.000014  loss: 2.9335  time: 0.3123  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2450/20565]  eta: 1:35:19  lr: 0.000014  loss: 2.9658  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2500/20565]  eta: 1:35:02  lr: 0.000014  loss: 2.7489  time: 0.3162  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2550/20565]  eta: 1:34:46  lr: 0.000014  loss: 3.1969  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2600/20565]  eta: 1:34:29  lr: 0.000014  loss: 5.0956  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2650/20565]  eta: 1:34:14  lr: 0.000014  loss: 3.2550  time: 0.3178  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2700/20565]  eta: 1:33:58  lr: 0.000014  loss: 4.0391  time: 0.3165  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2750/20565]  eta: 1:33:42  lr: 0.000014  loss: 2.8527  time: 0.3153  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2800/20565]  eta: 1:33:26  lr: 0.000014  loss: 3.0267  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2850/20565]  eta: 1:33:11  lr: 0.000014  loss: 3.5144  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2900/20565]  eta: 1:32:55  lr: 0.000014  loss: 2.7342  time: 0.3172  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 2950/20565]  eta: 1:32:39  lr: 0.000014  loss: 3.9456  time: 0.3155  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3000/20565]  eta: 1:32:23  lr: 0.000014  loss: 3.3900  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3050/20565]  eta: 1:32:07  lr: 0.000014  loss: 2.4650  time: 0.3146  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3100/20565]  eta: 1:31:51  lr: 0.000014  loss: 2.5302  time: 0.3128  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3150/20565]  eta: 1:31:35  lr: 0.000014  loss: 2.9621  time: 0.3147  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3200/20565]  eta: 1:31:19  lr: 0.000014  loss: 3.2188  time: 0.3158  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3250/20565]  eta: 1:31:03  lr: 0.000014  loss: 2.9697  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3300/20565]  eta: 1:30:47  lr: 0.000014  loss: 3.2155  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3350/20565]  eta: 1:30:31  lr: 0.000014  loss: 3.3664  time: 0.3150  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3400/20565]  eta: 1:30:16  lr: 0.000014  loss: 4.0202  time: 0.3163  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3450/20565]  eta: 1:30:00  lr: 0.000014  loss: 2.8927  time: 0.3149  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3500/20565]  eta: 1:29:43  lr: 0.000014  loss: 3.6768  time: 0.3128  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3550/20565]  eta: 1:29:28  lr: 0.000014  loss: 2.5232  time: 0.3175  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3600/20565]  eta: 1:29:12  lr: 0.000014  loss: 3.4250  time: 0.3138  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3650/20565]  eta: 1:28:56  lr: 0.000014  loss: 4.1021  time: 0.3167  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3700/20565]  eta: 1:28:40  lr: 0.000014  loss: 2.8921  time: 0.3169  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3750/20565]  eta: 1:28:24  lr: 0.000014  loss: 3.6104  time: 0.3133  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3800/20565]  eta: 1:28:08  lr: 0.000014  loss: 2.5318  time: 0.3159  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3850/20565]  eta: 1:27:52  lr: 0.000014  loss: 2.3317  time: 0.3124  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3900/20565]  eta: 1:27:36  lr: 0.000014  loss: 2.8912  time: 0.3144  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 3950/20565]  eta: 1:27:20  lr: 0.000014  loss: 3.5712  time: 0.3141  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 4000/20565]  eta: 1:27:04  lr: 0.000014  loss: 2.3969  time: 0.3152  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 4050/20565]  eta: 1:26:48  lr: 0.000014  loss: 3.9623  time: 0.3160  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 4100/20565]  eta: 1:26:32  lr: 0.000014  loss: 4.7255  time: 0.3169  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 4150/20565]  eta: 1:26:16  lr: 0.000014  loss: 2.0655  time: 0.3126  data: 0.0002  max mem: 14698\n","Train Epoch: [3]  [ 4200/20565]  eta: 1:26:01  lr: 0.000014  loss: 2.7752  time: 0.3218  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4250/20565]  eta: 1:25:44  lr: 0.000014  loss: 3.4219  time: 0.3126  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4300/20565]  eta: 1:25:29  lr: 0.000014  loss: 2.9846  time: 0.3164  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4350/20565]  eta: 1:25:13  lr: 0.000014  loss: 2.6278  time: 0.3135  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4400/20565]  eta: 1:24:57  lr: 0.000014  loss: 2.6643  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4450/20565]  eta: 1:24:41  lr: 0.000014  loss: 2.9058  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4500/20565]  eta: 1:24:25  lr: 0.000014  loss: 3.1085  time: 0.3124  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4550/20565]  eta: 1:24:09  lr: 0.000014  loss: 3.1172  time: 0.3166  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4600/20565]  eta: 1:23:53  lr: 0.000014  loss: 2.6075  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4650/20565]  eta: 1:23:38  lr: 0.000014  loss: 2.9041  time: 0.3164  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4700/20565]  eta: 1:23:22  lr: 0.000014  loss: 3.2170  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4750/20565]  eta: 1:23:06  lr: 0.000014  loss: 3.7281  time: 0.3135  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4800/20565]  eta: 1:22:50  lr: 0.000014  loss: 3.3433  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4850/20565]  eta: 1:22:34  lr: 0.000014  loss: 3.3554  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4900/20565]  eta: 1:22:19  lr: 0.000014  loss: 3.2780  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 4950/20565]  eta: 1:22:03  lr: 0.000014  loss: 2.6136  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5000/20565]  eta: 1:21:47  lr: 0.000014  loss: 4.2974  time: 0.3174  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5050/20565]  eta: 1:21:31  lr: 0.000014  loss: 3.3162  time: 0.3174  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5100/20565]  eta: 1:21:16  lr: 0.000014  loss: 3.1004  time: 0.3134  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5150/20565]  eta: 1:21:00  lr: 0.000014  loss: 4.1096  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5200/20565]  eta: 1:20:44  lr: 0.000014  loss: 2.8473  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5250/20565]  eta: 1:20:29  lr: 0.000014  loss: 3.0294  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5300/20565]  eta: 1:20:13  lr: 0.000014  loss: 2.8148  time: 0.3168  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5350/20565]  eta: 1:19:57  lr: 0.000014  loss: 3.0368  time: 0.3160  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5400/20565]  eta: 1:19:41  lr: 0.000014  loss: 3.7833  time: 0.3165  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5450/20565]  eta: 1:19:26  lr: 0.000014  loss: 3.7514  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5500/20565]  eta: 1:19:10  lr: 0.000014  loss: 3.9683  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5550/20565]  eta: 1:18:54  lr: 0.000014  loss: 3.6378  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5600/20565]  eta: 1:18:38  lr: 0.000014  loss: 2.5443  time: 0.3118  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5650/20565]  eta: 1:18:22  lr: 0.000014  loss: 2.4381  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5700/20565]  eta: 1:18:07  lr: 0.000014  loss: 2.8484  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5750/20565]  eta: 1:17:51  lr: 0.000014  loss: 2.7145  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5800/20565]  eta: 1:17:36  lr: 0.000014  loss: 3.8345  time: 0.3179  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5850/20565]  eta: 1:17:20  lr: 0.000014  loss: 3.0126  time: 0.3141  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5900/20565]  eta: 1:17:04  lr: 0.000014  loss: 3.8095  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 5950/20565]  eta: 1:16:48  lr: 0.000014  loss: 4.0507  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6000/20565]  eta: 1:16:33  lr: 0.000014  loss: 3.4508  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6050/20565]  eta: 1:16:17  lr: 0.000014  loss: 3.4191  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6100/20565]  eta: 1:16:01  lr: 0.000014  loss: 2.9478  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6150/20565]  eta: 1:15:45  lr: 0.000014  loss: 2.4891  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6200/20565]  eta: 1:15:30  lr: 0.000014  loss: 2.8568  time: 0.3183  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6250/20565]  eta: 1:15:14  lr: 0.000014  loss: 2.4087  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6300/20565]  eta: 1:14:58  lr: 0.000014  loss: 2.7649  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6350/20565]  eta: 1:14:42  lr: 0.000014  loss: 2.6164  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6400/20565]  eta: 1:14:26  lr: 0.000014  loss: 3.6173  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6450/20565]  eta: 1:14:11  lr: 0.000014  loss: 2.9587  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6500/20565]  eta: 1:13:55  lr: 0.000014  loss: 1.9828  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6550/20565]  eta: 1:13:39  lr: 0.000014  loss: 4.1834  time: 0.3168  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6600/20565]  eta: 1:13:23  lr: 0.000014  loss: 3.5904  time: 0.3139  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6650/20565]  eta: 1:13:08  lr: 0.000014  loss: 3.1229  time: 0.3171  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6700/20565]  eta: 1:12:52  lr: 0.000014  loss: 3.4916  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6750/20565]  eta: 1:12:36  lr: 0.000014  loss: 2.7428  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6800/20565]  eta: 1:12:20  lr: 0.000014  loss: 2.5356  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6850/20565]  eta: 1:12:05  lr: 0.000014  loss: 3.7320  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6900/20565]  eta: 1:11:49  lr: 0.000014  loss: 3.1994  time: 0.3181  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 6950/20565]  eta: 1:11:33  lr: 0.000014  loss: 2.7762  time: 0.3123  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7000/20565]  eta: 1:11:17  lr: 0.000014  loss: 3.1567  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7050/20565]  eta: 1:11:02  lr: 0.000014  loss: 2.9382  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7100/20565]  eta: 1:10:46  lr: 0.000014  loss: 2.7953  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7150/20565]  eta: 1:10:30  lr: 0.000014  loss: 4.0257  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7200/20565]  eta: 1:10:14  lr: 0.000014  loss: 3.1657  time: 0.3160  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7250/20565]  eta: 1:09:59  lr: 0.000014  loss: 3.9084  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7300/20565]  eta: 1:09:43  lr: 0.000014  loss: 3.1989  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7350/20565]  eta: 1:09:27  lr: 0.000014  loss: 3.3904  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7400/20565]  eta: 1:09:11  lr: 0.000014  loss: 2.6598  time: 0.3173  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7450/20565]  eta: 1:08:56  lr: 0.000014  loss: 3.2420  time: 0.3171  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7500/20565]  eta: 1:08:40  lr: 0.000014  loss: 2.8423  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7550/20565]  eta: 1:08:24  lr: 0.000014  loss: 2.4812  time: 0.3185  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7600/20565]  eta: 1:08:08  lr: 0.000014  loss: 4.3460  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7650/20565]  eta: 1:07:53  lr: 0.000014  loss: 3.0202  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7700/20565]  eta: 1:07:37  lr: 0.000014  loss: 3.3207  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7750/20565]  eta: 1:07:21  lr: 0.000014  loss: 4.3634  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7800/20565]  eta: 1:07:05  lr: 0.000014  loss: 4.3103  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7850/20565]  eta: 1:06:49  lr: 0.000014  loss: 2.9285  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7900/20565]  eta: 1:06:34  lr: 0.000014  loss: 2.6161  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 7950/20565]  eta: 1:06:18  lr: 0.000014  loss: 3.4456  time: 0.3165  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8000/20565]  eta: 1:06:02  lr: 0.000014  loss: 2.5651  time: 0.3135  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8050/20565]  eta: 1:05:46  lr: 0.000014  loss: 3.7231  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8100/20565]  eta: 1:05:31  lr: 0.000014  loss: 2.5253  time: 0.3127  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8150/20565]  eta: 1:05:15  lr: 0.000014  loss: 2.1482  time: 0.3171  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8200/20565]  eta: 1:04:59  lr: 0.000014  loss: 2.4423  time: 0.3128  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8250/20565]  eta: 1:04:43  lr: 0.000014  loss: 3.8273  time: 0.3175  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8300/20565]  eta: 1:04:27  lr: 0.000014  loss: 3.2782  time: 0.3139  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8350/20565]  eta: 1:04:12  lr: 0.000014  loss: 2.1277  time: 0.3178  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8400/20565]  eta: 1:03:56  lr: 0.000014  loss: 3.4436  time: 0.3128  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8450/20565]  eta: 1:03:40  lr: 0.000014  loss: 2.1271  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8500/20565]  eta: 1:03:24  lr: 0.000014  loss: 3.7281  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8550/20565]  eta: 1:03:09  lr: 0.000014  loss: 2.6291  time: 0.3128  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8600/20565]  eta: 1:02:53  lr: 0.000014  loss: 3.6786  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8650/20565]  eta: 1:02:37  lr: 0.000014  loss: 2.5886  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8700/20565]  eta: 1:02:21  lr: 0.000014  loss: 2.3411  time: 0.3177  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8750/20565]  eta: 1:02:05  lr: 0.000014  loss: 4.1009  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8800/20565]  eta: 1:01:50  lr: 0.000014  loss: 3.8316  time: 0.3175  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8850/20565]  eta: 1:01:34  lr: 0.000014  loss: 3.8830  time: 0.3183  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8900/20565]  eta: 1:01:18  lr: 0.000014  loss: 2.6559  time: 0.3184  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 8950/20565]  eta: 1:01:02  lr: 0.000014  loss: 3.1835  time: 0.3116  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9000/20565]  eta: 1:00:47  lr: 0.000014  loss: 3.1454  time: 0.3166  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9050/20565]  eta: 1:00:31  lr: 0.000014  loss: 3.2282  time: 0.3164  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9100/20565]  eta: 1:00:15  lr: 0.000014  loss: 2.5530  time: 0.3177  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9150/20565]  eta: 1:00:00  lr: 0.000014  loss: 3.1509  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9200/20565]  eta: 0:59:44  lr: 0.000014  loss: 2.7152  time: 0.3174  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9250/20565]  eta: 0:59:28  lr: 0.000014  loss: 3.1547  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9300/20565]  eta: 0:59:12  lr: 0.000014  loss: 2.8660  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9350/20565]  eta: 0:58:57  lr: 0.000014  loss: 3.0309  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9400/20565]  eta: 0:58:41  lr: 0.000014  loss: 3.1136  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9450/20565]  eta: 0:58:25  lr: 0.000014  loss: 3.1961  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9500/20565]  eta: 0:58:09  lr: 0.000014  loss: 3.0185  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9550/20565]  eta: 0:57:53  lr: 0.000014  loss: 3.0416  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9600/20565]  eta: 0:57:38  lr: 0.000014  loss: 3.0332  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9650/20565]  eta: 0:57:22  lr: 0.000014  loss: 2.1059  time: 0.3123  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9700/20565]  eta: 0:57:06  lr: 0.000014  loss: 2.7858  time: 0.3124  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9750/20565]  eta: 0:56:50  lr: 0.000014  loss: 3.8009  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9800/20565]  eta: 0:56:34  lr: 0.000014  loss: 3.3498  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9850/20565]  eta: 0:56:19  lr: 0.000014  loss: 3.3709  time: 0.3170  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9900/20565]  eta: 0:56:03  lr: 0.000014  loss: 3.1620  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [ 9950/20565]  eta: 0:55:47  lr: 0.000014  loss: 3.0633  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10000/20565]  eta: 0:55:31  lr: 0.000014  loss: 2.5251  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10050/20565]  eta: 0:55:16  lr: 0.000014  loss: 2.6822  time: 0.3127  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10100/20565]  eta: 0:55:00  lr: 0.000014  loss: 2.9945  time: 0.3203  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10150/20565]  eta: 0:54:44  lr: 0.000014  loss: 2.5768  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10200/20565]  eta: 0:54:28  lr: 0.000014  loss: 3.0092  time: 0.3166  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10250/20565]  eta: 0:54:12  lr: 0.000014  loss: 2.5907  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10300/20565]  eta: 0:53:57  lr: 0.000014  loss: 3.2673  time: 0.3178  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10350/20565]  eta: 0:53:41  lr: 0.000014  loss: 3.3479  time: 0.3105  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10400/20565]  eta: 0:53:25  lr: 0.000014  loss: 3.1304  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10450/20565]  eta: 0:53:09  lr: 0.000014  loss: 3.0988  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10500/20565]  eta: 0:52:53  lr: 0.000014  loss: 2.5990  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10550/20565]  eta: 0:52:38  lr: 0.000014  loss: 3.1680  time: 0.3163  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10600/20565]  eta: 0:52:22  lr: 0.000014  loss: 2.8757  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10650/20565]  eta: 0:52:06  lr: 0.000014  loss: 3.3836  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10700/20565]  eta: 0:51:50  lr: 0.000014  loss: 3.3142  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10750/20565]  eta: 0:51:34  lr: 0.000014  loss: 2.7006  time: 0.3119  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10800/20565]  eta: 0:51:19  lr: 0.000014  loss: 2.9141  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10850/20565]  eta: 0:51:03  lr: 0.000014  loss: 3.2887  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10900/20565]  eta: 0:50:47  lr: 0.000014  loss: 3.1717  time: 0.3165  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [10950/20565]  eta: 0:50:31  lr: 0.000014  loss: 2.7527  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11000/20565]  eta: 0:50:15  lr: 0.000014  loss: 2.3721  time: 0.3141  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11050/20565]  eta: 0:49:59  lr: 0.000014  loss: 3.1353  time: 0.3169  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11100/20565]  eta: 0:49:44  lr: 0.000014  loss: 3.2930  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11150/20565]  eta: 0:49:28  lr: 0.000014  loss: 4.3745  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11200/20565]  eta: 0:49:12  lr: 0.000014  loss: 4.2754  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11250/20565]  eta: 0:48:56  lr: 0.000014  loss: 2.7831  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11300/20565]  eta: 0:48:40  lr: 0.000014  loss: 2.3956  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11350/20565]  eta: 0:48:25  lr: 0.000014  loss: 3.1537  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11400/20565]  eta: 0:48:09  lr: 0.000014  loss: 2.9471  time: 0.3130  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11450/20565]  eta: 0:47:53  lr: 0.000014  loss: 2.7833  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11500/20565]  eta: 0:47:37  lr: 0.000014  loss: 3.2902  time: 0.3189  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11550/20565]  eta: 0:47:22  lr: 0.000014  loss: 2.8678  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11600/20565]  eta: 0:47:06  lr: 0.000014  loss: 2.9139  time: 0.3129  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11650/20565]  eta: 0:46:50  lr: 0.000014  loss: 3.1840  time: 0.3143  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11700/20565]  eta: 0:46:34  lr: 0.000014  loss: 4.7291  time: 0.3170  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11750/20565]  eta: 0:46:19  lr: 0.000014  loss: 3.1948  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11800/20565]  eta: 0:46:03  lr: 0.000014  loss: 2.6166  time: 0.3164  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11850/20565]  eta: 0:45:47  lr: 0.000014  loss: 2.6811  time: 0.3175  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11900/20565]  eta: 0:45:31  lr: 0.000014  loss: 2.0302  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [11950/20565]  eta: 0:45:16  lr: 0.000014  loss: 2.6296  time: 0.3160  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12000/20565]  eta: 0:45:00  lr: 0.000014  loss: 3.1963  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12050/20565]  eta: 0:44:44  lr: 0.000014  loss: 2.8393  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12100/20565]  eta: 0:44:28  lr: 0.000014  loss: 3.2514  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12150/20565]  eta: 0:44:13  lr: 0.000014  loss: 2.6339  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12200/20565]  eta: 0:43:57  lr: 0.000014  loss: 3.0221  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12250/20565]  eta: 0:43:41  lr: 0.000014  loss: 3.1737  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12300/20565]  eta: 0:43:25  lr: 0.000014  loss: 3.0381  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12350/20565]  eta: 0:43:09  lr: 0.000014  loss: 2.3290  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12400/20565]  eta: 0:42:54  lr: 0.000014  loss: 4.2218  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12450/20565]  eta: 0:42:38  lr: 0.000014  loss: 2.5835  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12500/20565]  eta: 0:42:22  lr: 0.000014  loss: 3.2551  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12550/20565]  eta: 0:42:06  lr: 0.000014  loss: 2.8201  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12600/20565]  eta: 0:41:51  lr: 0.000014  loss: 3.5229  time: 0.3126  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12650/20565]  eta: 0:41:35  lr: 0.000014  loss: 3.1155  time: 0.3163  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12700/20565]  eta: 0:41:19  lr: 0.000014  loss: 3.5190  time: 0.3178  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12750/20565]  eta: 0:41:03  lr: 0.000014  loss: 3.3246  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12800/20565]  eta: 0:40:47  lr: 0.000014  loss: 2.5059  time: 0.3174  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12850/20565]  eta: 0:40:32  lr: 0.000014  loss: 3.7255  time: 0.3174  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12900/20565]  eta: 0:40:16  lr: 0.000014  loss: 3.5057  time: 0.3135  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [12950/20565]  eta: 0:40:00  lr: 0.000014  loss: 2.9633  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13000/20565]  eta: 0:39:44  lr: 0.000014  loss: 2.8690  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13050/20565]  eta: 0:39:29  lr: 0.000014  loss: 2.5756  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13100/20565]  eta: 0:39:13  lr: 0.000014  loss: 3.7083  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13150/20565]  eta: 0:38:57  lr: 0.000014  loss: 3.5382  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13200/20565]  eta: 0:38:41  lr: 0.000014  loss: 2.8682  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13250/20565]  eta: 0:38:26  lr: 0.000014  loss: 2.7984  time: 0.3160  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13300/20565]  eta: 0:38:10  lr: 0.000014  loss: 2.8155  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13350/20565]  eta: 0:37:54  lr: 0.000014  loss: 3.1494  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13400/20565]  eta: 0:37:38  lr: 0.000014  loss: 3.3507  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13450/20565]  eta: 0:37:23  lr: 0.000014  loss: 3.3448  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13500/20565]  eta: 0:37:07  lr: 0.000014  loss: 2.3726  time: 0.3160  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13550/20565]  eta: 0:36:51  lr: 0.000014  loss: 3.5814  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13600/20565]  eta: 0:36:35  lr: 0.000014  loss: 2.9917  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13650/20565]  eta: 0:36:20  lr: 0.000014  loss: 3.5764  time: 0.3141  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13700/20565]  eta: 0:36:04  lr: 0.000014  loss: 4.1684  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13750/20565]  eta: 0:35:48  lr: 0.000014  loss: 2.7039  time: 0.3130  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13800/20565]  eta: 0:35:32  lr: 0.000014  loss: 3.1750  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13850/20565]  eta: 0:35:16  lr: 0.000014  loss: 3.4534  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13900/20565]  eta: 0:35:01  lr: 0.000014  loss: 3.1481  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [13950/20565]  eta: 0:34:45  lr: 0.000014  loss: 3.3167  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14000/20565]  eta: 0:34:29  lr: 0.000014  loss: 2.8271  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14050/20565]  eta: 0:34:13  lr: 0.000014  loss: 2.1159  time: 0.3169  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14100/20565]  eta: 0:33:58  lr: 0.000014  loss: 2.4762  time: 0.3163  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14150/20565]  eta: 0:33:42  lr: 0.000014  loss: 2.6202  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14200/20565]  eta: 0:33:26  lr: 0.000014  loss: 3.2194  time: 0.3188  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14250/20565]  eta: 0:33:10  lr: 0.000014  loss: 3.5858  time: 0.3165  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14300/20565]  eta: 0:32:55  lr: 0.000014  loss: 1.9840  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14350/20565]  eta: 0:32:39  lr: 0.000014  loss: 2.1568  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14400/20565]  eta: 0:32:23  lr: 0.000014  loss: 3.7307  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14450/20565]  eta: 0:32:07  lr: 0.000014  loss: 2.6278  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14500/20565]  eta: 0:31:52  lr: 0.000014  loss: 3.4188  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14550/20565]  eta: 0:31:36  lr: 0.000014  loss: 2.6506  time: 0.3169  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14600/20565]  eta: 0:31:20  lr: 0.000014  loss: 2.9421  time: 0.3170  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14650/20565]  eta: 0:31:04  lr: 0.000014  loss: 3.9756  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14700/20565]  eta: 0:30:48  lr: 0.000014  loss: 2.7150  time: 0.3110  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14750/20565]  eta: 0:30:33  lr: 0.000014  loss: 2.6925  time: 0.3139  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14800/20565]  eta: 0:30:17  lr: 0.000014  loss: 3.2301  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14850/20565]  eta: 0:30:01  lr: 0.000014  loss: 4.3082  time: 0.3136  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14900/20565]  eta: 0:29:45  lr: 0.000014  loss: 3.6675  time: 0.3138  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [14950/20565]  eta: 0:29:30  lr: 0.000014  loss: 2.8903  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15000/20565]  eta: 0:29:14  lr: 0.000014  loss: 4.0001  time: 0.3164  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15050/20565]  eta: 0:28:58  lr: 0.000014  loss: 2.5144  time: 0.3187  data: 0.0003  max mem: 14771\n","Train Epoch: [3]  [15100/20565]  eta: 0:28:42  lr: 0.000014  loss: 2.4959  time: 0.3175  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15150/20565]  eta: 0:28:27  lr: 0.000014  loss: 2.0868  time: 0.3156  data: 0.0003  max mem: 14771\n","Train Epoch: [3]  [15200/20565]  eta: 0:28:11  lr: 0.000014  loss: 3.6889  time: 0.3196  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15250/20565]  eta: 0:27:55  lr: 0.000014  loss: 2.7460  time: 0.3173  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15300/20565]  eta: 0:27:39  lr: 0.000014  loss: 3.4557  time: 0.3191  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15350/20565]  eta: 0:27:24  lr: 0.000014  loss: 4.5468  time: 0.3174  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15400/20565]  eta: 0:27:08  lr: 0.000014  loss: 3.1031  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15450/20565]  eta: 0:26:52  lr: 0.000014  loss: 3.6947  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15500/20565]  eta: 0:26:36  lr: 0.000014  loss: 3.2649  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15550/20565]  eta: 0:26:21  lr: 0.000014  loss: 3.2696  time: 0.3163  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15600/20565]  eta: 0:26:05  lr: 0.000014  loss: 3.1315  time: 0.3171  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15650/20565]  eta: 0:25:49  lr: 0.000014  loss: 2.3929  time: 0.3141  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15700/20565]  eta: 0:25:33  lr: 0.000014  loss: 2.3148  time: 0.3168  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15750/20565]  eta: 0:25:18  lr: 0.000014  loss: 3.3637  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15800/20565]  eta: 0:25:02  lr: 0.000014  loss: 4.3839  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15850/20565]  eta: 0:24:46  lr: 0.000014  loss: 2.0512  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15900/20565]  eta: 0:24:30  lr: 0.000014  loss: 3.6365  time: 0.3138  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [15950/20565]  eta: 0:24:15  lr: 0.000014  loss: 2.9708  time: 0.3171  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16000/20565]  eta: 0:23:59  lr: 0.000014  loss: 4.4876  time: 0.3138  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16050/20565]  eta: 0:23:43  lr: 0.000014  loss: 3.7908  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16100/20565]  eta: 0:23:27  lr: 0.000014  loss: 2.8617  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16150/20565]  eta: 0:23:12  lr: 0.000014  loss: 3.3691  time: 0.3185  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16200/20565]  eta: 0:22:56  lr: 0.000014  loss: 3.1329  time: 0.3136  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16250/20565]  eta: 0:22:40  lr: 0.000014  loss: 3.1144  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16300/20565]  eta: 0:22:24  lr: 0.000014  loss: 2.6280  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16350/20565]  eta: 0:22:09  lr: 0.000014  loss: 2.6310  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16400/20565]  eta: 0:21:53  lr: 0.000014  loss: 3.4416  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16450/20565]  eta: 0:21:37  lr: 0.000014  loss: 3.0384  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16500/20565]  eta: 0:21:21  lr: 0.000014  loss: 2.5553  time: 0.3123  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16550/20565]  eta: 0:21:06  lr: 0.000014  loss: 2.5275  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16600/20565]  eta: 0:20:50  lr: 0.000014  loss: 2.6422  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16650/20565]  eta: 0:20:34  lr: 0.000014  loss: 3.7271  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16700/20565]  eta: 0:20:18  lr: 0.000014  loss: 2.8573  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16750/20565]  eta: 0:20:02  lr: 0.000014  loss: 2.8663  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16800/20565]  eta: 0:19:47  lr: 0.000014  loss: 3.8404  time: 0.3180  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16850/20565]  eta: 0:19:31  lr: 0.000014  loss: 2.8558  time: 0.3127  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16900/20565]  eta: 0:19:15  lr: 0.000014  loss: 2.4783  time: 0.3170  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [16950/20565]  eta: 0:18:59  lr: 0.000014  loss: 3.4930  time: 0.3135  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17000/20565]  eta: 0:18:44  lr: 0.000014  loss: 4.1146  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17050/20565]  eta: 0:18:28  lr: 0.000014  loss: 3.1931  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17100/20565]  eta: 0:18:12  lr: 0.000014  loss: 2.2648  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17150/20565]  eta: 0:17:56  lr: 0.000014  loss: 2.9566  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17200/20565]  eta: 0:17:41  lr: 0.000014  loss: 3.4611  time: 0.3184  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17250/20565]  eta: 0:17:25  lr: 0.000014  loss: 2.8961  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17300/20565]  eta: 0:17:09  lr: 0.000014  loss: 2.3356  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17350/20565]  eta: 0:16:53  lr: 0.000014  loss: 2.4222  time: 0.3141  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17400/20565]  eta: 0:16:37  lr: 0.000014  loss: 4.6406  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17450/20565]  eta: 0:16:22  lr: 0.000014  loss: 2.9792  time: 0.3130  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17500/20565]  eta: 0:16:06  lr: 0.000014  loss: 2.7351  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17550/20565]  eta: 0:15:50  lr: 0.000014  loss: 2.4000  time: 0.3168  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17600/20565]  eta: 0:15:34  lr: 0.000014  loss: 2.9987  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17650/20565]  eta: 0:15:19  lr: 0.000014  loss: 2.6317  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17700/20565]  eta: 0:15:03  lr: 0.000014  loss: 3.0325  time: 0.3173  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17750/20565]  eta: 0:14:47  lr: 0.000014  loss: 2.4849  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17800/20565]  eta: 0:14:31  lr: 0.000014  loss: 3.2180  time: 0.3160  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17850/20565]  eta: 0:14:16  lr: 0.000014  loss: 2.7905  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17900/20565]  eta: 0:14:00  lr: 0.000014  loss: 3.5280  time: 0.3170  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [17950/20565]  eta: 0:13:44  lr: 0.000014  loss: 3.5276  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18000/20565]  eta: 0:13:28  lr: 0.000014  loss: 2.4611  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18050/20565]  eta: 0:13:13  lr: 0.000014  loss: 3.8704  time: 0.3184  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18100/20565]  eta: 0:12:57  lr: 0.000014  loss: 3.3835  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18150/20565]  eta: 0:12:41  lr: 0.000014  loss: 3.6381  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18200/20565]  eta: 0:12:25  lr: 0.000014  loss: 3.6589  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18250/20565]  eta: 0:12:09  lr: 0.000014  loss: 2.9815  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18300/20565]  eta: 0:11:54  lr: 0.000014  loss: 3.5734  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18350/20565]  eta: 0:11:38  lr: 0.000014  loss: 3.0689  time: 0.3127  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18400/20565]  eta: 0:11:22  lr: 0.000014  loss: 2.8665  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18450/20565]  eta: 0:11:06  lr: 0.000014  loss: 2.5821  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18500/20565]  eta: 0:10:51  lr: 0.000014  loss: 3.3846  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18550/20565]  eta: 0:10:35  lr: 0.000014  loss: 2.8920  time: 0.3135  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18600/20565]  eta: 0:10:19  lr: 0.000014  loss: 2.5564  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18650/20565]  eta: 0:10:03  lr: 0.000014  loss: 3.4679  time: 0.3175  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18700/20565]  eta: 0:09:48  lr: 0.000014  loss: 3.1760  time: 0.3198  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18750/20565]  eta: 0:09:32  lr: 0.000014  loss: 3.0116  time: 0.3138  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18800/20565]  eta: 0:09:16  lr: 0.000014  loss: 3.0722  time: 0.3160  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18850/20565]  eta: 0:09:00  lr: 0.000014  loss: 3.2858  time: 0.3173  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18900/20565]  eta: 0:08:45  lr: 0.000014  loss: 3.3189  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [18950/20565]  eta: 0:08:29  lr: 0.000014  loss: 3.0192  time: 0.3138  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19000/20565]  eta: 0:08:13  lr: 0.000014  loss: 3.1591  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19050/20565]  eta: 0:07:57  lr: 0.000014  loss: 2.0375  time: 0.3182  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19100/20565]  eta: 0:07:41  lr: 0.000014  loss: 2.7192  time: 0.3186  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19150/20565]  eta: 0:07:26  lr: 0.000014  loss: 3.9269  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19200/20565]  eta: 0:07:10  lr: 0.000014  loss: 3.3870  time: 0.3164  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19250/20565]  eta: 0:06:54  lr: 0.000014  loss: 3.7278  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19300/20565]  eta: 0:06:38  lr: 0.000014  loss: 2.5780  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19350/20565]  eta: 0:06:23  lr: 0.000014  loss: 2.9364  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19400/20565]  eta: 0:06:07  lr: 0.000014  loss: 3.2898  time: 0.3183  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19450/20565]  eta: 0:05:51  lr: 0.000014  loss: 2.1394  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19500/20565]  eta: 0:05:35  lr: 0.000014  loss: 3.4518  time: 0.3163  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19550/20565]  eta: 0:05:20  lr: 0.000014  loss: 2.8985  time: 0.3143  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19600/20565]  eta: 0:05:04  lr: 0.000014  loss: 3.5945  time: 0.3209  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19650/20565]  eta: 0:04:48  lr: 0.000014  loss: 3.8684  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19700/20565]  eta: 0:04:32  lr: 0.000014  loss: 3.1715  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19750/20565]  eta: 0:04:17  lr: 0.000014  loss: 2.9527  time: 0.3179  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19800/20565]  eta: 0:04:01  lr: 0.000014  loss: 2.1437  time: 0.3169  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19850/20565]  eta: 0:03:45  lr: 0.000014  loss: 3.6732  time: 0.3166  data: 0.0003  max mem: 14771\n","Train Epoch: [3]  [19900/20565]  eta: 0:03:29  lr: 0.000014  loss: 2.7153  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [19950/20565]  eta: 0:03:13  lr: 0.000014  loss: 3.9572  time: 0.3183  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20000/20565]  eta: 0:02:58  lr: 0.000014  loss: 3.6826  time: 0.3163  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20050/20565]  eta: 0:02:42  lr: 0.000014  loss: 2.7260  time: 0.3128  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20100/20565]  eta: 0:02:26  lr: 0.000014  loss: 2.4206  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20150/20565]  eta: 0:02:10  lr: 0.000014  loss: 3.2031  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20200/20565]  eta: 0:01:55  lr: 0.000014  loss: 3.2784  time: 0.3188  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20250/20565]  eta: 0:01:39  lr: 0.000014  loss: 2.5272  time: 0.3130  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20300/20565]  eta: 0:01:23  lr: 0.000014  loss: 3.1563  time: 0.3181  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20350/20565]  eta: 0:01:07  lr: 0.000014  loss: 2.3926  time: 0.3141  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20400/20565]  eta: 0:00:52  lr: 0.000014  loss: 2.7298  time: 0.3178  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20450/20565]  eta: 0:00:36  lr: 0.000014  loss: 2.8756  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20500/20565]  eta: 0:00:20  lr: 0.000014  loss: 3.0668  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20550/20565]  eta: 0:00:04  lr: 0.000014  loss: 3.1542  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [3]  [20564/20565]  eta: 0:00:00  lr: 0.000014  loss: 3.3567  time: 0.3177  data: 0.0024  max mem: 14771\n","Train Epoch: [3] Total time: 1:48:06 (0.3154 s / it)\n","Averaged stats: lr: 0.0000  loss: 3.1590\n"]},{"output_type":"stream","name":"stderr","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [4]  [    0/20565]  eta: 8:51:34  lr: 0.000011  loss: 3.2468  time: 1.5509  data: 1.1587  max mem: 14771\n","Train Epoch: [4]  [   50/20565]  eta: 1:56:55  lr: 0.000011  loss: 3.9336  time: 0.3192  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  100/20565]  eta: 1:52:20  lr: 0.000011  loss: 2.8361  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  150/20565]  eta: 1:50:37  lr: 0.000011  loss: 3.3046  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  200/20565]  eta: 1:49:35  lr: 0.000011  loss: 3.0243  time: 0.3183  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  250/20565]  eta: 1:48:47  lr: 0.000011  loss: 3.3898  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  300/20565]  eta: 1:48:10  lr: 0.000011  loss: 2.2508  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  350/20565]  eta: 1:47:38  lr: 0.000011  loss: 3.7915  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  400/20565]  eta: 1:47:10  lr: 0.000011  loss: 3.2578  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  450/20565]  eta: 1:46:44  lr: 0.000011  loss: 3.1108  time: 0.3123  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  500/20565]  eta: 1:46:21  lr: 0.000011  loss: 2.2959  time: 0.3139  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  550/20565]  eta: 1:45:59  lr: 0.000011  loss: 2.2086  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  600/20565]  eta: 1:45:39  lr: 0.000011  loss: 4.0951  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  650/20565]  eta: 1:45:18  lr: 0.000011  loss: 2.5173  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  700/20565]  eta: 1:44:59  lr: 0.000011  loss: 3.3645  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  750/20565]  eta: 1:44:40  lr: 0.000011  loss: 3.4612  time: 0.3171  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  800/20565]  eta: 1:44:22  lr: 0.000011  loss: 4.3238  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  850/20565]  eta: 1:44:06  lr: 0.000011  loss: 2.8108  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  900/20565]  eta: 1:43:49  lr: 0.000011  loss: 2.8519  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [  950/20565]  eta: 1:43:33  lr: 0.000011  loss: 3.1783  time: 0.3177  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1000/20565]  eta: 1:43:16  lr: 0.000011  loss: 2.9907  time: 0.3166  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1050/20565]  eta: 1:42:59  lr: 0.000011  loss: 2.2409  time: 0.3160  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1100/20565]  eta: 1:42:40  lr: 0.000011  loss: 3.6781  time: 0.3131  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1150/20565]  eta: 1:42:25  lr: 0.000011  loss: 2.5696  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1200/20565]  eta: 1:42:09  lr: 0.000011  loss: 3.6491  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1250/20565]  eta: 1:41:52  lr: 0.000011  loss: 3.0779  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1300/20565]  eta: 1:41:36  lr: 0.000011  loss: 3.4591  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1350/20565]  eta: 1:41:18  lr: 0.000011  loss: 2.6287  time: 0.3128  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1400/20565]  eta: 1:41:01  lr: 0.000011  loss: 3.8811  time: 0.3141  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1450/20565]  eta: 1:40:44  lr: 0.000011  loss: 2.5541  time: 0.3128  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1500/20565]  eta: 1:40:27  lr: 0.000011  loss: 2.7011  time: 0.3143  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1550/20565]  eta: 1:40:10  lr: 0.000011  loss: 2.5385  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1600/20565]  eta: 1:39:54  lr: 0.000011  loss: 3.5527  time: 0.3177  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1650/20565]  eta: 1:39:39  lr: 0.000011  loss: 3.3796  time: 0.3178  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1700/20565]  eta: 1:39:23  lr: 0.000011  loss: 3.9600  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1750/20565]  eta: 1:39:07  lr: 0.000011  loss: 2.6280  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1800/20565]  eta: 1:38:52  lr: 0.000011  loss: 3.0418  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1850/20565]  eta: 1:38:35  lr: 0.000011  loss: 2.8046  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1900/20565]  eta: 1:38:18  lr: 0.000011  loss: 2.9647  time: 0.3131  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 1950/20565]  eta: 1:38:02  lr: 0.000011  loss: 2.7915  time: 0.3131  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2000/20565]  eta: 1:37:46  lr: 0.000011  loss: 2.6481  time: 0.3138  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2050/20565]  eta: 1:37:30  lr: 0.000011  loss: 3.0221  time: 0.3141  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2100/20565]  eta: 1:37:14  lr: 0.000011  loss: 3.2562  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2150/20565]  eta: 1:36:57  lr: 0.000011  loss: 2.5383  time: 0.3124  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2200/20565]  eta: 1:36:41  lr: 0.000011  loss: 2.1933  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2250/20565]  eta: 1:36:25  lr: 0.000011  loss: 2.4937  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2300/20565]  eta: 1:36:09  lr: 0.000011  loss: 3.0092  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2350/20565]  eta: 1:35:53  lr: 0.000011  loss: 3.0043  time: 0.3159  data: 0.0003  max mem: 14771\n","Train Epoch: [4]  [ 2400/20565]  eta: 1:35:37  lr: 0.000011  loss: 2.4889  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2450/20565]  eta: 1:35:21  lr: 0.000011  loss: 4.3774  time: 0.3169  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2500/20565]  eta: 1:35:05  lr: 0.000011  loss: 2.4019  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2550/20565]  eta: 1:34:49  lr: 0.000011  loss: 2.5807  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2600/20565]  eta: 1:34:32  lr: 0.000011  loss: 3.8343  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2650/20565]  eta: 1:34:16  lr: 0.000011  loss: 2.8771  time: 0.3138  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2700/20565]  eta: 1:34:00  lr: 0.000011  loss: 3.5418  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2750/20565]  eta: 1:33:44  lr: 0.000011  loss: 2.4966  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2800/20565]  eta: 1:33:28  lr: 0.000011  loss: 3.1599  time: 0.3165  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2850/20565]  eta: 1:33:12  lr: 0.000011  loss: 2.3876  time: 0.3125  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2900/20565]  eta: 1:32:56  lr: 0.000011  loss: 3.4282  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 2950/20565]  eta: 1:32:40  lr: 0.000011  loss: 3.3284  time: 0.3128  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3000/20565]  eta: 1:32:25  lr: 0.000011  loss: 3.2052  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3050/20565]  eta: 1:32:08  lr: 0.000011  loss: 2.6317  time: 0.3106  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3100/20565]  eta: 1:31:52  lr: 0.000011  loss: 3.9332  time: 0.3136  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3150/20565]  eta: 1:31:36  lr: 0.000011  loss: 3.5842  time: 0.3166  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3200/20565]  eta: 1:31:20  lr: 0.000011  loss: 3.4770  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3250/20565]  eta: 1:31:05  lr: 0.000011  loss: 3.3206  time: 0.3175  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3300/20565]  eta: 1:30:49  lr: 0.000011  loss: 2.6770  time: 0.3143  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3350/20565]  eta: 1:30:33  lr: 0.000011  loss: 3.0866  time: 0.3168  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3400/20565]  eta: 1:30:18  lr: 0.000011  loss: 4.1014  time: 0.3188  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3450/20565]  eta: 1:30:02  lr: 0.000011  loss: 3.0106  time: 0.3176  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3500/20565]  eta: 1:29:46  lr: 0.000011  loss: 2.3457  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3550/20565]  eta: 1:29:30  lr: 0.000011  loss: 3.5436  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3600/20565]  eta: 1:29:14  lr: 0.000011  loss: 2.5553  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3650/20565]  eta: 1:28:58  lr: 0.000011  loss: 2.7603  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3700/20565]  eta: 1:28:42  lr: 0.000011  loss: 2.9150  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3750/20565]  eta: 1:28:26  lr: 0.000011  loss: 4.1075  time: 0.3116  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3800/20565]  eta: 1:28:10  lr: 0.000011  loss: 3.1224  time: 0.3139  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3850/20565]  eta: 1:27:54  lr: 0.000011  loss: 3.1592  time: 0.3135  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3900/20565]  eta: 1:27:38  lr: 0.000011  loss: 2.6522  time: 0.3169  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 3950/20565]  eta: 1:27:22  lr: 0.000011  loss: 3.1881  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4000/20565]  eta: 1:27:06  lr: 0.000011  loss: 3.8026  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4050/20565]  eta: 1:26:51  lr: 0.000011  loss: 3.7078  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4100/20565]  eta: 1:26:35  lr: 0.000011  loss: 2.7025  time: 0.3185  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4150/20565]  eta: 1:26:19  lr: 0.000011  loss: 3.4375  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4200/20565]  eta: 1:26:03  lr: 0.000011  loss: 3.3804  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4250/20565]  eta: 1:25:47  lr: 0.000011  loss: 2.8457  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4300/20565]  eta: 1:25:31  lr: 0.000011  loss: 3.9209  time: 0.3136  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4350/20565]  eta: 1:25:16  lr: 0.000011  loss: 4.1937  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4400/20565]  eta: 1:25:00  lr: 0.000011  loss: 2.3109  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4450/20565]  eta: 1:24:44  lr: 0.000011  loss: 2.2890  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4500/20565]  eta: 1:24:28  lr: 0.000011  loss: 3.5887  time: 0.3176  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4550/20565]  eta: 1:24:13  lr: 0.000011  loss: 2.5334  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4600/20565]  eta: 1:23:57  lr: 0.000011  loss: 3.5200  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4650/20565]  eta: 1:23:41  lr: 0.000011  loss: 3.9462  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4700/20565]  eta: 1:23:25  lr: 0.000011  loss: 2.9637  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4750/20565]  eta: 1:23:09  lr: 0.000011  loss: 3.2888  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4800/20565]  eta: 1:22:53  lr: 0.000011  loss: 3.2382  time: 0.3130  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4850/20565]  eta: 1:22:38  lr: 0.000011  loss: 3.5460  time: 0.3182  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4900/20565]  eta: 1:22:22  lr: 0.000011  loss: 2.6642  time: 0.3187  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 4950/20565]  eta: 1:22:06  lr: 0.000011  loss: 3.5977  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5000/20565]  eta: 1:21:50  lr: 0.000011  loss: 2.9332  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5050/20565]  eta: 1:21:34  lr: 0.000011  loss: 3.2868  time: 0.3136  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5100/20565]  eta: 1:21:18  lr: 0.000011  loss: 3.4657  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5150/20565]  eta: 1:21:02  lr: 0.000011  loss: 4.1441  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5200/20565]  eta: 1:20:46  lr: 0.000011  loss: 3.0763  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5250/20565]  eta: 1:20:31  lr: 0.000011  loss: 2.6401  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5300/20565]  eta: 1:20:15  lr: 0.000011  loss: 2.7542  time: 0.3181  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5350/20565]  eta: 1:19:59  lr: 0.000011  loss: 4.7837  time: 0.3179  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5400/20565]  eta: 1:19:43  lr: 0.000011  loss: 2.7189  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5450/20565]  eta: 1:19:27  lr: 0.000011  loss: 3.9281  time: 0.3179  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5500/20565]  eta: 1:19:11  lr: 0.000011  loss: 2.7269  time: 0.3121  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5550/20565]  eta: 1:18:55  lr: 0.000011  loss: 3.1360  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5600/20565]  eta: 1:18:40  lr: 0.000011  loss: 4.3526  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5650/20565]  eta: 1:18:24  lr: 0.000011  loss: 3.0325  time: 0.3171  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5700/20565]  eta: 1:18:08  lr: 0.000011  loss: 4.2387  time: 0.3178  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5750/20565]  eta: 1:17:52  lr: 0.000011  loss: 2.7326  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5800/20565]  eta: 1:17:36  lr: 0.000011  loss: 1.9445  time: 0.3123  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5850/20565]  eta: 1:17:20  lr: 0.000011  loss: 2.7479  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5900/20565]  eta: 1:17:05  lr: 0.000011  loss: 3.2379  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 5950/20565]  eta: 1:16:49  lr: 0.000011  loss: 2.3550  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6000/20565]  eta: 1:16:33  lr: 0.000011  loss: 2.9900  time: 0.3165  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6050/20565]  eta: 1:16:17  lr: 0.000011  loss: 2.9237  time: 0.3187  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6100/20565]  eta: 1:16:01  lr: 0.000011  loss: 3.0127  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6150/20565]  eta: 1:15:46  lr: 0.000011  loss: 2.9773  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6200/20565]  eta: 1:15:30  lr: 0.000011  loss: 2.9827  time: 0.3165  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6250/20565]  eta: 1:15:14  lr: 0.000011  loss: 3.0940  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6300/20565]  eta: 1:14:58  lr: 0.000011  loss: 3.7481  time: 0.3168  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6350/20565]  eta: 1:14:42  lr: 0.000011  loss: 2.9989  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6400/20565]  eta: 1:14:27  lr: 0.000011  loss: 3.5329  time: 0.3170  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6450/20565]  eta: 1:14:11  lr: 0.000011  loss: 3.0467  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6500/20565]  eta: 1:13:55  lr: 0.000011  loss: 3.8092  time: 0.3139  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6550/20565]  eta: 1:13:39  lr: 0.000011  loss: 2.9334  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6600/20565]  eta: 1:13:23  lr: 0.000011  loss: 2.3852  time: 0.3136  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6650/20565]  eta: 1:13:07  lr: 0.000011  loss: 4.1177  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6700/20565]  eta: 1:12:52  lr: 0.000011  loss: 2.4848  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6750/20565]  eta: 1:12:36  lr: 0.000011  loss: 3.5364  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6800/20565]  eta: 1:12:20  lr: 0.000011  loss: 3.5145  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6850/20565]  eta: 1:12:09  lr: 0.000011  loss: 3.2679  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6900/20565]  eta: 1:11:54  lr: 0.000011  loss: 3.6864  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 6950/20565]  eta: 1:11:38  lr: 0.000011  loss: 2.7973  time: 0.3156  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7000/20565]  eta: 1:11:22  lr: 0.000011  loss: 3.3742  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7050/20565]  eta: 1:11:06  lr: 0.000011  loss: 3.0333  time: 0.3130  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7100/20565]  eta: 1:10:50  lr: 0.000011  loss: 3.3840  time: 0.3131  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7150/20565]  eta: 1:10:34  lr: 0.000011  loss: 3.3475  time: 0.3131  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7200/20565]  eta: 1:10:18  lr: 0.000011  loss: 2.8592  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7250/20565]  eta: 1:10:02  lr: 0.000011  loss: 3.1759  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7300/20565]  eta: 1:09:47  lr: 0.000011  loss: 3.7585  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7350/20565]  eta: 1:09:31  lr: 0.000011  loss: 2.5766  time: 0.3105  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7400/20565]  eta: 1:09:15  lr: 0.000011  loss: 3.8567  time: 0.3166  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7450/20565]  eta: 1:08:59  lr: 0.000011  loss: 3.9230  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7500/20565]  eta: 1:08:43  lr: 0.000011  loss: 3.4166  time: 0.3193  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7550/20565]  eta: 1:08:27  lr: 0.000011  loss: 2.5364  time: 0.3143  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7600/20565]  eta: 1:08:12  lr: 0.000011  loss: 3.2585  time: 0.3174  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7650/20565]  eta: 1:07:56  lr: 0.000011  loss: 3.2063  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7700/20565]  eta: 1:07:40  lr: 0.000011  loss: 2.9704  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7750/20565]  eta: 1:07:24  lr: 0.000011  loss: 2.8227  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7800/20565]  eta: 1:07:08  lr: 0.000011  loss: 4.3178  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7850/20565]  eta: 1:06:53  lr: 0.000011  loss: 4.1990  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7900/20565]  eta: 1:06:37  lr: 0.000011  loss: 3.2759  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 7950/20565]  eta: 1:06:21  lr: 0.000011  loss: 3.3850  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8000/20565]  eta: 1:06:05  lr: 0.000011  loss: 2.7671  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8050/20565]  eta: 1:05:49  lr: 0.000011  loss: 2.7956  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8100/20565]  eta: 1:05:33  lr: 0.000011  loss: 3.5918  time: 0.3120  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8150/20565]  eta: 1:05:18  lr: 0.000011  loss: 3.0359  time: 0.3125  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8200/20565]  eta: 1:05:02  lr: 0.000011  loss: 2.7345  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8250/20565]  eta: 1:04:46  lr: 0.000011  loss: 3.2595  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8300/20565]  eta: 1:04:30  lr: 0.000011  loss: 2.9668  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8350/20565]  eta: 1:04:15  lr: 0.000011  loss: 3.8823  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8400/20565]  eta: 1:03:59  lr: 0.000011  loss: 2.8665  time: 0.3164  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8450/20565]  eta: 1:03:43  lr: 0.000011  loss: 2.6825  time: 0.3184  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8500/20565]  eta: 1:03:27  lr: 0.000011  loss: 2.8387  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8550/20565]  eta: 1:03:11  lr: 0.000011  loss: 3.5063  time: 0.3166  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8600/20565]  eta: 1:02:56  lr: 0.000011  loss: 3.2110  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8650/20565]  eta: 1:02:40  lr: 0.000011  loss: 2.1066  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8700/20565]  eta: 1:02:24  lr: 0.000011  loss: 3.1786  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8750/20565]  eta: 1:02:08  lr: 0.000011  loss: 3.3442  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8800/20565]  eta: 1:01:52  lr: 0.000011  loss: 3.1158  time: 0.3136  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8850/20565]  eta: 1:01:37  lr: 0.000011  loss: 3.3814  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8900/20565]  eta: 1:01:21  lr: 0.000011  loss: 2.8901  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 8950/20565]  eta: 1:01:05  lr: 0.000011  loss: 3.7850  time: 0.3160  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9000/20565]  eta: 1:00:49  lr: 0.000011  loss: 2.6255  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9050/20565]  eta: 1:00:33  lr: 0.000011  loss: 2.6497  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9100/20565]  eta: 1:00:17  lr: 0.000011  loss: 3.0045  time: 0.3158  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9150/20565]  eta: 1:00:02  lr: 0.000011  loss: 2.1671  time: 0.3136  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9200/20565]  eta: 0:59:46  lr: 0.000011  loss: 2.9977  time: 0.3131  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9250/20565]  eta: 0:59:30  lr: 0.000011  loss: 3.7499  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9300/20565]  eta: 0:59:14  lr: 0.000011  loss: 3.0443  time: 0.3142  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9350/20565]  eta: 0:58:58  lr: 0.000011  loss: 2.2516  time: 0.3133  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9400/20565]  eta: 0:58:43  lr: 0.000011  loss: 3.2477  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9450/20565]  eta: 0:58:27  lr: 0.000011  loss: 1.8489  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9500/20565]  eta: 0:58:11  lr: 0.000011  loss: 4.4846  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9550/20565]  eta: 0:57:55  lr: 0.000011  loss: 2.9229  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9600/20565]  eta: 0:57:39  lr: 0.000011  loss: 3.3918  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9650/20565]  eta: 0:57:24  lr: 0.000011  loss: 2.0983  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9700/20565]  eta: 0:57:08  lr: 0.000011  loss: 3.9051  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9750/20565]  eta: 0:56:52  lr: 0.000011  loss: 2.2018  time: 0.3187  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9800/20565]  eta: 0:56:37  lr: 0.000011  loss: 2.8377  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9850/20565]  eta: 0:56:21  lr: 0.000011  loss: 3.7976  time: 0.3166  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9900/20565]  eta: 0:56:05  lr: 0.000011  loss: 2.9809  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [ 9950/20565]  eta: 0:55:49  lr: 0.000011  loss: 3.1466  time: 0.3139  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10000/20565]  eta: 0:55:33  lr: 0.000011  loss: 4.3601  time: 0.3138  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10050/20565]  eta: 0:55:17  lr: 0.000011  loss: 2.4855  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10100/20565]  eta: 0:55:02  lr: 0.000011  loss: 3.2135  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10150/20565]  eta: 0:54:46  lr: 0.000011  loss: 2.8850  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10200/20565]  eta: 0:54:30  lr: 0.000011  loss: 2.9872  time: 0.3139  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10250/20565]  eta: 0:54:14  lr: 0.000011  loss: 2.7683  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10300/20565]  eta: 0:53:58  lr: 0.000011  loss: 2.6981  time: 0.3137  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10350/20565]  eta: 0:53:43  lr: 0.000011  loss: 2.3258  time: 0.3126  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10400/20565]  eta: 0:53:27  lr: 0.000011  loss: 3.6880  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10450/20565]  eta: 0:53:11  lr: 0.000011  loss: 3.7682  time: 0.3178  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10500/20565]  eta: 0:52:55  lr: 0.000011  loss: 3.5313  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10550/20565]  eta: 0:52:39  lr: 0.000011  loss: 3.3787  time: 0.3182  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10600/20565]  eta: 0:52:24  lr: 0.000011  loss: 2.8389  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10650/20565]  eta: 0:52:08  lr: 0.000011  loss: 2.1101  time: 0.3196  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10700/20565]  eta: 0:51:52  lr: 0.000011  loss: 2.2425  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10750/20565]  eta: 0:51:37  lr: 0.000011  loss: 3.7950  time: 0.3169  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10800/20565]  eta: 0:51:21  lr: 0.000011  loss: 2.2815  time: 0.3145  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10850/20565]  eta: 0:51:05  lr: 0.000011  loss: 2.8912  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10900/20565]  eta: 0:50:49  lr: 0.000011  loss: 2.5933  time: 0.3181  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [10950/20565]  eta: 0:50:34  lr: 0.000011  loss: 3.0856  time: 0.3163  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11000/20565]  eta: 0:50:18  lr: 0.000011  loss: 2.6808  time: 0.3163  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11050/20565]  eta: 0:50:02  lr: 0.000011  loss: 3.8637  time: 0.3118  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11100/20565]  eta: 0:49:46  lr: 0.000011  loss: 2.9278  time: 0.3116  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11150/20565]  eta: 0:49:30  lr: 0.000011  loss: 2.7691  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11200/20565]  eta: 0:49:15  lr: 0.000011  loss: 3.6857  time: 0.3157  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11250/20565]  eta: 0:48:59  lr: 0.000011  loss: 3.4364  time: 0.3134  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11300/20565]  eta: 0:48:43  lr: 0.000011  loss: 5.0226  time: 0.3191  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11350/20565]  eta: 0:48:27  lr: 0.000011  loss: 2.8655  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11400/20565]  eta: 0:48:12  lr: 0.000011  loss: 3.5591  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11450/20565]  eta: 0:47:56  lr: 0.000011  loss: 3.1106  time: 0.3131  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11500/20565]  eta: 0:47:40  lr: 0.000011  loss: 3.3181  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11550/20565]  eta: 0:47:24  lr: 0.000011  loss: 3.2029  time: 0.3174  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11600/20565]  eta: 0:47:08  lr: 0.000011  loss: 2.8098  time: 0.3131  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11650/20565]  eta: 0:46:53  lr: 0.000011  loss: 2.7823  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11700/20565]  eta: 0:46:37  lr: 0.000011  loss: 3.1431  time: 0.3138  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11750/20565]  eta: 0:46:21  lr: 0.000011  loss: 3.1870  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11800/20565]  eta: 0:46:05  lr: 0.000011  loss: 3.5079  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11850/20565]  eta: 0:45:49  lr: 0.000011  loss: 2.9864  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11900/20565]  eta: 0:45:34  lr: 0.000011  loss: 4.1036  time: 0.3179  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [11950/20565]  eta: 0:45:18  lr: 0.000011  loss: 2.9902  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12000/20565]  eta: 0:45:02  lr: 0.000011  loss: 2.5709  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12050/20565]  eta: 0:44:46  lr: 0.000011  loss: 2.7699  time: 0.3144  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12100/20565]  eta: 0:44:31  lr: 0.000011  loss: 2.9682  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12150/20565]  eta: 0:44:15  lr: 0.000011  loss: 3.1863  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12200/20565]  eta: 0:43:59  lr: 0.000011  loss: 3.6921  time: 0.3169  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12250/20565]  eta: 0:43:43  lr: 0.000011  loss: 3.5452  time: 0.3143  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12300/20565]  eta: 0:43:28  lr: 0.000011  loss: 3.7754  time: 0.3162  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12350/20565]  eta: 0:43:12  lr: 0.000011  loss: 3.2754  time: 0.3150  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12400/20565]  eta: 0:42:56  lr: 0.000011  loss: 2.5618  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12450/20565]  eta: 0:42:40  lr: 0.000011  loss: 2.7705  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12500/20565]  eta: 0:42:24  lr: 0.000011  loss: 1.9957  time: 0.3172  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12550/20565]  eta: 0:42:09  lr: 0.000011  loss: 3.1006  time: 0.3143  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12600/20565]  eta: 0:41:53  lr: 0.000011  loss: 3.8145  time: 0.3154  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12650/20565]  eta: 0:41:37  lr: 0.000011  loss: 2.7827  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12700/20565]  eta: 0:41:21  lr: 0.000011  loss: 3.1154  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12750/20565]  eta: 0:41:05  lr: 0.000011  loss: 2.7176  time: 0.3147  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12800/20565]  eta: 0:40:50  lr: 0.000011  loss: 2.7195  time: 0.3159  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12850/20565]  eta: 0:40:34  lr: 0.000011  loss: 3.2339  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12900/20565]  eta: 0:40:18  lr: 0.000011  loss: 2.8840  time: 0.3141  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [12950/20565]  eta: 0:40:02  lr: 0.000011  loss: 3.1566  time: 0.3182  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13000/20565]  eta: 0:39:46  lr: 0.000011  loss: 2.9291  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13050/20565]  eta: 0:39:31  lr: 0.000011  loss: 4.2031  time: 0.3125  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13100/20565]  eta: 0:39:15  lr: 0.000011  loss: 3.2015  time: 0.3140  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13150/20565]  eta: 0:38:59  lr: 0.000011  loss: 2.5340  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13200/20565]  eta: 0:38:43  lr: 0.000011  loss: 3.3067  time: 0.3167  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13250/20565]  eta: 0:38:28  lr: 0.000011  loss: 2.8400  time: 0.3114  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13300/20565]  eta: 0:38:12  lr: 0.000011  loss: 3.3422  time: 0.3152  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13350/20565]  eta: 0:37:56  lr: 0.000011  loss: 2.9586  time: 0.3149  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13400/20565]  eta: 0:37:40  lr: 0.000011  loss: 3.8585  time: 0.3166  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13450/20565]  eta: 0:37:24  lr: 0.000011  loss: 3.7346  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13500/20565]  eta: 0:37:09  lr: 0.000011  loss: 3.5861  time: 0.3153  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13550/20565]  eta: 0:36:53  lr: 0.000011  loss: 3.3430  time: 0.3120  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13600/20565]  eta: 0:36:37  lr: 0.000011  loss: 2.8925  time: 0.3125  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13650/20565]  eta: 0:36:21  lr: 0.000011  loss: 3.6012  time: 0.3132  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13700/20565]  eta: 0:36:05  lr: 0.000011  loss: 3.0693  time: 0.3175  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13750/20565]  eta: 0:35:50  lr: 0.000011  loss: 2.7567  time: 0.3165  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13800/20565]  eta: 0:35:34  lr: 0.000011  loss: 3.2482  time: 0.3173  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13850/20565]  eta: 0:35:18  lr: 0.000011  loss: 3.9050  time: 0.3155  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13900/20565]  eta: 0:35:02  lr: 0.000011  loss: 3.0180  time: 0.3146  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [13950/20565]  eta: 0:34:47  lr: 0.000011  loss: 2.7140  time: 0.3151  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [14000/20565]  eta: 0:34:31  lr: 0.000011  loss: 3.3084  time: 0.3161  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [14050/20565]  eta: 0:34:15  lr: 0.000011  loss: 2.8300  time: 0.3148  data: 0.0002  max mem: 14771\n","Train Epoch: [4]  [14100/20565]  eta: 0:33:59  lr: 0.000011  loss: 3.6582  time: 0.3182  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14150/20565]  eta: 0:33:44  lr: 0.000011  loss: 2.8573  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14200/20565]  eta: 0:33:28  lr: 0.000011  loss: 3.6022  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14250/20565]  eta: 0:33:12  lr: 0.000011  loss: 3.9694  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14300/20565]  eta: 0:32:56  lr: 0.000011  loss: 4.7042  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14350/20565]  eta: 0:32:40  lr: 0.000011  loss: 2.4070  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14400/20565]  eta: 0:32:24  lr: 0.000011  loss: 3.5642  time: 0.3128  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14450/20565]  eta: 0:32:09  lr: 0.000011  loss: 2.9851  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14500/20565]  eta: 0:31:53  lr: 0.000011  loss: 2.7704  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14550/20565]  eta: 0:31:37  lr: 0.000011  loss: 2.4159  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14600/20565]  eta: 0:31:21  lr: 0.000011  loss: 3.0207  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14650/20565]  eta: 0:31:06  lr: 0.000011  loss: 2.8278  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14700/20565]  eta: 0:30:50  lr: 0.000011  loss: 3.0411  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14750/20565]  eta: 0:30:34  lr: 0.000011  loss: 3.2030  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14800/20565]  eta: 0:30:18  lr: 0.000011  loss: 3.2438  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14850/20565]  eta: 0:30:02  lr: 0.000011  loss: 2.8595  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14900/20565]  eta: 0:29:47  lr: 0.000011  loss: 3.8139  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [14950/20565]  eta: 0:29:31  lr: 0.000011  loss: 3.0463  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15000/20565]  eta: 0:29:15  lr: 0.000011  loss: 2.9814  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15050/20565]  eta: 0:28:59  lr: 0.000011  loss: 3.8326  time: 0.3187  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15100/20565]  eta: 0:28:44  lr: 0.000011  loss: 2.6060  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15150/20565]  eta: 0:28:28  lr: 0.000011  loss: 2.8316  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15200/20565]  eta: 0:28:12  lr: 0.000011  loss: 3.9515  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15250/20565]  eta: 0:27:56  lr: 0.000011  loss: 3.9459  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15300/20565]  eta: 0:27:41  lr: 0.000011  loss: 4.7362  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15350/20565]  eta: 0:27:25  lr: 0.000011  loss: 1.8562  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15400/20565]  eta: 0:27:09  lr: 0.000011  loss: 2.2523  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15450/20565]  eta: 0:26:53  lr: 0.000011  loss: 2.7280  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15500/20565]  eta: 0:26:38  lr: 0.000011  loss: 3.1365  time: 0.3181  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15550/20565]  eta: 0:26:22  lr: 0.000011  loss: 2.6905  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15600/20565]  eta: 0:26:06  lr: 0.000011  loss: 3.2617  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15650/20565]  eta: 0:25:50  lr: 0.000011  loss: 3.2372  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15700/20565]  eta: 0:25:34  lr: 0.000011  loss: 2.4321  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15750/20565]  eta: 0:25:19  lr: 0.000011  loss: 2.9300  time: 0.3114  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15800/20565]  eta: 0:25:03  lr: 0.000011  loss: 2.4569  time: 0.3114  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15850/20565]  eta: 0:24:47  lr: 0.000011  loss: 2.4106  time: 0.3175  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15900/20565]  eta: 0:24:31  lr: 0.000011  loss: 2.3348  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [15950/20565]  eta: 0:24:15  lr: 0.000011  loss: 3.3317  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16000/20565]  eta: 0:24:00  lr: 0.000011  loss: 2.4605  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16050/20565]  eta: 0:23:44  lr: 0.000011  loss: 4.1000  time: 0.3189  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16100/20565]  eta: 0:23:28  lr: 0.000011  loss: 3.2515  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16150/20565]  eta: 0:23:12  lr: 0.000011  loss: 2.1239  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16200/20565]  eta: 0:22:57  lr: 0.000011  loss: 4.0712  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16250/20565]  eta: 0:22:41  lr: 0.000011  loss: 2.8904  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16300/20565]  eta: 0:22:25  lr: 0.000011  loss: 2.9987  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16350/20565]  eta: 0:22:09  lr: 0.000011  loss: 2.9752  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16400/20565]  eta: 0:21:54  lr: 0.000011  loss: 2.6782  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16450/20565]  eta: 0:21:38  lr: 0.000011  loss: 3.3808  time: 0.3111  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16500/20565]  eta: 0:21:22  lr: 0.000011  loss: 3.3019  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16550/20565]  eta: 0:21:06  lr: 0.000011  loss: 2.6145  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16600/20565]  eta: 0:20:50  lr: 0.000011  loss: 3.3080  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16650/20565]  eta: 0:20:35  lr: 0.000011  loss: 2.2723  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16700/20565]  eta: 0:20:19  lr: 0.000011  loss: 1.7586  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16750/20565]  eta: 0:20:03  lr: 0.000011  loss: 3.0993  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16800/20565]  eta: 0:19:47  lr: 0.000011  loss: 3.0908  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16850/20565]  eta: 0:19:32  lr: 0.000011  loss: 2.9825  time: 0.3124  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16900/20565]  eta: 0:19:16  lr: 0.000011  loss: 3.2458  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [16950/20565]  eta: 0:19:00  lr: 0.000011  loss: 2.8998  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17000/20565]  eta: 0:18:44  lr: 0.000011  loss: 2.7300  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17050/20565]  eta: 0:18:28  lr: 0.000011  loss: 3.0045  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17100/20565]  eta: 0:18:13  lr: 0.000011  loss: 3.2821  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17150/20565]  eta: 0:17:57  lr: 0.000011  loss: 2.7082  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17200/20565]  eta: 0:17:41  lr: 0.000011  loss: 3.0732  time: 0.3113  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17250/20565]  eta: 0:17:25  lr: 0.000011  loss: 3.2664  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17300/20565]  eta: 0:17:10  lr: 0.000011  loss: 3.6552  time: 0.3185  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17350/20565]  eta: 0:16:54  lr: 0.000011  loss: 3.6800  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17400/20565]  eta: 0:16:38  lr: 0.000011  loss: 3.1038  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17450/20565]  eta: 0:16:22  lr: 0.000011  loss: 2.4963  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17500/20565]  eta: 0:16:06  lr: 0.000011  loss: 3.0061  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17550/20565]  eta: 0:15:51  lr: 0.000011  loss: 2.9136  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17600/20565]  eta: 0:15:35  lr: 0.000011  loss: 2.7281  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17650/20565]  eta: 0:15:19  lr: 0.000011  loss: 2.8888  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17700/20565]  eta: 0:15:03  lr: 0.000011  loss: 2.4379  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17750/20565]  eta: 0:14:48  lr: 0.000011  loss: 3.9237  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17800/20565]  eta: 0:14:32  lr: 0.000011  loss: 3.1184  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17850/20565]  eta: 0:14:16  lr: 0.000011  loss: 2.4290  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17900/20565]  eta: 0:14:00  lr: 0.000011  loss: 4.0778  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [17950/20565]  eta: 0:13:44  lr: 0.000011  loss: 3.3999  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18000/20565]  eta: 0:13:29  lr: 0.000011  loss: 2.0437  time: 0.3121  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18050/20565]  eta: 0:13:13  lr: 0.000011  loss: 3.6114  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18100/20565]  eta: 0:12:57  lr: 0.000011  loss: 2.2868  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18150/20565]  eta: 0:12:41  lr: 0.000011  loss: 3.5438  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18200/20565]  eta: 0:12:26  lr: 0.000011  loss: 2.9195  time: 0.3126  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18250/20565]  eta: 0:12:10  lr: 0.000011  loss: 2.7412  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18300/20565]  eta: 0:11:54  lr: 0.000011  loss: 2.5478  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18350/20565]  eta: 0:11:38  lr: 0.000011  loss: 2.3448  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18400/20565]  eta: 0:11:22  lr: 0.000011  loss: 2.0972  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18450/20565]  eta: 0:11:07  lr: 0.000011  loss: 2.9254  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18500/20565]  eta: 0:10:51  lr: 0.000011  loss: 3.6315  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18550/20565]  eta: 0:10:35  lr: 0.000011  loss: 3.1753  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18600/20565]  eta: 0:10:19  lr: 0.000011  loss: 2.2041  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18650/20565]  eta: 0:10:04  lr: 0.000011  loss: 3.2809  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18700/20565]  eta: 0:09:48  lr: 0.000011  loss: 3.7852  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18750/20565]  eta: 0:09:32  lr: 0.000011  loss: 3.8729  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18800/20565]  eta: 0:09:16  lr: 0.000011  loss: 2.7395  time: 0.3122  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18850/20565]  eta: 0:09:00  lr: 0.000011  loss: 2.7722  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18900/20565]  eta: 0:08:45  lr: 0.000011  loss: 2.4163  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [18950/20565]  eta: 0:08:29  lr: 0.000011  loss: 3.3327  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19000/20565]  eta: 0:08:13  lr: 0.000011  loss: 2.5048  time: 0.3220  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19050/20565]  eta: 0:07:57  lr: 0.000011  loss: 3.3779  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19100/20565]  eta: 0:07:42  lr: 0.000011  loss: 2.7743  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19150/20565]  eta: 0:07:26  lr: 0.000011  loss: 2.8774  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19200/20565]  eta: 0:07:10  lr: 0.000011  loss: 3.4642  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19250/20565]  eta: 0:06:54  lr: 0.000011  loss: 3.2323  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19300/20565]  eta: 0:06:39  lr: 0.000011  loss: 2.8587  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19350/20565]  eta: 0:06:23  lr: 0.000011  loss: 3.3440  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19400/20565]  eta: 0:06:07  lr: 0.000011  loss: 3.2413  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19450/20565]  eta: 0:05:51  lr: 0.000011  loss: 3.3736  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19500/20565]  eta: 0:05:35  lr: 0.000011  loss: 3.0489  time: 0.3123  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19550/20565]  eta: 0:05:20  lr: 0.000011  loss: 3.1657  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19600/20565]  eta: 0:05:04  lr: 0.000011  loss: 2.4648  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19650/20565]  eta: 0:04:48  lr: 0.000011  loss: 2.6008  time: 0.3183  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19700/20565]  eta: 0:04:32  lr: 0.000011  loss: 2.9148  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19750/20565]  eta: 0:04:17  lr: 0.000011  loss: 2.9524  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19800/20565]  eta: 0:04:01  lr: 0.000011  loss: 3.1808  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19850/20565]  eta: 0:03:45  lr: 0.000011  loss: 2.9634  time: 0.3185  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19900/20565]  eta: 0:03:29  lr: 0.000011  loss: 3.4604  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [19950/20565]  eta: 0:03:13  lr: 0.000011  loss: 2.8274  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20000/20565]  eta: 0:02:58  lr: 0.000011  loss: 3.8860  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20050/20565]  eta: 0:02:42  lr: 0.000011  loss: 3.7297  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20100/20565]  eta: 0:02:26  lr: 0.000011  loss: 3.6024  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20150/20565]  eta: 0:02:10  lr: 0.000011  loss: 3.8267  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20200/20565]  eta: 0:01:55  lr: 0.000011  loss: 2.1629  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20250/20565]  eta: 0:01:39  lr: 0.000011  loss: 3.1785  time: 0.3177  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20300/20565]  eta: 0:01:23  lr: 0.000011  loss: 3.9599  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20350/20565]  eta: 0:01:07  lr: 0.000011  loss: 3.0788  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20400/20565]  eta: 0:00:52  lr: 0.000011  loss: 2.2368  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20450/20565]  eta: 0:00:36  lr: 0.000011  loss: 3.3517  time: 0.3189  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20500/20565]  eta: 0:00:20  lr: 0.000011  loss: 3.4899  time: 0.3187  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20550/20565]  eta: 0:00:04  lr: 0.000011  loss: 3.5191  time: 0.3187  data: 0.0002  max mem: 14940\n","Train Epoch: [4]  [20564/20565]  eta: 0:00:00  lr: 0.000011  loss: 3.0611  time: 0.3198  data: 0.0024  max mem: 14940\n","Train Epoch: [4] Total time: 1:48:08 (0.3155 s / it)\n","Averaged stats: lr: 0.0000  loss: 3.0849\n"]},{"output_type":"stream","name":"stderr","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [5]  [    0/20565]  eta: 8:51:52  lr: 0.000007  loss: 3.1205  time: 1.5518  data: 1.1831  max mem: 14940\n"]},{"output_type":"stream","name":"stderr","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [5]  [   50/20565]  eta: 1:57:17  lr: 0.000007  loss: 3.4401  time: 0.3202  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  100/20565]  eta: 1:52:49  lr: 0.000007  loss: 2.2705  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  150/20565]  eta: 1:50:46  lr: 0.000007  loss: 2.5417  time: 0.3177  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  200/20565]  eta: 1:49:37  lr: 0.000007  loss: 2.6248  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  250/20565]  eta: 1:48:50  lr: 0.000007  loss: 4.1115  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  300/20565]  eta: 1:48:09  lr: 0.000007  loss: 2.6093  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  350/20565]  eta: 1:47:36  lr: 0.000007  loss: 2.9761  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  400/20565]  eta: 1:47:11  lr: 0.000007  loss: 3.0725  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  450/20565]  eta: 1:46:46  lr: 0.000007  loss: 2.9033  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  500/20565]  eta: 1:46:23  lr: 0.000007  loss: 1.8677  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  550/20565]  eta: 1:45:58  lr: 0.000007  loss: 4.2483  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  600/20565]  eta: 1:45:38  lr: 0.000007  loss: 2.7154  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  650/20565]  eta: 1:45:18  lr: 0.000007  loss: 2.4792  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  700/20565]  eta: 1:44:59  lr: 0.000007  loss: 3.6617  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  750/20565]  eta: 1:44:41  lr: 0.000007  loss: 2.6717  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  800/20565]  eta: 1:44:24  lr: 0.000007  loss: 2.4748  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  850/20565]  eta: 1:44:06  lr: 0.000007  loss: 2.7585  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  900/20565]  eta: 1:43:50  lr: 0.000007  loss: 3.1846  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [  950/20565]  eta: 1:43:31  lr: 0.000007  loss: 3.4377  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1000/20565]  eta: 1:43:13  lr: 0.000007  loss: 2.0279  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1050/20565]  eta: 1:42:57  lr: 0.000007  loss: 3.1032  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1100/20565]  eta: 1:42:40  lr: 0.000007  loss: 3.0834  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1150/20565]  eta: 1:42:23  lr: 0.000007  loss: 3.3864  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1200/20565]  eta: 1:42:06  lr: 0.000007  loss: 3.1424  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1250/20565]  eta: 1:41:49  lr: 0.000007  loss: 3.5445  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1300/20565]  eta: 1:41:33  lr: 0.000007  loss: 3.0030  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1350/20565]  eta: 1:41:17  lr: 0.000007  loss: 2.6014  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1400/20565]  eta: 1:41:00  lr: 0.000007  loss: 2.7088  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1450/20565]  eta: 1:40:44  lr: 0.000007  loss: 2.3170  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1500/20565]  eta: 1:40:28  lr: 0.000007  loss: 2.1610  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1550/20565]  eta: 1:40:11  lr: 0.000007  loss: 2.5869  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1600/20565]  eta: 1:39:54  lr: 0.000007  loss: 2.9225  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1650/20565]  eta: 1:39:37  lr: 0.000007  loss: 2.8745  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1700/20565]  eta: 1:39:20  lr: 0.000007  loss: 2.9547  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1750/20565]  eta: 1:39:04  lr: 0.000007  loss: 2.6566  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1800/20565]  eta: 1:38:48  lr: 0.000007  loss: 3.0424  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1850/20565]  eta: 1:38:32  lr: 0.000007  loss: 2.2534  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1900/20565]  eta: 1:38:16  lr: 0.000007  loss: 3.0558  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 1950/20565]  eta: 1:37:59  lr: 0.000007  loss: 3.7753  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2000/20565]  eta: 1:37:42  lr: 0.000007  loss: 3.1542  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2050/20565]  eta: 1:37:26  lr: 0.000007  loss: 2.6292  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2100/20565]  eta: 1:37:10  lr: 0.000007  loss: 3.1804  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2150/20565]  eta: 1:36:54  lr: 0.000007  loss: 2.7703  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2200/20565]  eta: 1:36:38  lr: 0.000007  loss: 4.5708  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2250/20565]  eta: 1:36:22  lr: 0.000007  loss: 2.1361  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2300/20565]  eta: 1:36:07  lr: 0.000007  loss: 3.0154  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2350/20565]  eta: 1:35:51  lr: 0.000007  loss: 3.3951  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2400/20565]  eta: 1:35:35  lr: 0.000007  loss: 2.4363  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2450/20565]  eta: 1:35:18  lr: 0.000007  loss: 3.0851  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2500/20565]  eta: 1:35:02  lr: 0.000007  loss: 3.6290  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2550/20565]  eta: 1:34:46  lr: 0.000007  loss: 3.3059  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2600/20565]  eta: 1:34:30  lr: 0.000007  loss: 4.0459  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2650/20565]  eta: 1:34:14  lr: 0.000007  loss: 2.9701  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2700/20565]  eta: 1:33:58  lr: 0.000007  loss: 2.8906  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2750/20565]  eta: 1:33:43  lr: 0.000007  loss: 2.7688  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2800/20565]  eta: 1:33:27  lr: 0.000007  loss: 3.9147  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2850/20565]  eta: 1:33:11  lr: 0.000007  loss: 2.5698  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2900/20565]  eta: 1:32:55  lr: 0.000007  loss: 2.9695  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 2950/20565]  eta: 1:32:39  lr: 0.000007  loss: 3.5507  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3000/20565]  eta: 1:32:23  lr: 0.000007  loss: 3.4286  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3050/20565]  eta: 1:32:07  lr: 0.000007  loss: 1.9644  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3100/20565]  eta: 1:31:51  lr: 0.000007  loss: 3.0336  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3150/20565]  eta: 1:31:36  lr: 0.000007  loss: 2.0974  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3200/20565]  eta: 1:31:20  lr: 0.000007  loss: 2.7498  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3250/20565]  eta: 1:31:04  lr: 0.000007  loss: 2.8574  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3300/20565]  eta: 1:30:48  lr: 0.000007  loss: 2.8659  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3350/20565]  eta: 1:30:32  lr: 0.000007  loss: 3.4142  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3400/20565]  eta: 1:30:16  lr: 0.000007  loss: 3.3202  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3450/20565]  eta: 1:30:00  lr: 0.000007  loss: 3.7678  time: 0.3177  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3500/20565]  eta: 1:29:45  lr: 0.000007  loss: 2.4276  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3550/20565]  eta: 1:29:29  lr: 0.000007  loss: 2.8704  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3600/20565]  eta: 1:29:13  lr: 0.000007  loss: 2.8471  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3650/20565]  eta: 1:28:57  lr: 0.000007  loss: 2.5221  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3700/20565]  eta: 1:28:42  lr: 0.000007  loss: 2.1845  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3750/20565]  eta: 1:28:25  lr: 0.000007  loss: 2.9722  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3800/20565]  eta: 1:28:09  lr: 0.000007  loss: 2.3988  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3850/20565]  eta: 1:27:54  lr: 0.000007  loss: 3.2242  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3900/20565]  eta: 1:27:37  lr: 0.000007  loss: 3.2663  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 3950/20565]  eta: 1:27:22  lr: 0.000007  loss: 2.5122  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4000/20565]  eta: 1:27:06  lr: 0.000007  loss: 3.0514  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4050/20565]  eta: 1:26:51  lr: 0.000007  loss: 3.0880  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4100/20565]  eta: 1:26:35  lr: 0.000007  loss: 2.4693  time: 0.3191  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4150/20565]  eta: 1:26:19  lr: 0.000007  loss: 3.5268  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4200/20565]  eta: 1:26:04  lr: 0.000007  loss: 2.4933  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4250/20565]  eta: 1:25:48  lr: 0.000007  loss: 2.5269  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4300/20565]  eta: 1:25:32  lr: 0.000007  loss: 3.2366  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4350/20565]  eta: 1:25:16  lr: 0.000007  loss: 2.9225  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4400/20565]  eta: 1:25:00  lr: 0.000007  loss: 2.8849  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4450/20565]  eta: 1:24:44  lr: 0.000007  loss: 2.6510  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4500/20565]  eta: 1:24:29  lr: 0.000007  loss: 3.4587  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4550/20565]  eta: 1:24:13  lr: 0.000007  loss: 3.7815  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4600/20565]  eta: 1:23:57  lr: 0.000007  loss: 3.6334  time: 0.3180  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4650/20565]  eta: 1:23:41  lr: 0.000007  loss: 2.9865  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4700/20565]  eta: 1:23:25  lr: 0.000007  loss: 2.7529  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4750/20565]  eta: 1:23:10  lr: 0.000007  loss: 1.8749  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4800/20565]  eta: 1:22:54  lr: 0.000007  loss: 3.2934  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4850/20565]  eta: 1:22:38  lr: 0.000007  loss: 3.6646  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4900/20565]  eta: 1:22:22  lr: 0.000007  loss: 3.0369  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 4950/20565]  eta: 1:22:06  lr: 0.000007  loss: 2.8105  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5000/20565]  eta: 1:21:50  lr: 0.000007  loss: 3.4761  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5050/20565]  eta: 1:21:34  lr: 0.000007  loss: 3.0466  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5100/20565]  eta: 1:21:18  lr: 0.000007  loss: 2.1804  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5150/20565]  eta: 1:21:02  lr: 0.000007  loss: 3.0447  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5200/20565]  eta: 1:20:46  lr: 0.000007  loss: 2.9638  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5250/20565]  eta: 1:20:31  lr: 0.000007  loss: 2.7363  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5300/20565]  eta: 1:20:15  lr: 0.000007  loss: 3.3222  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5350/20565]  eta: 1:19:59  lr: 0.000007  loss: 2.4682  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5400/20565]  eta: 1:19:43  lr: 0.000007  loss: 3.0880  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5450/20565]  eta: 1:19:27  lr: 0.000007  loss: 2.7741  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5500/20565]  eta: 1:19:11  lr: 0.000007  loss: 2.7871  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5550/20565]  eta: 1:18:56  lr: 0.000007  loss: 2.7587  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5600/20565]  eta: 1:18:40  lr: 0.000007  loss: 2.0209  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5650/20565]  eta: 1:18:24  lr: 0.000007  loss: 2.2472  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5700/20565]  eta: 1:18:08  lr: 0.000007  loss: 2.9576  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5750/20565]  eta: 1:17:52  lr: 0.000007  loss: 2.4990  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5800/20565]  eta: 1:17:37  lr: 0.000007  loss: 2.7539  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5850/20565]  eta: 1:17:21  lr: 0.000007  loss: 4.1981  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5900/20565]  eta: 1:17:05  lr: 0.000007  loss: 3.9246  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 5950/20565]  eta: 1:16:49  lr: 0.000007  loss: 3.1548  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6000/20565]  eta: 1:16:33  lr: 0.000007  loss: 2.1354  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6050/20565]  eta: 1:16:17  lr: 0.000007  loss: 3.6545  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6100/20565]  eta: 1:16:01  lr: 0.000007  loss: 2.8213  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6150/20565]  eta: 1:15:46  lr: 0.000007  loss: 4.1937  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6200/20565]  eta: 1:15:30  lr: 0.000007  loss: 2.1920  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6250/20565]  eta: 1:15:14  lr: 0.000007  loss: 3.1342  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6300/20565]  eta: 1:14:58  lr: 0.000007  loss: 3.1192  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6350/20565]  eta: 1:14:42  lr: 0.000007  loss: 2.4703  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6400/20565]  eta: 1:14:26  lr: 0.000007  loss: 3.3208  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6450/20565]  eta: 1:14:11  lr: 0.000007  loss: 3.0812  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6500/20565]  eta: 1:13:55  lr: 0.000007  loss: 3.3619  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6550/20565]  eta: 1:13:39  lr: 0.000007  loss: 2.7357  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6600/20565]  eta: 1:13:23  lr: 0.000007  loss: 4.1303  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6650/20565]  eta: 1:13:07  lr: 0.000007  loss: 3.8256  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6700/20565]  eta: 1:12:52  lr: 0.000007  loss: 2.5139  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6750/20565]  eta: 1:12:36  lr: 0.000007  loss: 3.1647  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6800/20565]  eta: 1:12:20  lr: 0.000007  loss: 3.4763  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6850/20565]  eta: 1:12:04  lr: 0.000007  loss: 3.1799  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6900/20565]  eta: 1:11:49  lr: 0.000007  loss: 3.6789  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 6950/20565]  eta: 1:11:33  lr: 0.000007  loss: 3.3268  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7000/20565]  eta: 1:11:17  lr: 0.000007  loss: 2.3070  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7050/20565]  eta: 1:11:01  lr: 0.000007  loss: 2.5623  time: 0.3125  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7100/20565]  eta: 1:10:45  lr: 0.000007  loss: 2.5171  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7150/20565]  eta: 1:10:29  lr: 0.000007  loss: 3.0075  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7200/20565]  eta: 1:10:14  lr: 0.000007  loss: 3.3318  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7250/20565]  eta: 1:09:58  lr: 0.000007  loss: 2.7271  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7300/20565]  eta: 1:09:42  lr: 0.000007  loss: 3.6383  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7350/20565]  eta: 1:09:27  lr: 0.000007  loss: 4.0174  time: 0.3187  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7400/20565]  eta: 1:09:11  lr: 0.000007  loss: 2.5017  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7450/20565]  eta: 1:08:55  lr: 0.000007  loss: 3.2477  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7500/20565]  eta: 1:08:39  lr: 0.000007  loss: 3.6356  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7550/20565]  eta: 1:08:24  lr: 0.000007  loss: 3.3491  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7600/20565]  eta: 1:08:08  lr: 0.000007  loss: 4.2781  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7650/20565]  eta: 1:07:52  lr: 0.000007  loss: 3.4102  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7700/20565]  eta: 1:07:36  lr: 0.000007  loss: 2.9916  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7750/20565]  eta: 1:07:20  lr: 0.000007  loss: 2.4512  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7800/20565]  eta: 1:07:05  lr: 0.000007  loss: 3.2895  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7850/20565]  eta: 1:06:49  lr: 0.000007  loss: 2.7407  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7900/20565]  eta: 1:06:33  lr: 0.000007  loss: 2.8588  time: 0.3181  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 7950/20565]  eta: 1:06:17  lr: 0.000007  loss: 3.0183  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8000/20565]  eta: 1:06:02  lr: 0.000007  loss: 3.2607  time: 0.3180  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8050/20565]  eta: 1:05:46  lr: 0.000007  loss: 2.9568  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8100/20565]  eta: 1:05:30  lr: 0.000007  loss: 3.0584  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8150/20565]  eta: 1:05:14  lr: 0.000007  loss: 2.9390  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8200/20565]  eta: 1:04:59  lr: 0.000007  loss: 3.1393  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8250/20565]  eta: 1:04:43  lr: 0.000007  loss: 3.3656  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8300/20565]  eta: 1:04:27  lr: 0.000007  loss: 2.5059  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8350/20565]  eta: 1:04:11  lr: 0.000007  loss: 1.9964  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8400/20565]  eta: 1:03:56  lr: 0.000007  loss: 2.5773  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8450/20565]  eta: 1:03:40  lr: 0.000007  loss: 2.5590  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8500/20565]  eta: 1:03:24  lr: 0.000007  loss: 3.1220  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8550/20565]  eta: 1:03:08  lr: 0.000007  loss: 3.6769  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8600/20565]  eta: 1:02:53  lr: 0.000007  loss: 2.7992  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8650/20565]  eta: 1:02:37  lr: 0.000007  loss: 3.1804  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8700/20565]  eta: 1:02:21  lr: 0.000007  loss: 3.7329  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8750/20565]  eta: 1:02:06  lr: 0.000007  loss: 2.9290  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8800/20565]  eta: 1:01:50  lr: 0.000007  loss: 2.7599  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8850/20565]  eta: 1:01:34  lr: 0.000007  loss: 2.7875  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8900/20565]  eta: 1:01:18  lr: 0.000007  loss: 2.8155  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 8950/20565]  eta: 1:01:03  lr: 0.000007  loss: 3.9549  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9000/20565]  eta: 1:00:47  lr: 0.000007  loss: 3.5432  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9050/20565]  eta: 1:00:31  lr: 0.000007  loss: 2.7984  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9100/20565]  eta: 1:00:15  lr: 0.000007  loss: 3.1749  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9150/20565]  eta: 1:00:00  lr: 0.000007  loss: 2.7623  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9200/20565]  eta: 0:59:44  lr: 0.000007  loss: 3.4098  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9250/20565]  eta: 0:59:28  lr: 0.000007  loss: 2.6092  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9300/20565]  eta: 0:59:12  lr: 0.000007  loss: 3.4600  time: 0.3188  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9350/20565]  eta: 0:58:56  lr: 0.000007  loss: 2.8143  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9400/20565]  eta: 0:58:41  lr: 0.000007  loss: 3.6664  time: 0.3177  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9450/20565]  eta: 0:58:25  lr: 0.000007  loss: 3.7604  time: 0.3180  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9500/20565]  eta: 0:58:09  lr: 0.000007  loss: 3.3064  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9550/20565]  eta: 0:57:53  lr: 0.000007  loss: 3.0489  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9600/20565]  eta: 0:57:38  lr: 0.000007  loss: 2.6122  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9650/20565]  eta: 0:57:22  lr: 0.000007  loss: 2.4652  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9700/20565]  eta: 0:57:06  lr: 0.000007  loss: 2.8522  time: 0.3128  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9750/20565]  eta: 0:56:50  lr: 0.000007  loss: 3.1058  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9800/20565]  eta: 0:56:34  lr: 0.000007  loss: 3.1341  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9850/20565]  eta: 0:56:19  lr: 0.000007  loss: 2.3934  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9900/20565]  eta: 0:56:03  lr: 0.000007  loss: 2.5668  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [ 9950/20565]  eta: 0:55:47  lr: 0.000007  loss: 2.6663  time: 0.3177  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10000/20565]  eta: 0:55:31  lr: 0.000007  loss: 2.3409  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10050/20565]  eta: 0:55:16  lr: 0.000007  loss: 3.4522  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10100/20565]  eta: 0:55:00  lr: 0.000007  loss: 2.8573  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10150/20565]  eta: 0:54:44  lr: 0.000007  loss: 4.2424  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10200/20565]  eta: 0:54:28  lr: 0.000007  loss: 2.6057  time: 0.3121  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10250/20565]  eta: 0:54:12  lr: 0.000007  loss: 3.7900  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10300/20565]  eta: 0:53:57  lr: 0.000007  loss: 2.8714  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10350/20565]  eta: 0:53:41  lr: 0.000007  loss: 3.4315  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10400/20565]  eta: 0:53:25  lr: 0.000007  loss: 3.0431  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10450/20565]  eta: 0:53:09  lr: 0.000007  loss: 3.9802  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10500/20565]  eta: 0:52:54  lr: 0.000007  loss: 3.3708  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10550/20565]  eta: 0:52:38  lr: 0.000007  loss: 2.9634  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10600/20565]  eta: 0:52:22  lr: 0.000007  loss: 4.5690  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10650/20565]  eta: 0:52:06  lr: 0.000007  loss: 4.3181  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10700/20565]  eta: 0:51:50  lr: 0.000007  loss: 3.0205  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10750/20565]  eta: 0:51:35  lr: 0.000007  loss: 3.0085  time: 0.3112  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10800/20565]  eta: 0:51:19  lr: 0.000007  loss: 2.8128  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10850/20565]  eta: 0:51:03  lr: 0.000007  loss: 2.9894  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10900/20565]  eta: 0:50:47  lr: 0.000007  loss: 2.9386  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [10950/20565]  eta: 0:50:31  lr: 0.000007  loss: 3.2499  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11000/20565]  eta: 0:50:15  lr: 0.000007  loss: 2.6254  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11050/20565]  eta: 0:50:00  lr: 0.000007  loss: 3.5860  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11100/20565]  eta: 0:49:44  lr: 0.000007  loss: 2.9408  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11150/20565]  eta: 0:49:28  lr: 0.000007  loss: 2.3956  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11200/20565]  eta: 0:49:12  lr: 0.000007  loss: 2.5315  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11250/20565]  eta: 0:48:57  lr: 0.000007  loss: 2.5988  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11300/20565]  eta: 0:48:41  lr: 0.000007  loss: 3.0742  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11350/20565]  eta: 0:48:25  lr: 0.000007  loss: 3.3792  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11400/20565]  eta: 0:48:09  lr: 0.000007  loss: 2.5836  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11450/20565]  eta: 0:47:54  lr: 0.000007  loss: 2.5622  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11500/20565]  eta: 0:47:38  lr: 0.000007  loss: 3.1850  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11550/20565]  eta: 0:47:22  lr: 0.000007  loss: 1.7117  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11600/20565]  eta: 0:47:06  lr: 0.000007  loss: 2.9969  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11650/20565]  eta: 0:46:50  lr: 0.000007  loss: 2.8035  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11700/20565]  eta: 0:46:35  lr: 0.000007  loss: 3.3681  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11750/20565]  eta: 0:46:19  lr: 0.000007  loss: 3.4105  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11800/20565]  eta: 0:46:03  lr: 0.000007  loss: 2.5671  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11850/20565]  eta: 0:45:47  lr: 0.000007  loss: 3.3152  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11900/20565]  eta: 0:45:31  lr: 0.000007  loss: 2.9414  time: 0.3121  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [11950/20565]  eta: 0:45:16  lr: 0.000007  loss: 3.2952  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12000/20565]  eta: 0:45:00  lr: 0.000007  loss: 3.3078  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12050/20565]  eta: 0:44:44  lr: 0.000007  loss: 1.9439  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12100/20565]  eta: 0:44:28  lr: 0.000007  loss: 3.9753  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12150/20565]  eta: 0:44:13  lr: 0.000007  loss: 3.1197  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12200/20565]  eta: 0:43:57  lr: 0.000007  loss: 2.8867  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12250/20565]  eta: 0:43:41  lr: 0.000007  loss: 3.6320  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12300/20565]  eta: 0:43:25  lr: 0.000007  loss: 1.6671  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12350/20565]  eta: 0:43:10  lr: 0.000007  loss: 2.1903  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12400/20565]  eta: 0:42:54  lr: 0.000007  loss: 2.8099  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12450/20565]  eta: 0:42:38  lr: 0.000007  loss: 2.9484  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12500/20565]  eta: 0:42:22  lr: 0.000007  loss: 2.7184  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12550/20565]  eta: 0:42:06  lr: 0.000007  loss: 2.4942  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12600/20565]  eta: 0:41:51  lr: 0.000007  loss: 2.7598  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12650/20565]  eta: 0:41:35  lr: 0.000007  loss: 3.8634  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12700/20565]  eta: 0:41:19  lr: 0.000007  loss: 1.9109  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12750/20565]  eta: 0:41:03  lr: 0.000007  loss: 3.1907  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12800/20565]  eta: 0:40:48  lr: 0.000007  loss: 2.7892  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12850/20565]  eta: 0:40:32  lr: 0.000007  loss: 2.6391  time: 0.3119  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12900/20565]  eta: 0:40:16  lr: 0.000007  loss: 3.3603  time: 0.3119  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [12950/20565]  eta: 0:40:00  lr: 0.000007  loss: 2.8353  time: 0.3127  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13000/20565]  eta: 0:39:44  lr: 0.000007  loss: 2.4104  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13050/20565]  eta: 0:39:29  lr: 0.000007  loss: 2.8068  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13100/20565]  eta: 0:39:13  lr: 0.000007  loss: 3.0361  time: 0.3183  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13150/20565]  eta: 0:38:57  lr: 0.000007  loss: 3.6500  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13200/20565]  eta: 0:38:41  lr: 0.000007  loss: 3.4496  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13250/20565]  eta: 0:38:26  lr: 0.000007  loss: 2.3107  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13300/20565]  eta: 0:38:10  lr: 0.000007  loss: 3.9529  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13350/20565]  eta: 0:37:54  lr: 0.000007  loss: 2.3997  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13400/20565]  eta: 0:37:38  lr: 0.000007  loss: 3.2812  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13450/20565]  eta: 0:37:23  lr: 0.000007  loss: 3.7318  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13500/20565]  eta: 0:37:07  lr: 0.000007  loss: 3.0071  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13550/20565]  eta: 0:36:51  lr: 0.000007  loss: 3.2028  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13600/20565]  eta: 0:36:35  lr: 0.000007  loss: 2.4316  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13650/20565]  eta: 0:36:20  lr: 0.000007  loss: 2.9573  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13700/20565]  eta: 0:36:04  lr: 0.000007  loss: 2.9734  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13750/20565]  eta: 0:35:48  lr: 0.000007  loss: 3.0848  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13800/20565]  eta: 0:35:32  lr: 0.000007  loss: 3.4809  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13850/20565]  eta: 0:35:16  lr: 0.000007  loss: 2.1094  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13900/20565]  eta: 0:35:01  lr: 0.000007  loss: 3.0047  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [13950/20565]  eta: 0:34:45  lr: 0.000007  loss: 3.0950  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14000/20565]  eta: 0:34:29  lr: 0.000007  loss: 2.8336  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14050/20565]  eta: 0:34:13  lr: 0.000007  loss: 2.7431  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14100/20565]  eta: 0:33:58  lr: 0.000007  loss: 3.4200  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14150/20565]  eta: 0:33:42  lr: 0.000007  loss: 3.7587  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14200/20565]  eta: 0:33:26  lr: 0.000007  loss: 3.1393  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14250/20565]  eta: 0:33:10  lr: 0.000007  loss: 3.0580  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14300/20565]  eta: 0:32:55  lr: 0.000007  loss: 2.3076  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14350/20565]  eta: 0:32:39  lr: 0.000007  loss: 3.1874  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14400/20565]  eta: 0:32:23  lr: 0.000007  loss: 3.5915  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14450/20565]  eta: 0:32:07  lr: 0.000007  loss: 3.1523  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14500/20565]  eta: 0:31:51  lr: 0.000007  loss: 2.5109  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14550/20565]  eta: 0:31:36  lr: 0.000007  loss: 3.2743  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14600/20565]  eta: 0:31:20  lr: 0.000007  loss: 2.7242  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14650/20565]  eta: 0:31:04  lr: 0.000007  loss: 2.9305  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14700/20565]  eta: 0:30:48  lr: 0.000007  loss: 2.1787  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14750/20565]  eta: 0:30:33  lr: 0.000007  loss: 2.5821  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14800/20565]  eta: 0:30:17  lr: 0.000007  loss: 2.8878  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14850/20565]  eta: 0:30:01  lr: 0.000007  loss: 2.6683  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14900/20565]  eta: 0:29:45  lr: 0.000007  loss: 2.7856  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [14950/20565]  eta: 0:29:30  lr: 0.000007  loss: 3.2770  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15000/20565]  eta: 0:29:14  lr: 0.000007  loss: 3.0815  time: 0.3178  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15050/20565]  eta: 0:28:58  lr: 0.000007  loss: 2.9559  time: 0.3124  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15100/20565]  eta: 0:28:42  lr: 0.000007  loss: 2.8752  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15150/20565]  eta: 0:28:27  lr: 0.000007  loss: 2.6804  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15200/20565]  eta: 0:28:11  lr: 0.000007  loss: 2.7029  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15250/20565]  eta: 0:27:55  lr: 0.000007  loss: 2.5778  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15300/20565]  eta: 0:27:39  lr: 0.000007  loss: 3.3549  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15350/20565]  eta: 0:27:24  lr: 0.000007  loss: 3.2971  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15400/20565]  eta: 0:27:08  lr: 0.000007  loss: 2.8908  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15450/20565]  eta: 0:26:52  lr: 0.000007  loss: 3.3039  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15500/20565]  eta: 0:26:36  lr: 0.000007  loss: 3.5159  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15550/20565]  eta: 0:26:21  lr: 0.000007  loss: 2.7517  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15600/20565]  eta: 0:26:05  lr: 0.000007  loss: 2.5556  time: 0.3128  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15650/20565]  eta: 0:25:49  lr: 0.000007  loss: 4.6271  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15700/20565]  eta: 0:25:33  lr: 0.000007  loss: 2.7464  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15750/20565]  eta: 0:25:17  lr: 0.000007  loss: 3.5450  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15800/20565]  eta: 0:25:02  lr: 0.000007  loss: 3.3281  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15850/20565]  eta: 0:24:46  lr: 0.000007  loss: 2.7234  time: 0.3144  data: 0.0003  max mem: 14940\n","Train Epoch: [5]  [15900/20565]  eta: 0:24:30  lr: 0.000007  loss: 3.5522  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [15950/20565]  eta: 0:24:14  lr: 0.000007  loss: 3.4685  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16000/20565]  eta: 0:23:59  lr: 0.000007  loss: 2.9290  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16050/20565]  eta: 0:23:43  lr: 0.000007  loss: 3.0530  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16100/20565]  eta: 0:23:27  lr: 0.000007  loss: 3.3273  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16150/20565]  eta: 0:23:11  lr: 0.000007  loss: 4.4021  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16200/20565]  eta: 0:22:56  lr: 0.000007  loss: 3.4644  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16250/20565]  eta: 0:22:40  lr: 0.000007  loss: 3.3651  time: 0.3105  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16300/20565]  eta: 0:22:24  lr: 0.000007  loss: 2.5838  time: 0.3123  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16350/20565]  eta: 0:22:08  lr: 0.000007  loss: 2.5843  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16400/20565]  eta: 0:21:53  lr: 0.000007  loss: 2.8667  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16450/20565]  eta: 0:21:37  lr: 0.000007  loss: 3.5599  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16500/20565]  eta: 0:21:21  lr: 0.000007  loss: 2.5862  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16550/20565]  eta: 0:21:05  lr: 0.000007  loss: 2.6582  time: 0.3175  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16600/20565]  eta: 0:20:49  lr: 0.000007  loss: 2.9532  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16650/20565]  eta: 0:20:34  lr: 0.000007  loss: 2.7312  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16700/20565]  eta: 0:20:18  lr: 0.000007  loss: 3.4376  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16750/20565]  eta: 0:20:02  lr: 0.000007  loss: 3.0762  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16800/20565]  eta: 0:19:46  lr: 0.000007  loss: 2.6392  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16850/20565]  eta: 0:19:31  lr: 0.000007  loss: 2.2117  time: 0.3128  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16900/20565]  eta: 0:19:15  lr: 0.000007  loss: 3.4741  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [16950/20565]  eta: 0:18:59  lr: 0.000007  loss: 3.0721  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17000/20565]  eta: 0:18:43  lr: 0.000007  loss: 3.4356  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17050/20565]  eta: 0:18:28  lr: 0.000007  loss: 3.4791  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17100/20565]  eta: 0:18:12  lr: 0.000007  loss: 2.7361  time: 0.3118  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17150/20565]  eta: 0:17:56  lr: 0.000007  loss: 3.9464  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17200/20565]  eta: 0:17:40  lr: 0.000007  loss: 3.5121  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17250/20565]  eta: 0:17:25  lr: 0.000007  loss: 2.9449  time: 0.3187  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17300/20565]  eta: 0:17:09  lr: 0.000007  loss: 3.3989  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17350/20565]  eta: 0:16:53  lr: 0.000007  loss: 2.9130  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17400/20565]  eta: 0:16:37  lr: 0.000007  loss: 3.4944  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17450/20565]  eta: 0:16:21  lr: 0.000007  loss: 2.6518  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17500/20565]  eta: 0:16:06  lr: 0.000007  loss: 3.7872  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17550/20565]  eta: 0:15:50  lr: 0.000007  loss: 3.3663  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17600/20565]  eta: 0:15:34  lr: 0.000007  loss: 3.6091  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17650/20565]  eta: 0:15:19  lr: 0.000007  loss: 2.5055  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17700/20565]  eta: 0:15:03  lr: 0.000007  loss: 3.2215  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17750/20565]  eta: 0:14:47  lr: 0.000007  loss: 3.3802  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17800/20565]  eta: 0:14:32  lr: 0.000007  loss: 2.8915  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17850/20565]  eta: 0:14:16  lr: 0.000007  loss: 3.7943  time: 0.3115  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17900/20565]  eta: 0:14:00  lr: 0.000007  loss: 2.6004  time: 0.3200  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [17950/20565]  eta: 0:13:44  lr: 0.000007  loss: 2.9035  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18000/20565]  eta: 0:13:28  lr: 0.000007  loss: 4.4449  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18050/20565]  eta: 0:13:13  lr: 0.000007  loss: 2.6887  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18100/20565]  eta: 0:12:57  lr: 0.000007  loss: 2.7244  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18150/20565]  eta: 0:12:41  lr: 0.000007  loss: 2.0248  time: 0.3118  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18200/20565]  eta: 0:12:25  lr: 0.000007  loss: 2.5436  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18250/20565]  eta: 0:12:10  lr: 0.000007  loss: 3.2821  time: 0.3183  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18300/20565]  eta: 0:11:54  lr: 0.000007  loss: 2.5929  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18350/20565]  eta: 0:11:38  lr: 0.000007  loss: 4.5971  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18400/20565]  eta: 0:11:22  lr: 0.000007  loss: 3.3746  time: 0.3189  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18450/20565]  eta: 0:11:07  lr: 0.000007  loss: 3.2897  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18500/20565]  eta: 0:10:51  lr: 0.000007  loss: 2.4443  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18550/20565]  eta: 0:10:35  lr: 0.000007  loss: 2.9576  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18600/20565]  eta: 0:10:19  lr: 0.000007  loss: 3.4919  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18650/20565]  eta: 0:10:03  lr: 0.000007  loss: 2.3766  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18700/20565]  eta: 0:09:48  lr: 0.000007  loss: 3.4899  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18750/20565]  eta: 0:09:32  lr: 0.000007  loss: 3.1564  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18800/20565]  eta: 0:09:16  lr: 0.000007  loss: 2.2222  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18850/20565]  eta: 0:09:00  lr: 0.000007  loss: 3.6152  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18900/20565]  eta: 0:08:45  lr: 0.000007  loss: 3.9304  time: 0.3175  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [18950/20565]  eta: 0:08:29  lr: 0.000007  loss: 3.5724  time: 0.3114  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19000/20565]  eta: 0:08:13  lr: 0.000007  loss: 3.3682  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19050/20565]  eta: 0:07:57  lr: 0.000007  loss: 2.6797  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19100/20565]  eta: 0:07:42  lr: 0.000007  loss: 3.0815  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19150/20565]  eta: 0:07:26  lr: 0.000007  loss: 3.3885  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19200/20565]  eta: 0:07:10  lr: 0.000007  loss: 2.6579  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19250/20565]  eta: 0:06:54  lr: 0.000007  loss: 3.2598  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19300/20565]  eta: 0:06:38  lr: 0.000007  loss: 3.6035  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19350/20565]  eta: 0:06:23  lr: 0.000007  loss: 3.3652  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19400/20565]  eta: 0:06:07  lr: 0.000007  loss: 2.6485  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19450/20565]  eta: 0:05:51  lr: 0.000007  loss: 3.2422  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19500/20565]  eta: 0:05:35  lr: 0.000007  loss: 3.3277  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19550/20565]  eta: 0:05:20  lr: 0.000007  loss: 2.9439  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19600/20565]  eta: 0:05:04  lr: 0.000007  loss: 2.9417  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19650/20565]  eta: 0:04:48  lr: 0.000007  loss: 2.3112  time: 0.3127  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19700/20565]  eta: 0:04:32  lr: 0.000007  loss: 2.4802  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19750/20565]  eta: 0:04:17  lr: 0.000007  loss: 3.8954  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19800/20565]  eta: 0:04:01  lr: 0.000007  loss: 3.6420  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19850/20565]  eta: 0:03:45  lr: 0.000007  loss: 2.3021  time: 0.3188  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19900/20565]  eta: 0:03:29  lr: 0.000007  loss: 2.9744  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [19950/20565]  eta: 0:03:13  lr: 0.000007  loss: 3.3754  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20000/20565]  eta: 0:02:58  lr: 0.000007  loss: 4.5079  time: 0.3125  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20050/20565]  eta: 0:02:42  lr: 0.000007  loss: 2.9922  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20100/20565]  eta: 0:02:26  lr: 0.000007  loss: 2.5018  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20150/20565]  eta: 0:02:10  lr: 0.000007  loss: 2.1087  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20200/20565]  eta: 0:01:55  lr: 0.000007  loss: 2.7780  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20250/20565]  eta: 0:01:39  lr: 0.000007  loss: 3.3612  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20300/20565]  eta: 0:01:23  lr: 0.000007  loss: 3.3372  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20350/20565]  eta: 0:01:07  lr: 0.000007  loss: 2.5226  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20400/20565]  eta: 0:00:52  lr: 0.000007  loss: 3.6435  time: 0.3184  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20450/20565]  eta: 0:00:36  lr: 0.000007  loss: 3.0392  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20500/20565]  eta: 0:00:20  lr: 0.000007  loss: 3.1429  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20550/20565]  eta: 0:00:04  lr: 0.000007  loss: 2.6575  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [5]  [20564/20565]  eta: 0:00:00  lr: 0.000007  loss: 2.6638  time: 0.3175  data: 0.0022  max mem: 14940\n","Train Epoch: [5] Total time: 1:48:06 (0.3154 s / it)\n","Averaged stats: lr: 0.0000  loss: 3.0273\n"]},{"output_type":"stream","name":"stderr","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [6]  [    0/20565]  eta: 8:37:59  lr: 0.000004  loss: 2.3024  time: 1.5113  data: 1.1586  max mem: 14940\n","Train Epoch: [6]  [   50/20565]  eta: 1:56:55  lr: 0.000004  loss: 2.8837  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  100/20565]  eta: 1:52:24  lr: 0.000004  loss: 3.3647  time: 0.3177  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  150/20565]  eta: 1:50:42  lr: 0.000004  loss: 3.7999  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  200/20565]  eta: 1:49:29  lr: 0.000004  loss: 2.4904  time: 0.3126  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  250/20565]  eta: 1:48:43  lr: 0.000004  loss: 2.3861  time: 0.3126  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  300/20565]  eta: 1:48:08  lr: 0.000004  loss: 2.3969  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  350/20565]  eta: 1:47:33  lr: 0.000004  loss: 3.3599  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  400/20565]  eta: 1:47:10  lr: 0.000004  loss: 3.6550  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  450/20565]  eta: 1:46:46  lr: 0.000004  loss: 2.6726  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  500/20565]  eta: 1:46:21  lr: 0.000004  loss: 3.0526  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  550/20565]  eta: 1:45:59  lr: 0.000004  loss: 3.9859  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  600/20565]  eta: 1:45:39  lr: 0.000004  loss: 3.1956  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  650/20565]  eta: 1:45:20  lr: 0.000004  loss: 3.6291  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  700/20565]  eta: 1:44:59  lr: 0.000004  loss: 3.2396  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  750/20565]  eta: 1:44:44  lr: 0.000004  loss: 3.4708  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  800/20565]  eta: 1:44:26  lr: 0.000004  loss: 3.0644  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  850/20565]  eta: 1:44:09  lr: 0.000004  loss: 3.3020  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  900/20565]  eta: 1:43:52  lr: 0.000004  loss: 2.4854  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [  950/20565]  eta: 1:43:34  lr: 0.000004  loss: 3.1713  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1000/20565]  eta: 1:43:16  lr: 0.000004  loss: 2.2865  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1050/20565]  eta: 1:43:00  lr: 0.000004  loss: 3.2282  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1100/20565]  eta: 1:42:41  lr: 0.000004  loss: 2.8804  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1150/20565]  eta: 1:42:24  lr: 0.000004  loss: 3.2680  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1200/20565]  eta: 1:42:08  lr: 0.000004  loss: 3.4262  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1250/20565]  eta: 1:41:50  lr: 0.000004  loss: 2.8847  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1300/20565]  eta: 1:41:35  lr: 0.000004  loss: 2.7489  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1350/20565]  eta: 1:41:19  lr: 0.000004  loss: 2.6127  time: 0.3175  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1400/20565]  eta: 1:41:03  lr: 0.000004  loss: 2.7760  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1450/20565]  eta: 1:40:47  lr: 0.000004  loss: 2.7478  time: 0.3185  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1500/20565]  eta: 1:40:30  lr: 0.000004  loss: 3.4794  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1550/20565]  eta: 1:40:13  lr: 0.000004  loss: 2.4992  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1600/20565]  eta: 1:39:56  lr: 0.000004  loss: 3.0151  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1650/20565]  eta: 1:39:40  lr: 0.000004  loss: 2.9276  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1700/20565]  eta: 1:39:24  lr: 0.000004  loss: 1.6459  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1750/20565]  eta: 1:39:08  lr: 0.000004  loss: 2.6435  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1800/20565]  eta: 1:38:52  lr: 0.000004  loss: 3.2704  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1850/20565]  eta: 1:38:35  lr: 0.000004  loss: 4.0676  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1900/20565]  eta: 1:38:19  lr: 0.000004  loss: 3.1893  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 1950/20565]  eta: 1:38:02  lr: 0.000004  loss: 3.0790  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2000/20565]  eta: 1:37:46  lr: 0.000004  loss: 3.6563  time: 0.3187  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2050/20565]  eta: 1:37:31  lr: 0.000004  loss: 3.0474  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2100/20565]  eta: 1:37:15  lr: 0.000004  loss: 3.0427  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2150/20565]  eta: 1:36:59  lr: 0.000004  loss: 2.2120  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2200/20565]  eta: 1:36:42  lr: 0.000004  loss: 2.8429  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2250/20565]  eta: 1:36:27  lr: 0.000004  loss: 2.5802  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2300/20565]  eta: 1:36:11  lr: 0.000004  loss: 2.2312  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2350/20565]  eta: 1:35:55  lr: 0.000004  loss: 4.8279  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2400/20565]  eta: 1:35:39  lr: 0.000004  loss: 2.7926  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2450/20565]  eta: 1:35:23  lr: 0.000004  loss: 2.8141  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2500/20565]  eta: 1:35:08  lr: 0.000004  loss: 3.7882  time: 0.3185  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2550/20565]  eta: 1:34:52  lr: 0.000004  loss: 3.1435  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2600/20565]  eta: 1:34:36  lr: 0.000004  loss: 2.8409  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2650/20565]  eta: 1:34:21  lr: 0.000004  loss: 3.6151  time: 0.3180  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2700/20565]  eta: 1:34:05  lr: 0.000004  loss: 3.2958  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2750/20565]  eta: 1:33:49  lr: 0.000004  loss: 2.6877  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2800/20565]  eta: 1:33:33  lr: 0.000004  loss: 2.4730  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2850/20565]  eta: 1:33:17  lr: 0.000004  loss: 2.6129  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2900/20565]  eta: 1:33:02  lr: 0.000004  loss: 3.2880  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 2950/20565]  eta: 1:32:46  lr: 0.000004  loss: 3.3601  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3000/20565]  eta: 1:32:30  lr: 0.000004  loss: 2.3765  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3050/20565]  eta: 1:32:14  lr: 0.000004  loss: 2.8467  time: 0.3180  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3100/20565]  eta: 1:31:58  lr: 0.000004  loss: 1.8564  time: 0.3122  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3150/20565]  eta: 1:31:42  lr: 0.000004  loss: 2.2068  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3200/20565]  eta: 1:31:26  lr: 0.000004  loss: 3.5061  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3250/20565]  eta: 1:31:11  lr: 0.000004  loss: 3.1927  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3300/20565]  eta: 1:30:55  lr: 0.000004  loss: 3.2426  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3350/20565]  eta: 1:30:39  lr: 0.000004  loss: 2.8583  time: 0.3121  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3400/20565]  eta: 1:30:23  lr: 0.000004  loss: 2.8874  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3450/20565]  eta: 1:30:07  lr: 0.000004  loss: 3.2061  time: 0.3116  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3500/20565]  eta: 1:29:51  lr: 0.000004  loss: 3.4560  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3550/20565]  eta: 1:29:35  lr: 0.000004  loss: 4.3443  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3600/20565]  eta: 1:29:19  lr: 0.000004  loss: 2.7900  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3650/20565]  eta: 1:29:03  lr: 0.000004  loss: 3.3788  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3700/20565]  eta: 1:28:47  lr: 0.000004  loss: 3.6046  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3750/20565]  eta: 1:28:32  lr: 0.000004  loss: 3.6342  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3800/20565]  eta: 1:28:15  lr: 0.000004  loss: 2.7274  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3850/20565]  eta: 1:28:00  lr: 0.000004  loss: 2.7979  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3900/20565]  eta: 1:27:44  lr: 0.000004  loss: 3.5354  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 3950/20565]  eta: 1:27:28  lr: 0.000004  loss: 3.2641  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4000/20565]  eta: 1:27:12  lr: 0.000004  loss: 4.0339  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4050/20565]  eta: 1:26:56  lr: 0.000004  loss: 2.4162  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4100/20565]  eta: 1:26:40  lr: 0.000004  loss: 3.1527  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4150/20565]  eta: 1:26:24  lr: 0.000004  loss: 2.8174  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4200/20565]  eta: 1:26:08  lr: 0.000004  loss: 3.0204  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4250/20565]  eta: 1:25:52  lr: 0.000004  loss: 3.0524  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4300/20565]  eta: 1:25:36  lr: 0.000004  loss: 2.4394  time: 0.3182  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4350/20565]  eta: 1:25:21  lr: 0.000004  loss: 2.9653  time: 0.3177  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4400/20565]  eta: 1:25:04  lr: 0.000004  loss: 3.6765  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4450/20565]  eta: 1:24:49  lr: 0.000004  loss: 3.3246  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4500/20565]  eta: 1:24:33  lr: 0.000004  loss: 3.4318  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4550/20565]  eta: 1:24:17  lr: 0.000004  loss: 3.7206  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4600/20565]  eta: 1:24:01  lr: 0.000004  loss: 2.5038  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4650/20565]  eta: 1:23:45  lr: 0.000004  loss: 3.0376  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4700/20565]  eta: 1:23:30  lr: 0.000004  loss: 4.0561  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4750/20565]  eta: 1:23:14  lr: 0.000004  loss: 3.3567  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4800/20565]  eta: 1:22:58  lr: 0.000004  loss: 2.2331  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4850/20565]  eta: 1:22:42  lr: 0.000004  loss: 2.9715  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4900/20565]  eta: 1:22:26  lr: 0.000004  loss: 3.1744  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 4950/20565]  eta: 1:22:10  lr: 0.000004  loss: 2.8304  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5000/20565]  eta: 1:21:55  lr: 0.000004  loss: 2.7434  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5050/20565]  eta: 1:21:39  lr: 0.000004  loss: 3.2533  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5100/20565]  eta: 1:21:23  lr: 0.000004  loss: 2.8177  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5150/20565]  eta: 1:21:07  lr: 0.000004  loss: 2.9108  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5200/20565]  eta: 1:20:52  lr: 0.000004  loss: 3.1536  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5250/20565]  eta: 1:20:36  lr: 0.000004  loss: 2.7254  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5300/20565]  eta: 1:20:20  lr: 0.000004  loss: 2.4872  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5350/20565]  eta: 1:20:04  lr: 0.000004  loss: 3.4844  time: 0.3185  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5400/20565]  eta: 1:19:49  lr: 0.000004  loss: 3.1375  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5450/20565]  eta: 1:19:33  lr: 0.000004  loss: 2.2150  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5500/20565]  eta: 1:19:17  lr: 0.000004  loss: 3.5083  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5550/20565]  eta: 1:19:01  lr: 0.000004  loss: 2.5795  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5600/20565]  eta: 1:18:45  lr: 0.000004  loss: 2.7895  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5650/20565]  eta: 1:18:29  lr: 0.000004  loss: 2.7787  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5700/20565]  eta: 1:18:14  lr: 0.000004  loss: 3.1861  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5750/20565]  eta: 1:17:58  lr: 0.000004  loss: 3.0821  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5800/20565]  eta: 1:17:42  lr: 0.000004  loss: 2.4932  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5850/20565]  eta: 1:17:26  lr: 0.000004  loss: 3.1612  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5900/20565]  eta: 1:17:10  lr: 0.000004  loss: 2.7021  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 5950/20565]  eta: 1:16:54  lr: 0.000004  loss: 3.6032  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6000/20565]  eta: 1:16:39  lr: 0.000004  loss: 4.0672  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6050/20565]  eta: 1:16:23  lr: 0.000004  loss: 2.8068  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6100/20565]  eta: 1:16:07  lr: 0.000004  loss: 2.7803  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6150/20565]  eta: 1:15:51  lr: 0.000004  loss: 2.7783  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6200/20565]  eta: 1:15:35  lr: 0.000004  loss: 3.6703  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6250/20565]  eta: 1:15:19  lr: 0.000004  loss: 3.1690  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6300/20565]  eta: 1:15:03  lr: 0.000004  loss: 4.1738  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6350/20565]  eta: 1:14:47  lr: 0.000004  loss: 3.3749  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6400/20565]  eta: 1:14:32  lr: 0.000004  loss: 2.7066  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6450/20565]  eta: 1:14:16  lr: 0.000004  loss: 2.8385  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6500/20565]  eta: 1:14:00  lr: 0.000004  loss: 2.4751  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6550/20565]  eta: 1:13:44  lr: 0.000004  loss: 3.0888  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6600/20565]  eta: 1:13:28  lr: 0.000004  loss: 2.5162  time: 0.3178  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6650/20565]  eta: 1:13:12  lr: 0.000004  loss: 3.1528  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6700/20565]  eta: 1:12:56  lr: 0.000004  loss: 2.9325  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6750/20565]  eta: 1:12:41  lr: 0.000004  loss: 3.0064  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6800/20565]  eta: 1:12:25  lr: 0.000004  loss: 2.7774  time: 0.3178  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6850/20565]  eta: 1:12:09  lr: 0.000004  loss: 3.2780  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6900/20565]  eta: 1:11:53  lr: 0.000004  loss: 3.1864  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 6950/20565]  eta: 1:11:38  lr: 0.000004  loss: 2.2073  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7000/20565]  eta: 1:11:22  lr: 0.000004  loss: 2.6146  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7050/20565]  eta: 1:11:06  lr: 0.000004  loss: 3.4389  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7100/20565]  eta: 1:10:50  lr: 0.000004  loss: 2.9104  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7150/20565]  eta: 1:10:34  lr: 0.000004  loss: 3.2855  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7200/20565]  eta: 1:10:18  lr: 0.000004  loss: 3.5670  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7250/20565]  eta: 1:10:02  lr: 0.000004  loss: 1.9632  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7300/20565]  eta: 1:09:46  lr: 0.000004  loss: 2.7744  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7350/20565]  eta: 1:09:30  lr: 0.000004  loss: 3.5246  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7400/20565]  eta: 1:09:15  lr: 0.000004  loss: 3.2677  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7450/20565]  eta: 1:08:59  lr: 0.000004  loss: 2.7154  time: 0.3121  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7500/20565]  eta: 1:08:43  lr: 0.000004  loss: 3.5153  time: 0.3123  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7550/20565]  eta: 1:08:27  lr: 0.000004  loss: 2.7989  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7600/20565]  eta: 1:08:11  lr: 0.000004  loss: 2.6750  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7650/20565]  eta: 1:07:55  lr: 0.000004  loss: 2.9313  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7700/20565]  eta: 1:07:39  lr: 0.000004  loss: 2.2029  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7750/20565]  eta: 1:07:23  lr: 0.000004  loss: 2.7236  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7800/20565]  eta: 1:07:08  lr: 0.000004  loss: 3.7487  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7850/20565]  eta: 1:06:52  lr: 0.000004  loss: 2.9782  time: 0.3127  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7900/20565]  eta: 1:06:36  lr: 0.000004  loss: 3.4783  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 7950/20565]  eta: 1:06:20  lr: 0.000004  loss: 2.6855  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8000/20565]  eta: 1:06:04  lr: 0.000004  loss: 3.1805  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8050/20565]  eta: 1:05:48  lr: 0.000004  loss: 2.9825  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8100/20565]  eta: 1:05:33  lr: 0.000004  loss: 3.2931  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8150/20565]  eta: 1:05:17  lr: 0.000004  loss: 3.3395  time: 0.3180  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8200/20565]  eta: 1:05:01  lr: 0.000004  loss: 2.5780  time: 0.3116  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8250/20565]  eta: 1:04:45  lr: 0.000004  loss: 1.7264  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8300/20565]  eta: 1:04:29  lr: 0.000004  loss: 2.7340  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8350/20565]  eta: 1:04:14  lr: 0.000004  loss: 3.5635  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8400/20565]  eta: 1:03:58  lr: 0.000004  loss: 2.6608  time: 0.3126  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8450/20565]  eta: 1:03:42  lr: 0.000004  loss: 2.7969  time: 0.3125  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8500/20565]  eta: 1:03:26  lr: 0.000004  loss: 3.3188  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8550/20565]  eta: 1:03:10  lr: 0.000004  loss: 3.0241  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8600/20565]  eta: 1:02:54  lr: 0.000004  loss: 2.4989  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8650/20565]  eta: 1:02:38  lr: 0.000004  loss: 3.3440  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8700/20565]  eta: 1:02:23  lr: 0.000004  loss: 3.0260  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8750/20565]  eta: 1:02:07  lr: 0.000004  loss: 4.3143  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8800/20565]  eta: 1:01:51  lr: 0.000004  loss: 3.2982  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8850/20565]  eta: 1:01:35  lr: 0.000004  loss: 4.0001  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8900/20565]  eta: 1:01:19  lr: 0.000004  loss: 2.4392  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 8950/20565]  eta: 1:01:04  lr: 0.000004  loss: 3.8383  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9000/20565]  eta: 1:00:48  lr: 0.000004  loss: 2.6306  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9050/20565]  eta: 1:00:32  lr: 0.000004  loss: 3.3244  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9100/20565]  eta: 1:00:16  lr: 0.000004  loss: 2.8688  time: 0.3113  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9150/20565]  eta: 1:00:00  lr: 0.000004  loss: 3.3696  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9200/20565]  eta: 0:59:44  lr: 0.000004  loss: 2.6910  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9250/20565]  eta: 0:59:29  lr: 0.000004  loss: 2.3710  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9300/20565]  eta: 0:59:13  lr: 0.000004  loss: 3.4002  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9350/20565]  eta: 0:58:57  lr: 0.000004  loss: 2.8242  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9400/20565]  eta: 0:58:41  lr: 0.000004  loss: 3.0812  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9450/20565]  eta: 0:58:26  lr: 0.000004  loss: 2.4424  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9500/20565]  eta: 0:58:10  lr: 0.000004  loss: 3.3857  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9550/20565]  eta: 0:57:54  lr: 0.000004  loss: 2.5924  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9600/20565]  eta: 0:57:38  lr: 0.000004  loss: 3.2062  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9650/20565]  eta: 0:57:22  lr: 0.000004  loss: 3.6829  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9700/20565]  eta: 0:57:07  lr: 0.000004  loss: 2.5766  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9750/20565]  eta: 0:56:51  lr: 0.000004  loss: 3.6676  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9800/20565]  eta: 0:56:35  lr: 0.000004  loss: 2.6180  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9850/20565]  eta: 0:56:19  lr: 0.000004  loss: 3.5998  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9900/20565]  eta: 0:56:03  lr: 0.000004  loss: 3.9096  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [ 9950/20565]  eta: 0:55:48  lr: 0.000004  loss: 2.4231  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10000/20565]  eta: 0:55:32  lr: 0.000004  loss: 2.8589  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10050/20565]  eta: 0:55:16  lr: 0.000004  loss: 3.2012  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10100/20565]  eta: 0:55:00  lr: 0.000004  loss: 2.9553  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10150/20565]  eta: 0:54:44  lr: 0.000004  loss: 3.2404  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10200/20565]  eta: 0:54:29  lr: 0.000004  loss: 3.2503  time: 0.3126  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10250/20565]  eta: 0:54:13  lr: 0.000004  loss: 3.0336  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10300/20565]  eta: 0:53:57  lr: 0.000004  loss: 2.4811  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10350/20565]  eta: 0:53:41  lr: 0.000004  loss: 2.6124  time: 0.3124  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10400/20565]  eta: 0:53:25  lr: 0.000004  loss: 3.4834  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10450/20565]  eta: 0:53:10  lr: 0.000004  loss: 2.3469  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10500/20565]  eta: 0:52:54  lr: 0.000004  loss: 3.1104  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10550/20565]  eta: 0:52:38  lr: 0.000004  loss: 3.1137  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10600/20565]  eta: 0:52:22  lr: 0.000004  loss: 2.8172  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10650/20565]  eta: 0:52:06  lr: 0.000004  loss: 3.8215  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10700/20565]  eta: 0:51:51  lr: 0.000004  loss: 3.2267  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10750/20565]  eta: 0:51:35  lr: 0.000004  loss: 3.0142  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10800/20565]  eta: 0:51:19  lr: 0.000004  loss: 2.8360  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10850/20565]  eta: 0:51:03  lr: 0.000004  loss: 1.8397  time: 0.3124  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10900/20565]  eta: 0:50:47  lr: 0.000004  loss: 3.0571  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [10950/20565]  eta: 0:50:32  lr: 0.000004  loss: 3.0729  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11000/20565]  eta: 0:50:16  lr: 0.000004  loss: 3.3712  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11050/20565]  eta: 0:50:00  lr: 0.000004  loss: 3.1011  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11100/20565]  eta: 0:49:44  lr: 0.000004  loss: 2.1486  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11150/20565]  eta: 0:49:28  lr: 0.000004  loss: 2.8848  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11200/20565]  eta: 0:49:13  lr: 0.000004  loss: 3.2587  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11250/20565]  eta: 0:48:57  lr: 0.000004  loss: 3.2054  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11300/20565]  eta: 0:48:41  lr: 0.000004  loss: 3.0652  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11350/20565]  eta: 0:48:25  lr: 0.000004  loss: 2.1885  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11400/20565]  eta: 0:48:09  lr: 0.000004  loss: 3.5351  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11450/20565]  eta: 0:47:54  lr: 0.000004  loss: 1.9731  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11500/20565]  eta: 0:47:38  lr: 0.000004  loss: 3.4847  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11550/20565]  eta: 0:47:22  lr: 0.000004  loss: 3.4211  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11600/20565]  eta: 0:47:06  lr: 0.000004  loss: 4.4141  time: 0.3180  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11650/20565]  eta: 0:46:51  lr: 0.000004  loss: 3.3565  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11700/20565]  eta: 0:46:35  lr: 0.000004  loss: 3.0675  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11750/20565]  eta: 0:46:19  lr: 0.000004  loss: 3.0109  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11800/20565]  eta: 0:46:03  lr: 0.000004  loss: 3.5444  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11850/20565]  eta: 0:45:47  lr: 0.000004  loss: 4.1164  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11900/20565]  eta: 0:45:32  lr: 0.000004  loss: 2.6861  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [11950/20565]  eta: 0:45:16  lr: 0.000004  loss: 3.3092  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12000/20565]  eta: 0:45:00  lr: 0.000004  loss: 2.5507  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12050/20565]  eta: 0:44:44  lr: 0.000004  loss: 3.7044  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12100/20565]  eta: 0:44:28  lr: 0.000004  loss: 3.2333  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12150/20565]  eta: 0:44:13  lr: 0.000004  loss: 2.4127  time: 0.3127  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12200/20565]  eta: 0:43:57  lr: 0.000004  loss: 4.5364  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12250/20565]  eta: 0:43:41  lr: 0.000004  loss: 3.1526  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12300/20565]  eta: 0:43:25  lr: 0.000004  loss: 2.9613  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12350/20565]  eta: 0:43:10  lr: 0.000004  loss: 2.9023  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12400/20565]  eta: 0:42:54  lr: 0.000004  loss: 3.4556  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12450/20565]  eta: 0:42:38  lr: 0.000004  loss: 3.5040  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12500/20565]  eta: 0:42:22  lr: 0.000004  loss: 2.2067  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12550/20565]  eta: 0:42:07  lr: 0.000004  loss: 3.0282  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12600/20565]  eta: 0:41:51  lr: 0.000004  loss: 3.3922  time: 0.3184  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12650/20565]  eta: 0:41:35  lr: 0.000004  loss: 3.7184  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12700/20565]  eta: 0:41:19  lr: 0.000004  loss: 3.2665  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12750/20565]  eta: 0:41:04  lr: 0.000004  loss: 3.1040  time: 0.3204  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12800/20565]  eta: 0:40:48  lr: 0.000004  loss: 2.5489  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12850/20565]  eta: 0:40:32  lr: 0.000004  loss: 2.5321  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12900/20565]  eta: 0:40:16  lr: 0.000004  loss: 3.4535  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [12950/20565]  eta: 0:40:01  lr: 0.000004  loss: 3.0987  time: 0.3178  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13000/20565]  eta: 0:39:45  lr: 0.000004  loss: 3.3769  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13050/20565]  eta: 0:39:29  lr: 0.000004  loss: 2.9752  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13100/20565]  eta: 0:39:13  lr: 0.000004  loss: 2.0529  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13150/20565]  eta: 0:38:57  lr: 0.000004  loss: 3.0200  time: 0.3112  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13200/20565]  eta: 0:38:42  lr: 0.000004  loss: 2.8754  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13250/20565]  eta: 0:38:26  lr: 0.000004  loss: 3.1481  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13300/20565]  eta: 0:38:10  lr: 0.000004  loss: 3.4386  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13350/20565]  eta: 0:37:54  lr: 0.000004  loss: 2.7460  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13400/20565]  eta: 0:37:39  lr: 0.000004  loss: 4.3516  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13450/20565]  eta: 0:37:23  lr: 0.000004  loss: 3.1597  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13500/20565]  eta: 0:37:07  lr: 0.000004  loss: 3.0605  time: 0.3178  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13550/20565]  eta: 0:36:51  lr: 0.000004  loss: 2.7003  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13600/20565]  eta: 0:36:36  lr: 0.000004  loss: 2.7842  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13650/20565]  eta: 0:36:20  lr: 0.000004  loss: 3.1398  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13700/20565]  eta: 0:36:04  lr: 0.000004  loss: 2.7546  time: 0.3118  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13750/20565]  eta: 0:35:48  lr: 0.000004  loss: 3.5077  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13800/20565]  eta: 0:35:33  lr: 0.000004  loss: 2.1695  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13850/20565]  eta: 0:35:17  lr: 0.000004  loss: 2.9506  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13900/20565]  eta: 0:35:01  lr: 0.000004  loss: 2.9731  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [13950/20565]  eta: 0:34:45  lr: 0.000004  loss: 2.1730  time: 0.3191  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14000/20565]  eta: 0:34:29  lr: 0.000004  loss: 3.3391  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14050/20565]  eta: 0:34:14  lr: 0.000004  loss: 3.3522  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14100/20565]  eta: 0:33:58  lr: 0.000004  loss: 3.2456  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14150/20565]  eta: 0:33:42  lr: 0.000004  loss: 3.1004  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14200/20565]  eta: 0:33:26  lr: 0.000004  loss: 2.3443  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14250/20565]  eta: 0:33:11  lr: 0.000004  loss: 4.0256  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14300/20565]  eta: 0:32:55  lr: 0.000004  loss: 3.1843  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14350/20565]  eta: 0:32:39  lr: 0.000004  loss: 2.8883  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14400/20565]  eta: 0:32:23  lr: 0.000004  loss: 2.4714  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14450/20565]  eta: 0:32:08  lr: 0.000004  loss: 2.6504  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14500/20565]  eta: 0:31:52  lr: 0.000004  loss: 3.4462  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14550/20565]  eta: 0:31:36  lr: 0.000004  loss: 4.2190  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14600/20565]  eta: 0:31:20  lr: 0.000004  loss: 2.5142  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14650/20565]  eta: 0:31:04  lr: 0.000004  loss: 3.0008  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14700/20565]  eta: 0:30:49  lr: 0.000004  loss: 2.4383  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14750/20565]  eta: 0:30:33  lr: 0.000004  loss: 3.2163  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14800/20565]  eta: 0:30:17  lr: 0.000004  loss: 1.9626  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14850/20565]  eta: 0:30:01  lr: 0.000004  loss: 2.7113  time: 0.3182  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14900/20565]  eta: 0:29:46  lr: 0.000004  loss: 3.0961  time: 0.3127  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [14950/20565]  eta: 0:29:30  lr: 0.000004  loss: 2.9534  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15000/20565]  eta: 0:29:14  lr: 0.000004  loss: 3.8106  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15050/20565]  eta: 0:28:58  lr: 0.000004  loss: 2.9151  time: 0.3117  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15100/20565]  eta: 0:28:43  lr: 0.000004  loss: 2.7461  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15150/20565]  eta: 0:28:27  lr: 0.000004  loss: 3.6234  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15200/20565]  eta: 0:28:11  lr: 0.000004  loss: 4.0381  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15250/20565]  eta: 0:27:55  lr: 0.000004  loss: 2.7141  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15300/20565]  eta: 0:27:39  lr: 0.000004  loss: 2.8292  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15350/20565]  eta: 0:27:24  lr: 0.000004  loss: 3.4060  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15400/20565]  eta: 0:27:08  lr: 0.000004  loss: 3.1123  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15450/20565]  eta: 0:26:52  lr: 0.000004  loss: 2.8018  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15500/20565]  eta: 0:26:36  lr: 0.000004  loss: 2.5259  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15550/20565]  eta: 0:26:21  lr: 0.000004  loss: 2.5175  time: 0.3126  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15600/20565]  eta: 0:26:05  lr: 0.000004  loss: 2.9122  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15650/20565]  eta: 0:25:49  lr: 0.000004  loss: 3.7569  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15700/20565]  eta: 0:25:33  lr: 0.000004  loss: 2.6285  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15750/20565]  eta: 0:25:18  lr: 0.000004  loss: 3.1798  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15800/20565]  eta: 0:25:02  lr: 0.000004  loss: 3.4582  time: 0.3184  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15850/20565]  eta: 0:24:46  lr: 0.000004  loss: 3.4632  time: 0.3183  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15900/20565]  eta: 0:24:30  lr: 0.000004  loss: 3.5918  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [15950/20565]  eta: 0:24:15  lr: 0.000004  loss: 2.8876  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16000/20565]  eta: 0:23:59  lr: 0.000004  loss: 3.2957  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16050/20565]  eta: 0:23:43  lr: 0.000004  loss: 2.8336  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16100/20565]  eta: 0:23:27  lr: 0.000004  loss: 2.7450  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16150/20565]  eta: 0:23:12  lr: 0.000004  loss: 3.5085  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16200/20565]  eta: 0:22:56  lr: 0.000004  loss: 2.9037  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16250/20565]  eta: 0:22:40  lr: 0.000004  loss: 3.5484  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16300/20565]  eta: 0:22:24  lr: 0.000004  loss: 2.6325  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16350/20565]  eta: 0:22:08  lr: 0.000004  loss: 3.3820  time: 0.3191  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16400/20565]  eta: 0:21:53  lr: 0.000004  loss: 2.6380  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16450/20565]  eta: 0:21:37  lr: 0.000004  loss: 2.6084  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16500/20565]  eta: 0:21:21  lr: 0.000004  loss: 2.7283  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16550/20565]  eta: 0:21:05  lr: 0.000004  loss: 2.9296  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16600/20565]  eta: 0:20:50  lr: 0.000004  loss: 2.8465  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16650/20565]  eta: 0:20:34  lr: 0.000004  loss: 2.9745  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16700/20565]  eta: 0:20:18  lr: 0.000004  loss: 3.0976  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16750/20565]  eta: 0:20:02  lr: 0.000004  loss: 3.2849  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16800/20565]  eta: 0:19:47  lr: 0.000004  loss: 2.8437  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16850/20565]  eta: 0:19:31  lr: 0.000004  loss: 2.5569  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16900/20565]  eta: 0:19:15  lr: 0.000004  loss: 4.4596  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [16950/20565]  eta: 0:18:59  lr: 0.000004  loss: 3.2495  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17000/20565]  eta: 0:18:44  lr: 0.000004  loss: 3.0822  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17050/20565]  eta: 0:18:28  lr: 0.000004  loss: 3.5354  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17100/20565]  eta: 0:18:12  lr: 0.000004  loss: 3.7416  time: 0.3128  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17150/20565]  eta: 0:17:56  lr: 0.000004  loss: 2.2743  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17200/20565]  eta: 0:17:40  lr: 0.000004  loss: 2.9850  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17250/20565]  eta: 0:17:25  lr: 0.000004  loss: 2.7629  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17300/20565]  eta: 0:17:09  lr: 0.000004  loss: 2.3912  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17350/20565]  eta: 0:16:53  lr: 0.000004  loss: 3.2927  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17400/20565]  eta: 0:16:37  lr: 0.000004  loss: 2.6395  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17450/20565]  eta: 0:16:22  lr: 0.000004  loss: 2.8354  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17500/20565]  eta: 0:16:06  lr: 0.000004  loss: 2.4892  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17550/20565]  eta: 0:15:50  lr: 0.000004  loss: 3.5705  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17600/20565]  eta: 0:15:34  lr: 0.000004  loss: 3.6956  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17650/20565]  eta: 0:15:19  lr: 0.000004  loss: 3.3516  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17700/20565]  eta: 0:15:03  lr: 0.000004  loss: 3.9871  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17750/20565]  eta: 0:14:47  lr: 0.000004  loss: 3.3116  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17800/20565]  eta: 0:14:31  lr: 0.000004  loss: 2.3777  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17850/20565]  eta: 0:14:16  lr: 0.000004  loss: 2.5011  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17900/20565]  eta: 0:14:00  lr: 0.000004  loss: 3.1125  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [17950/20565]  eta: 0:13:44  lr: 0.000004  loss: 3.5123  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18000/20565]  eta: 0:13:28  lr: 0.000004  loss: 2.7250  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18050/20565]  eta: 0:13:13  lr: 0.000004  loss: 3.2064  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18100/20565]  eta: 0:12:57  lr: 0.000004  loss: 2.9179  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18150/20565]  eta: 0:12:41  lr: 0.000004  loss: 2.6170  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18200/20565]  eta: 0:12:25  lr: 0.000004  loss: 2.7562  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18250/20565]  eta: 0:12:09  lr: 0.000004  loss: 2.6170  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18300/20565]  eta: 0:11:54  lr: 0.000004  loss: 2.8996  time: 0.3116  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18350/20565]  eta: 0:11:38  lr: 0.000004  loss: 2.8314  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18400/20565]  eta: 0:11:22  lr: 0.000004  loss: 2.5600  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18450/20565]  eta: 0:11:06  lr: 0.000004  loss: 2.9792  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18500/20565]  eta: 0:10:51  lr: 0.000004  loss: 3.3523  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18550/20565]  eta: 0:10:35  lr: 0.000004  loss: 2.2584  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18600/20565]  eta: 0:10:19  lr: 0.000004  loss: 3.1160  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18650/20565]  eta: 0:10:03  lr: 0.000004  loss: 3.3493  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18700/20565]  eta: 0:09:48  lr: 0.000004  loss: 2.4483  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18750/20565]  eta: 0:09:32  lr: 0.000004  loss: 3.2531  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18800/20565]  eta: 0:09:16  lr: 0.000004  loss: 1.9494  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18850/20565]  eta: 0:09:00  lr: 0.000004  loss: 2.7380  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18900/20565]  eta: 0:08:44  lr: 0.000004  loss: 3.3311  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [18950/20565]  eta: 0:08:29  lr: 0.000004  loss: 3.7886  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19000/20565]  eta: 0:08:13  lr: 0.000004  loss: 2.7933  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19050/20565]  eta: 0:07:57  lr: 0.000004  loss: 3.3027  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19100/20565]  eta: 0:07:41  lr: 0.000004  loss: 3.7187  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19150/20565]  eta: 0:07:26  lr: 0.000004  loss: 3.0794  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19200/20565]  eta: 0:07:10  lr: 0.000004  loss: 3.8357  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19250/20565]  eta: 0:06:54  lr: 0.000004  loss: 3.2476  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19300/20565]  eta: 0:06:38  lr: 0.000004  loss: 3.2468  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19350/20565]  eta: 0:06:23  lr: 0.000004  loss: 2.5053  time: 0.3200  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19400/20565]  eta: 0:06:07  lr: 0.000004  loss: 2.6564  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19450/20565]  eta: 0:05:51  lr: 0.000004  loss: 2.3140  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19500/20565]  eta: 0:05:35  lr: 0.000004  loss: 3.2352  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19550/20565]  eta: 0:05:20  lr: 0.000004  loss: 2.6164  time: 0.3123  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19600/20565]  eta: 0:05:04  lr: 0.000004  loss: 4.1662  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19650/20565]  eta: 0:04:48  lr: 0.000004  loss: 3.3687  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19700/20565]  eta: 0:04:32  lr: 0.000004  loss: 3.1735  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19750/20565]  eta: 0:04:16  lr: 0.000004  loss: 2.5465  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19800/20565]  eta: 0:04:01  lr: 0.000004  loss: 2.7762  time: 0.3191  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19850/20565]  eta: 0:03:45  lr: 0.000004  loss: 3.0189  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19900/20565]  eta: 0:03:29  lr: 0.000004  loss: 3.1440  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [19950/20565]  eta: 0:03:13  lr: 0.000004  loss: 3.6377  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20000/20565]  eta: 0:02:58  lr: 0.000004  loss: 3.1488  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20050/20565]  eta: 0:02:42  lr: 0.000004  loss: 1.8792  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20100/20565]  eta: 0:02:26  lr: 0.000004  loss: 3.9161  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20150/20565]  eta: 0:02:10  lr: 0.000004  loss: 2.3183  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20200/20565]  eta: 0:01:55  lr: 0.000004  loss: 3.6119  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20250/20565]  eta: 0:01:39  lr: 0.000004  loss: 3.1564  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20300/20565]  eta: 0:01:23  lr: 0.000004  loss: 2.7147  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20350/20565]  eta: 0:01:07  lr: 0.000004  loss: 2.2786  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20400/20565]  eta: 0:00:52  lr: 0.000004  loss: 2.8302  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20450/20565]  eta: 0:00:36  lr: 0.000004  loss: 3.7021  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20500/20565]  eta: 0:00:20  lr: 0.000004  loss: 2.8315  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20550/20565]  eta: 0:00:04  lr: 0.000004  loss: 2.1279  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [6]  [20564/20565]  eta: 0:00:00  lr: 0.000004  loss: 3.0256  time: 0.3164  data: 0.0022  max mem: 14940\n","Train Epoch: [6] Total time: 1:48:06 (0.3154 s / it)\n","Averaged stats: lr: 0.0000  loss: 2.9866\n"]},{"output_type":"stream","name":"stderr","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [7]  [    0/20565]  eta: 8:28:09  lr: 0.000002  loss: 2.8332  time: 1.4826  data: 1.1055  max mem: 14940\n"]},{"output_type":"stream","name":"stderr","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [7]  [   50/20565]  eta: 1:56:39  lr: 0.000002  loss: 3.6876  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  100/20565]  eta: 1:52:23  lr: 0.000002  loss: 3.8490  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  150/20565]  eta: 1:50:40  lr: 0.000002  loss: 2.6062  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  200/20565]  eta: 1:49:40  lr: 0.000002  loss: 2.7558  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  250/20565]  eta: 1:48:59  lr: 0.000002  loss: 2.6288  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  300/20565]  eta: 1:48:21  lr: 0.000002  loss: 3.7193  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  350/20565]  eta: 1:47:48  lr: 0.000002  loss: 2.6352  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  400/20565]  eta: 1:47:16  lr: 0.000002  loss: 2.5980  time: 0.3121  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  450/20565]  eta: 1:46:51  lr: 0.000002  loss: 2.6720  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  500/20565]  eta: 1:46:27  lr: 0.000002  loss: 2.9465  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  550/20565]  eta: 1:46:06  lr: 0.000002  loss: 3.2867  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  600/20565]  eta: 1:45:43  lr: 0.000002  loss: 3.8084  time: 0.3126  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  650/20565]  eta: 1:45:25  lr: 0.000002  loss: 3.1721  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  700/20565]  eta: 1:45:06  lr: 0.000002  loss: 2.8961  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  750/20565]  eta: 1:44:45  lr: 0.000002  loss: 2.4532  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  800/20565]  eta: 1:44:26  lr: 0.000002  loss: 3.1797  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  850/20565]  eta: 1:44:08  lr: 0.000002  loss: 2.5659  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  900/20565]  eta: 1:43:51  lr: 0.000002  loss: 2.6819  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [  950/20565]  eta: 1:43:34  lr: 0.000002  loss: 2.9464  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1000/20565]  eta: 1:43:15  lr: 0.000002  loss: 2.2572  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1050/20565]  eta: 1:43:00  lr: 0.000002  loss: 2.9303  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1100/20565]  eta: 1:42:43  lr: 0.000002  loss: 2.6151  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1150/20565]  eta: 1:42:24  lr: 0.000002  loss: 3.0866  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1200/20565]  eta: 1:42:07  lr: 0.000002  loss: 3.4288  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1250/20565]  eta: 1:41:49  lr: 0.000002  loss: 3.7310  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1300/20565]  eta: 1:41:32  lr: 0.000002  loss: 2.5680  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1350/20565]  eta: 1:41:17  lr: 0.000002  loss: 3.5252  time: 0.3175  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1400/20565]  eta: 1:41:01  lr: 0.000002  loss: 2.6004  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1450/20565]  eta: 1:40:43  lr: 0.000002  loss: 2.9245  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1500/20565]  eta: 1:40:27  lr: 0.000002  loss: 2.6461  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1550/20565]  eta: 1:40:12  lr: 0.000002  loss: 2.8100  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1600/20565]  eta: 1:39:55  lr: 0.000002  loss: 2.6819  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1650/20565]  eta: 1:39:39  lr: 0.000002  loss: 2.6893  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1700/20565]  eta: 1:39:22  lr: 0.000002  loss: 3.5650  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1750/20565]  eta: 1:39:06  lr: 0.000002  loss: 2.9658  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1800/20565]  eta: 1:38:50  lr: 0.000002  loss: 2.9353  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1850/20565]  eta: 1:38:33  lr: 0.000002  loss: 3.4180  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1900/20565]  eta: 1:38:17  lr: 0.000002  loss: 3.1493  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 1950/20565]  eta: 1:38:01  lr: 0.000002  loss: 3.1497  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2000/20565]  eta: 1:37:45  lr: 0.000002  loss: 3.2436  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2050/20565]  eta: 1:37:28  lr: 0.000002  loss: 3.0645  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2100/20565]  eta: 1:37:12  lr: 0.000002  loss: 3.1905  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2150/20565]  eta: 1:36:56  lr: 0.000002  loss: 2.7434  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2200/20565]  eta: 1:36:41  lr: 0.000002  loss: 2.3008  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2250/20565]  eta: 1:36:25  lr: 0.000002  loss: 3.3973  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2300/20565]  eta: 1:36:09  lr: 0.000002  loss: 4.6672  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2350/20565]  eta: 1:35:53  lr: 0.000002  loss: 2.9752  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2400/20565]  eta: 1:35:37  lr: 0.000002  loss: 2.1601  time: 0.3124  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2450/20565]  eta: 1:35:22  lr: 0.000002  loss: 2.7505  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2500/20565]  eta: 1:35:05  lr: 0.000002  loss: 2.6811  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2550/20565]  eta: 1:34:49  lr: 0.000002  loss: 3.4739  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2600/20565]  eta: 1:34:34  lr: 0.000002  loss: 3.8598  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2650/20565]  eta: 1:34:17  lr: 0.000002  loss: 2.8679  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2700/20565]  eta: 1:34:02  lr: 0.000002  loss: 2.5259  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2750/20565]  eta: 1:33:45  lr: 0.000002  loss: 3.2783  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2800/20565]  eta: 1:33:29  lr: 0.000002  loss: 4.2494  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2850/20565]  eta: 1:33:13  lr: 0.000002  loss: 3.0326  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2900/20565]  eta: 1:32:57  lr: 0.000002  loss: 3.6228  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 2950/20565]  eta: 1:32:41  lr: 0.000002  loss: 3.6833  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3000/20565]  eta: 1:32:26  lr: 0.000002  loss: 2.5995  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3050/20565]  eta: 1:32:10  lr: 0.000002  loss: 2.5742  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3100/20565]  eta: 1:31:54  lr: 0.000002  loss: 2.8958  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3150/20565]  eta: 1:31:38  lr: 0.000002  loss: 3.3451  time: 0.3177  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3200/20565]  eta: 1:31:23  lr: 0.000002  loss: 4.3049  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3250/20565]  eta: 1:31:08  lr: 0.000002  loss: 2.1924  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3300/20565]  eta: 1:30:52  lr: 0.000002  loss: 3.3692  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3350/20565]  eta: 1:30:36  lr: 0.000002  loss: 3.0561  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3400/20565]  eta: 1:30:20  lr: 0.000002  loss: 2.8918  time: 0.3127  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3450/20565]  eta: 1:30:03  lr: 0.000002  loss: 3.2631  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3500/20565]  eta: 1:29:48  lr: 0.000002  loss: 2.3131  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3550/20565]  eta: 1:29:32  lr: 0.000002  loss: 2.5951  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3600/20565]  eta: 1:29:16  lr: 0.000002  loss: 2.4679  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3650/20565]  eta: 1:28:59  lr: 0.000002  loss: 4.1788  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3700/20565]  eta: 1:28:43  lr: 0.000002  loss: 2.9387  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3750/20565]  eta: 1:28:27  lr: 0.000002  loss: 3.6054  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3800/20565]  eta: 1:28:11  lr: 0.000002  loss: 3.7078  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3850/20565]  eta: 1:27:55  lr: 0.000002  loss: 2.5347  time: 0.3125  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3900/20565]  eta: 1:27:40  lr: 0.000002  loss: 3.1176  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 3950/20565]  eta: 1:27:24  lr: 0.000002  loss: 2.9104  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4000/20565]  eta: 1:27:07  lr: 0.000002  loss: 2.8511  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4050/20565]  eta: 1:26:51  lr: 0.000002  loss: 3.1551  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4100/20565]  eta: 1:26:36  lr: 0.000002  loss: 3.3943  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4150/20565]  eta: 1:26:20  lr: 0.000002  loss: 2.6364  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4200/20565]  eta: 1:26:04  lr: 0.000002  loss: 3.0580  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4250/20565]  eta: 1:25:48  lr: 0.000002  loss: 2.8240  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4300/20565]  eta: 1:25:32  lr: 0.000002  loss: 2.3494  time: 0.3176  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4350/20565]  eta: 1:25:16  lr: 0.000002  loss: 3.2257  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4400/20565]  eta: 1:25:01  lr: 0.000002  loss: 2.5436  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4450/20565]  eta: 1:24:45  lr: 0.000002  loss: 2.6678  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4500/20565]  eta: 1:24:29  lr: 0.000002  loss: 3.3347  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4550/20565]  eta: 1:24:13  lr: 0.000002  loss: 3.3701  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4600/20565]  eta: 1:23:57  lr: 0.000002  loss: 2.9220  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4650/20565]  eta: 1:23:41  lr: 0.000002  loss: 2.6621  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4700/20565]  eta: 1:23:25  lr: 0.000002  loss: 3.9406  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4750/20565]  eta: 1:23:10  lr: 0.000002  loss: 1.5098  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4800/20565]  eta: 1:22:54  lr: 0.000002  loss: 2.9951  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4850/20565]  eta: 1:22:38  lr: 0.000002  loss: 2.7877  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4900/20565]  eta: 1:22:22  lr: 0.000002  loss: 2.3539  time: 0.3125  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 4950/20565]  eta: 1:22:06  lr: 0.000002  loss: 2.6595  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5000/20565]  eta: 1:21:50  lr: 0.000002  loss: 2.8968  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5050/20565]  eta: 1:21:35  lr: 0.000002  loss: 3.6357  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5100/20565]  eta: 1:21:19  lr: 0.000002  loss: 3.2541  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5150/20565]  eta: 1:21:03  lr: 0.000002  loss: 3.5283  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5200/20565]  eta: 1:20:47  lr: 0.000002  loss: 3.4754  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5250/20565]  eta: 1:20:32  lr: 0.000002  loss: 3.7563  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5300/20565]  eta: 1:20:16  lr: 0.000002  loss: 3.6381  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5350/20565]  eta: 1:20:00  lr: 0.000002  loss: 1.9442  time: 0.3124  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5400/20565]  eta: 1:19:44  lr: 0.000002  loss: 2.7676  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5450/20565]  eta: 1:19:28  lr: 0.000002  loss: 2.4593  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5500/20565]  eta: 1:19:12  lr: 0.000002  loss: 2.5682  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5550/20565]  eta: 1:18:56  lr: 0.000002  loss: 3.5225  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5600/20565]  eta: 1:18:41  lr: 0.000002  loss: 3.6663  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5650/20565]  eta: 1:18:25  lr: 0.000002  loss: 2.4226  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5700/20565]  eta: 1:18:09  lr: 0.000002  loss: 2.6226  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5750/20565]  eta: 1:17:53  lr: 0.000002  loss: 1.9489  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5800/20565]  eta: 1:17:38  lr: 0.000002  loss: 3.2010  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5850/20565]  eta: 1:17:22  lr: 0.000002  loss: 2.7912  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5900/20565]  eta: 1:17:06  lr: 0.000002  loss: 1.8587  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 5950/20565]  eta: 1:16:50  lr: 0.000002  loss: 3.5470  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6000/20565]  eta: 1:16:34  lr: 0.000002  loss: 2.9965  time: 0.3118  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6050/20565]  eta: 1:16:18  lr: 0.000002  loss: 2.4598  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6100/20565]  eta: 1:16:02  lr: 0.000002  loss: 2.6630  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6150/20565]  eta: 1:15:47  lr: 0.000002  loss: 2.9625  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6200/20565]  eta: 1:15:31  lr: 0.000002  loss: 2.1643  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6250/20565]  eta: 1:15:15  lr: 0.000002  loss: 2.8277  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6300/20565]  eta: 1:14:59  lr: 0.000002  loss: 3.1044  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6350/20565]  eta: 1:14:44  lr: 0.000002  loss: 2.8356  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6400/20565]  eta: 1:14:28  lr: 0.000002  loss: 3.6832  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6450/20565]  eta: 1:14:12  lr: 0.000002  loss: 3.1135  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6500/20565]  eta: 1:13:56  lr: 0.000002  loss: 2.9249  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6550/20565]  eta: 1:13:41  lr: 0.000002  loss: 3.5799  time: 0.3163  data: 0.0003  max mem: 14940\n","Train Epoch: [7]  [ 6600/20565]  eta: 1:13:25  lr: 0.000002  loss: 3.3990  time: 0.3179  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6650/20565]  eta: 1:13:10  lr: 0.000002  loss: 2.4179  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6700/20565]  eta: 1:12:54  lr: 0.000002  loss: 2.8807  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6750/20565]  eta: 1:12:38  lr: 0.000002  loss: 3.0490  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6800/20565]  eta: 1:12:22  lr: 0.000002  loss: 2.7722  time: 0.3175  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6850/20565]  eta: 1:12:06  lr: 0.000002  loss: 2.3981  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6900/20565]  eta: 1:11:50  lr: 0.000002  loss: 2.8378  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 6950/20565]  eta: 1:11:35  lr: 0.000002  loss: 3.9873  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7000/20565]  eta: 1:11:19  lr: 0.000002  loss: 2.6588  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7050/20565]  eta: 1:11:03  lr: 0.000002  loss: 2.8386  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7100/20565]  eta: 1:10:47  lr: 0.000002  loss: 3.2562  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7150/20565]  eta: 1:10:31  lr: 0.000002  loss: 4.4106  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7200/20565]  eta: 1:10:15  lr: 0.000002  loss: 3.1006  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7250/20565]  eta: 1:10:00  lr: 0.000002  loss: 2.8766  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7300/20565]  eta: 1:09:44  lr: 0.000002  loss: 3.1858  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7350/20565]  eta: 1:09:28  lr: 0.000002  loss: 3.5668  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7400/20565]  eta: 1:09:12  lr: 0.000002  loss: 1.8926  time: 0.3180  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7450/20565]  eta: 1:08:57  lr: 0.000002  loss: 2.9464  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7500/20565]  eta: 1:08:41  lr: 0.000002  loss: 3.3956  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7550/20565]  eta: 1:08:25  lr: 0.000002  loss: 3.6651  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7600/20565]  eta: 1:08:09  lr: 0.000002  loss: 2.6061  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7650/20565]  eta: 1:07:54  lr: 0.000002  loss: 2.8790  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7700/20565]  eta: 1:07:38  lr: 0.000002  loss: 2.8709  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7750/20565]  eta: 1:07:22  lr: 0.000002  loss: 3.2160  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7800/20565]  eta: 1:07:06  lr: 0.000002  loss: 2.3927  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7850/20565]  eta: 1:06:51  lr: 0.000002  loss: 3.4404  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7900/20565]  eta: 1:06:35  lr: 0.000002  loss: 2.6840  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 7950/20565]  eta: 1:06:19  lr: 0.000002  loss: 2.9063  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8000/20565]  eta: 1:06:07  lr: 0.000002  loss: 2.9576  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8050/20565]  eta: 1:05:52  lr: 0.000002  loss: 3.9571  time: 0.3178  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8100/20565]  eta: 1:05:36  lr: 0.000002  loss: 3.3357  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8150/20565]  eta: 1:05:20  lr: 0.000002  loss: 3.3375  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8200/20565]  eta: 1:05:04  lr: 0.000002  loss: 3.3007  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8250/20565]  eta: 1:04:48  lr: 0.000002  loss: 2.3452  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8300/20565]  eta: 1:04:32  lr: 0.000002  loss: 2.8309  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8350/20565]  eta: 1:04:17  lr: 0.000002  loss: 2.5352  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8400/20565]  eta: 1:04:01  lr: 0.000002  loss: 3.3736  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8450/20565]  eta: 1:03:45  lr: 0.000002  loss: 3.9849  time: 0.3181  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8500/20565]  eta: 1:03:29  lr: 0.000002  loss: 2.8660  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8550/20565]  eta: 1:03:13  lr: 0.000002  loss: 2.7071  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8600/20565]  eta: 1:02:58  lr: 0.000002  loss: 2.4478  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8650/20565]  eta: 1:02:42  lr: 0.000002  loss: 2.9238  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8700/20565]  eta: 1:02:26  lr: 0.000002  loss: 4.1592  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8750/20565]  eta: 1:02:10  lr: 0.000002  loss: 2.7059  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8800/20565]  eta: 1:01:54  lr: 0.000002  loss: 3.0129  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8850/20565]  eta: 1:01:38  lr: 0.000002  loss: 3.1428  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8900/20565]  eta: 1:01:23  lr: 0.000002  loss: 2.8525  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 8950/20565]  eta: 1:01:07  lr: 0.000002  loss: 2.0576  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9000/20565]  eta: 1:00:51  lr: 0.000002  loss: 3.3398  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9050/20565]  eta: 1:00:35  lr: 0.000002  loss: 2.9464  time: 0.3168  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9100/20565]  eta: 1:00:19  lr: 0.000002  loss: 3.1175  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9150/20565]  eta: 1:00:03  lr: 0.000002  loss: 3.4881  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9200/20565]  eta: 0:59:48  lr: 0.000002  loss: 2.5488  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9250/20565]  eta: 0:59:32  lr: 0.000002  loss: 3.6662  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9300/20565]  eta: 0:59:16  lr: 0.000002  loss: 1.8423  time: 0.3126  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9350/20565]  eta: 0:59:00  lr: 0.000002  loss: 3.6243  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9400/20565]  eta: 0:58:44  lr: 0.000002  loss: 3.8840  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9450/20565]  eta: 0:58:29  lr: 0.000002  loss: 2.7369  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9500/20565]  eta: 0:58:13  lr: 0.000002  loss: 2.7934  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9550/20565]  eta: 0:57:57  lr: 0.000002  loss: 2.6408  time: 0.3191  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9600/20565]  eta: 0:57:41  lr: 0.000002  loss: 2.2540  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9650/20565]  eta: 0:57:26  lr: 0.000002  loss: 3.0199  time: 0.3177  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9700/20565]  eta: 0:57:10  lr: 0.000002  loss: 2.4885  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9750/20565]  eta: 0:56:54  lr: 0.000002  loss: 2.8851  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9800/20565]  eta: 0:56:38  lr: 0.000002  loss: 2.6583  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9850/20565]  eta: 0:56:22  lr: 0.000002  loss: 3.6587  time: 0.3175  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9900/20565]  eta: 0:56:07  lr: 0.000002  loss: 4.2624  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [ 9950/20565]  eta: 0:55:51  lr: 0.000002  loss: 3.3817  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10000/20565]  eta: 0:55:35  lr: 0.000002  loss: 3.0922  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10050/20565]  eta: 0:55:19  lr: 0.000002  loss: 3.1630  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10100/20565]  eta: 0:55:03  lr: 0.000002  loss: 3.8195  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10150/20565]  eta: 0:54:48  lr: 0.000002  loss: 2.6342  time: 0.3127  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10200/20565]  eta: 0:54:32  lr: 0.000002  loss: 3.0232  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10250/20565]  eta: 0:54:16  lr: 0.000002  loss: 3.6293  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10300/20565]  eta: 0:54:00  lr: 0.000002  loss: 3.2288  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10350/20565]  eta: 0:53:44  lr: 0.000002  loss: 2.3072  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10400/20565]  eta: 0:53:29  lr: 0.000002  loss: 3.7654  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10450/20565]  eta: 0:53:13  lr: 0.000002  loss: 2.1372  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10500/20565]  eta: 0:52:57  lr: 0.000002  loss: 2.5397  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10550/20565]  eta: 0:52:41  lr: 0.000002  loss: 2.5288  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10600/20565]  eta: 0:52:25  lr: 0.000002  loss: 2.4368  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10650/20565]  eta: 0:52:10  lr: 0.000002  loss: 2.9197  time: 0.3116  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10700/20565]  eta: 0:51:54  lr: 0.000002  loss: 3.6460  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10750/20565]  eta: 0:51:38  lr: 0.000002  loss: 3.9148  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10800/20565]  eta: 0:51:22  lr: 0.000002  loss: 3.4705  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10850/20565]  eta: 0:51:06  lr: 0.000002  loss: 3.1019  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10900/20565]  eta: 0:50:51  lr: 0.000002  loss: 3.4808  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [10950/20565]  eta: 0:50:35  lr: 0.000002  loss: 3.5923  time: 0.3181  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11000/20565]  eta: 0:50:19  lr: 0.000002  loss: 2.2945  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11050/20565]  eta: 0:50:03  lr: 0.000002  loss: 2.4267  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11100/20565]  eta: 0:49:47  lr: 0.000002  loss: 2.1893  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11150/20565]  eta: 0:49:32  lr: 0.000002  loss: 3.3520  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11200/20565]  eta: 0:49:16  lr: 0.000002  loss: 2.5873  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11250/20565]  eta: 0:49:00  lr: 0.000002  loss: 2.0735  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11300/20565]  eta: 0:48:44  lr: 0.000002  loss: 3.4296  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11350/20565]  eta: 0:48:28  lr: 0.000002  loss: 2.7142  time: 0.3139  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11400/20565]  eta: 0:48:13  lr: 0.000002  loss: 2.6230  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11450/20565]  eta: 0:47:57  lr: 0.000002  loss: 3.0349  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11500/20565]  eta: 0:47:41  lr: 0.000002  loss: 3.2547  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11550/20565]  eta: 0:47:25  lr: 0.000002  loss: 2.5868  time: 0.3175  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11600/20565]  eta: 0:47:10  lr: 0.000002  loss: 2.6641  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11650/20565]  eta: 0:46:54  lr: 0.000002  loss: 3.1951  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11700/20565]  eta: 0:46:38  lr: 0.000002  loss: 4.8456  time: 0.3132  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11750/20565]  eta: 0:46:22  lr: 0.000002  loss: 2.4080  time: 0.3118  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11800/20565]  eta: 0:46:06  lr: 0.000002  loss: 2.4723  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11850/20565]  eta: 0:45:50  lr: 0.000002  loss: 2.5633  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11900/20565]  eta: 0:45:35  lr: 0.000002  loss: 3.1208  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [11950/20565]  eta: 0:45:19  lr: 0.000002  loss: 2.8647  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12000/20565]  eta: 0:45:03  lr: 0.000002  loss: 3.2555  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12050/20565]  eta: 0:44:47  lr: 0.000002  loss: 3.0498  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12100/20565]  eta: 0:44:31  lr: 0.000002  loss: 2.6218  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12150/20565]  eta: 0:44:16  lr: 0.000002  loss: 2.7252  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12200/20565]  eta: 0:44:00  lr: 0.000002  loss: 3.3629  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12250/20565]  eta: 0:43:44  lr: 0.000002  loss: 3.0468  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12300/20565]  eta: 0:43:28  lr: 0.000002  loss: 2.8526  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12350/20565]  eta: 0:43:12  lr: 0.000002  loss: 2.7944  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12400/20565]  eta: 0:42:57  lr: 0.000002  loss: 3.1117  time: 0.3121  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12450/20565]  eta: 0:42:41  lr: 0.000002  loss: 3.3543  time: 0.3175  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12500/20565]  eta: 0:42:25  lr: 0.000002  loss: 2.2212  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12550/20565]  eta: 0:42:09  lr: 0.000002  loss: 3.1160  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12600/20565]  eta: 0:41:53  lr: 0.000002  loss: 2.8968  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12650/20565]  eta: 0:41:38  lr: 0.000002  loss: 2.7802  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12700/20565]  eta: 0:41:22  lr: 0.000002  loss: 3.1455  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12750/20565]  eta: 0:41:06  lr: 0.000002  loss: 2.7866  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12800/20565]  eta: 0:40:50  lr: 0.000002  loss: 4.0254  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12850/20565]  eta: 0:40:34  lr: 0.000002  loss: 3.7960  time: 0.3127  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12900/20565]  eta: 0:40:19  lr: 0.000002  loss: 2.2648  time: 0.3188  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [12950/20565]  eta: 0:40:03  lr: 0.000002  loss: 2.2069  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13000/20565]  eta: 0:39:47  lr: 0.000002  loss: 2.4016  time: 0.3126  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13050/20565]  eta: 0:39:31  lr: 0.000002  loss: 3.0618  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13100/20565]  eta: 0:39:16  lr: 0.000002  loss: 3.4943  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13150/20565]  eta: 0:39:00  lr: 0.000002  loss: 2.3164  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13200/20565]  eta: 0:38:44  lr: 0.000002  loss: 3.2246  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13250/20565]  eta: 0:38:28  lr: 0.000002  loss: 3.4824  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13300/20565]  eta: 0:38:12  lr: 0.000002  loss: 3.5612  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13350/20565]  eta: 0:37:57  lr: 0.000002  loss: 3.2947  time: 0.3169  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13400/20565]  eta: 0:37:41  lr: 0.000002  loss: 2.0500  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13450/20565]  eta: 0:37:25  lr: 0.000002  loss: 2.4178  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13500/20565]  eta: 0:37:09  lr: 0.000002  loss: 2.4125  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13550/20565]  eta: 0:36:53  lr: 0.000002  loss: 2.6699  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13600/20565]  eta: 0:36:38  lr: 0.000002  loss: 3.0482  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13650/20565]  eta: 0:36:22  lr: 0.000002  loss: 2.2832  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13700/20565]  eta: 0:36:06  lr: 0.000002  loss: 2.4522  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13750/20565]  eta: 0:35:50  lr: 0.000002  loss: 2.3063  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13800/20565]  eta: 0:35:35  lr: 0.000002  loss: 2.9247  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13850/20565]  eta: 0:35:19  lr: 0.000002  loss: 3.7218  time: 0.3185  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13900/20565]  eta: 0:35:03  lr: 0.000002  loss: 2.5374  time: 0.3128  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [13950/20565]  eta: 0:34:47  lr: 0.000002  loss: 2.9665  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14000/20565]  eta: 0:34:31  lr: 0.000002  loss: 3.4644  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14050/20565]  eta: 0:34:16  lr: 0.000002  loss: 3.4023  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14100/20565]  eta: 0:34:00  lr: 0.000002  loss: 2.9358  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14150/20565]  eta: 0:33:44  lr: 0.000002  loss: 3.0830  time: 0.3128  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14200/20565]  eta: 0:33:28  lr: 0.000002  loss: 2.7927  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14250/20565]  eta: 0:33:12  lr: 0.000002  loss: 3.3081  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14300/20565]  eta: 0:32:57  lr: 0.000002  loss: 2.9017  time: 0.3180  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14350/20565]  eta: 0:32:41  lr: 0.000002  loss: 3.6619  time: 0.3182  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14400/20565]  eta: 0:32:25  lr: 0.000002  loss: 2.5477  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14450/20565]  eta: 0:32:09  lr: 0.000002  loss: 2.5366  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14500/20565]  eta: 0:31:53  lr: 0.000002  loss: 2.5256  time: 0.3108  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14550/20565]  eta: 0:31:38  lr: 0.000002  loss: 2.6798  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14600/20565]  eta: 0:31:22  lr: 0.000002  loss: 2.9056  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14650/20565]  eta: 0:31:06  lr: 0.000002  loss: 2.9902  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14700/20565]  eta: 0:30:50  lr: 0.000002  loss: 3.3978  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14750/20565]  eta: 0:30:35  lr: 0.000002  loss: 2.8223  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14800/20565]  eta: 0:30:19  lr: 0.000002  loss: 3.0670  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14850/20565]  eta: 0:30:03  lr: 0.000002  loss: 2.9451  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14900/20565]  eta: 0:29:47  lr: 0.000002  loss: 2.6844  time: 0.3123  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [14950/20565]  eta: 0:29:31  lr: 0.000002  loss: 2.9224  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15000/20565]  eta: 0:29:16  lr: 0.000002  loss: 3.7068  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15050/20565]  eta: 0:29:00  lr: 0.000002  loss: 3.0901  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15100/20565]  eta: 0:28:44  lr: 0.000002  loss: 3.2370  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15150/20565]  eta: 0:28:28  lr: 0.000002  loss: 2.3513  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15200/20565]  eta: 0:28:13  lr: 0.000002  loss: 3.0044  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15250/20565]  eta: 0:27:57  lr: 0.000002  loss: 3.0307  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15300/20565]  eta: 0:27:41  lr: 0.000002  loss: 3.8454  time: 0.3149  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15350/20565]  eta: 0:27:25  lr: 0.000002  loss: 2.4154  time: 0.3136  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15400/20565]  eta: 0:27:09  lr: 0.000002  loss: 3.8382  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15450/20565]  eta: 0:26:54  lr: 0.000002  loss: 3.2688  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15500/20565]  eta: 0:26:38  lr: 0.000002  loss: 3.4191  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15550/20565]  eta: 0:26:22  lr: 0.000002  loss: 2.9800  time: 0.3130  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15600/20565]  eta: 0:26:06  lr: 0.000002  loss: 2.2775  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15650/20565]  eta: 0:25:50  lr: 0.000002  loss: 3.2128  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15700/20565]  eta: 0:25:35  lr: 0.000002  loss: 3.6281  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15750/20565]  eta: 0:25:19  lr: 0.000002  loss: 3.4502  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15800/20565]  eta: 0:25:03  lr: 0.000002  loss: 3.2072  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15850/20565]  eta: 0:24:47  lr: 0.000002  loss: 1.7393  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15900/20565]  eta: 0:24:32  lr: 0.000002  loss: 3.7609  time: 0.3134  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [15950/20565]  eta: 0:24:16  lr: 0.000002  loss: 3.3119  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16000/20565]  eta: 0:24:00  lr: 0.000002  loss: 2.9349  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16050/20565]  eta: 0:23:44  lr: 0.000002  loss: 2.5765  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16100/20565]  eta: 0:23:28  lr: 0.000002  loss: 2.7904  time: 0.3171  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16150/20565]  eta: 0:23:13  lr: 0.000002  loss: 2.8424  time: 0.3161  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16200/20565]  eta: 0:22:57  lr: 0.000002  loss: 2.4917  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16250/20565]  eta: 0:22:41  lr: 0.000002  loss: 2.9944  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16300/20565]  eta: 0:22:25  lr: 0.000002  loss: 3.5932  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16350/20565]  eta: 0:22:10  lr: 0.000002  loss: 2.9325  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16400/20565]  eta: 0:21:54  lr: 0.000002  loss: 2.7594  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16450/20565]  eta: 0:21:38  lr: 0.000002  loss: 3.8658  time: 0.3128  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16500/20565]  eta: 0:21:22  lr: 0.000002  loss: 2.9647  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16550/20565]  eta: 0:21:06  lr: 0.000002  loss: 2.7470  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16600/20565]  eta: 0:20:51  lr: 0.000002  loss: 3.4157  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16650/20565]  eta: 0:20:35  lr: 0.000002  loss: 2.9620  time: 0.3129  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16700/20565]  eta: 0:20:19  lr: 0.000002  loss: 2.8596  time: 0.3183  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16750/20565]  eta: 0:20:03  lr: 0.000002  loss: 2.5645  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16800/20565]  eta: 0:19:47  lr: 0.000002  loss: 2.4494  time: 0.3194  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16850/20565]  eta: 0:19:32  lr: 0.000002  loss: 3.3061  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16900/20565]  eta: 0:19:16  lr: 0.000002  loss: 3.6579  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [16950/20565]  eta: 0:19:00  lr: 0.000002  loss: 2.3892  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17000/20565]  eta: 0:18:44  lr: 0.000002  loss: 2.7307  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17050/20565]  eta: 0:18:29  lr: 0.000002  loss: 2.9491  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17100/20565]  eta: 0:18:13  lr: 0.000002  loss: 1.8273  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17150/20565]  eta: 0:17:57  lr: 0.000002  loss: 2.4473  time: 0.3182  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17200/20565]  eta: 0:17:41  lr: 0.000002  loss: 3.3830  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17250/20565]  eta: 0:17:25  lr: 0.000002  loss: 2.0436  time: 0.3128  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17300/20565]  eta: 0:17:10  lr: 0.000002  loss: 3.2313  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17350/20565]  eta: 0:16:54  lr: 0.000002  loss: 2.6346  time: 0.3147  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17400/20565]  eta: 0:16:38  lr: 0.000002  loss: 3.1062  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17450/20565]  eta: 0:16:22  lr: 0.000002  loss: 3.0692  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17500/20565]  eta: 0:16:07  lr: 0.000002  loss: 2.3450  time: 0.3159  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17550/20565]  eta: 0:15:51  lr: 0.000002  loss: 2.7221  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17600/20565]  eta: 0:15:35  lr: 0.000002  loss: 3.1529  time: 0.3148  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17650/20565]  eta: 0:15:19  lr: 0.000002  loss: 2.6603  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17700/20565]  eta: 0:15:03  lr: 0.000002  loss: 2.9095  time: 0.3163  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17750/20565]  eta: 0:14:48  lr: 0.000002  loss: 2.6578  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17800/20565]  eta: 0:14:32  lr: 0.000002  loss: 2.7257  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17850/20565]  eta: 0:14:16  lr: 0.000002  loss: 3.0438  time: 0.3156  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17900/20565]  eta: 0:14:00  lr: 0.000002  loss: 2.6184  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [17950/20565]  eta: 0:13:44  lr: 0.000002  loss: 3.4819  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18000/20565]  eta: 0:13:29  lr: 0.000002  loss: 3.5471  time: 0.3172  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18050/20565]  eta: 0:13:13  lr: 0.000002  loss: 2.6307  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18100/20565]  eta: 0:12:57  lr: 0.000002  loss: 2.7673  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18150/20565]  eta: 0:12:41  lr: 0.000002  loss: 2.5096  time: 0.3135  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18200/20565]  eta: 0:12:26  lr: 0.000002  loss: 2.6480  time: 0.3174  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18250/20565]  eta: 0:12:10  lr: 0.000002  loss: 2.8134  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18300/20565]  eta: 0:11:54  lr: 0.000002  loss: 3.2494  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18350/20565]  eta: 0:11:38  lr: 0.000002  loss: 2.6252  time: 0.3162  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18400/20565]  eta: 0:11:23  lr: 0.000002  loss: 3.5953  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18450/20565]  eta: 0:11:07  lr: 0.000002  loss: 3.2482  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18500/20565]  eta: 0:10:51  lr: 0.000002  loss: 3.2633  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18550/20565]  eta: 0:10:35  lr: 0.000002  loss: 2.7865  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18600/20565]  eta: 0:10:19  lr: 0.000002  loss: 4.0268  time: 0.3137  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18650/20565]  eta: 0:10:04  lr: 0.000002  loss: 2.2774  time: 0.3140  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18700/20565]  eta: 0:09:48  lr: 0.000002  loss: 3.0962  time: 0.3158  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18750/20565]  eta: 0:09:32  lr: 0.000002  loss: 3.0926  time: 0.3157  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18800/20565]  eta: 0:09:16  lr: 0.000002  loss: 2.4006  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18850/20565]  eta: 0:09:01  lr: 0.000002  loss: 3.9164  time: 0.3153  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18900/20565]  eta: 0:08:45  lr: 0.000002  loss: 2.4047  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [18950/20565]  eta: 0:08:29  lr: 0.000002  loss: 2.5916  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19000/20565]  eta: 0:08:13  lr: 0.000002  loss: 2.4638  time: 0.3133  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19050/20565]  eta: 0:07:57  lr: 0.000002  loss: 2.8111  time: 0.3170  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19100/20565]  eta: 0:07:42  lr: 0.000002  loss: 3.5263  time: 0.3146  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19150/20565]  eta: 0:07:26  lr: 0.000002  loss: 2.5169  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19200/20565]  eta: 0:07:10  lr: 0.000002  loss: 3.4723  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19250/20565]  eta: 0:06:54  lr: 0.000002  loss: 2.9007  time: 0.3167  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19300/20565]  eta: 0:06:39  lr: 0.000002  loss: 2.5283  time: 0.3154  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19350/20565]  eta: 0:06:23  lr: 0.000002  loss: 3.3246  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19400/20565]  eta: 0:06:07  lr: 0.000002  loss: 2.7802  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19450/20565]  eta: 0:05:51  lr: 0.000002  loss: 2.8666  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19500/20565]  eta: 0:05:35  lr: 0.000002  loss: 2.3241  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19550/20565]  eta: 0:05:20  lr: 0.000002  loss: 2.5971  time: 0.3155  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19600/20565]  eta: 0:05:04  lr: 0.000002  loss: 2.8662  time: 0.3190  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19650/20565]  eta: 0:04:48  lr: 0.000002  loss: 3.7186  time: 0.3141  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19700/20565]  eta: 0:04:32  lr: 0.000002  loss: 2.6164  time: 0.3151  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19750/20565]  eta: 0:04:17  lr: 0.000002  loss: 2.9345  time: 0.3150  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19800/20565]  eta: 0:04:01  lr: 0.000002  loss: 2.8552  time: 0.3164  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19850/20565]  eta: 0:03:45  lr: 0.000002  loss: 2.9810  time: 0.3191  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19900/20565]  eta: 0:03:29  lr: 0.000002  loss: 2.4017  time: 0.3165  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [19950/20565]  eta: 0:03:14  lr: 0.000002  loss: 2.6857  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20000/20565]  eta: 0:02:58  lr: 0.000002  loss: 2.9814  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20050/20565]  eta: 0:02:42  lr: 0.000002  loss: 2.8274  time: 0.3173  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20100/20565]  eta: 0:02:26  lr: 0.000002  loss: 2.7681  time: 0.3152  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20150/20565]  eta: 0:02:10  lr: 0.000002  loss: 3.2557  time: 0.3144  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20200/20565]  eta: 0:01:55  lr: 0.000002  loss: 2.6860  time: 0.3145  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20250/20565]  eta: 0:01:39  lr: 0.000002  loss: 3.5233  time: 0.3166  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20300/20565]  eta: 0:01:23  lr: 0.000002  loss: 2.7521  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20350/20565]  eta: 0:01:07  lr: 0.000002  loss: 3.0464  time: 0.3138  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20400/20565]  eta: 0:00:52  lr: 0.000002  loss: 2.3261  time: 0.3143  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20450/20565]  eta: 0:00:36  lr: 0.000002  loss: 2.5128  time: 0.3131  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20500/20565]  eta: 0:00:20  lr: 0.000002  loss: 2.8903  time: 0.3142  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20550/20565]  eta: 0:00:04  lr: 0.000002  loss: 2.7706  time: 0.3160  data: 0.0002  max mem: 14940\n","Train Epoch: [7]  [20564/20565]  eta: 0:00:00  lr: 0.000002  loss: 3.2671  time: 0.3183  data: 0.0023  max mem: 14940\n","Train Epoch: [7] Total time: 1:48:08 (0.3155 s / it)\n","Averaged stats: lr: 0.0000  loss: 2.9614\n","Generate VQA test result:  [    0/27988]  eta: 12:21:48    time: 1.5903  data: 0.7809  max mem: 14940\n","Generate VQA test result:  [   50/27988]  eta: 1:42:28    time: 0.1943  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  100/27988]  eta: 1:35:53    time: 0.1932  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  150/27988]  eta: 1:33:19    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  200/27988]  eta: 1:32:02    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  250/27988]  eta: 1:31:11    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  300/27988]  eta: 1:30:33    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  350/27988]  eta: 1:30:02    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  400/27988]  eta: 1:29:39    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  450/27988]  eta: 1:29:20    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  500/27988]  eta: 1:28:58    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  550/27988]  eta: 1:28:39    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  600/27988]  eta: 1:28:21    time: 0.1900  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  650/27988]  eta: 1:28:05    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  700/27988]  eta: 1:27:51    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  750/27988]  eta: 1:27:38    time: 0.1899  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  800/27988]  eta: 1:27:24    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  850/27988]  eta: 1:27:11    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  900/27988]  eta: 1:26:58    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [  950/27988]  eta: 1:26:46    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1000/27988]  eta: 1:26:34    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1050/27988]  eta: 1:26:23    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1100/27988]  eta: 1:26:12    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1150/27988]  eta: 1:26:00    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1200/27988]  eta: 1:25:49    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1250/27988]  eta: 1:25:38    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1300/27988]  eta: 1:25:27    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1350/27988]  eta: 1:25:17    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1400/27988]  eta: 1:25:05    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1450/27988]  eta: 1:24:55    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1500/27988]  eta: 1:24:44    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1550/27988]  eta: 1:24:33    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1600/27988]  eta: 1:24:23    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1650/27988]  eta: 1:24:13    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1700/27988]  eta: 1:24:02    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1750/27988]  eta: 1:23:52    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1800/27988]  eta: 1:23:42    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1850/27988]  eta: 1:23:32    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1900/27988]  eta: 1:23:22    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 1950/27988]  eta: 1:23:11    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2000/27988]  eta: 1:23:02    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2050/27988]  eta: 1:22:52    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2100/27988]  eta: 1:22:42    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2150/27988]  eta: 1:22:32    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2200/27988]  eta: 1:22:22    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2250/27988]  eta: 1:22:12    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2300/27988]  eta: 1:22:03    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2350/27988]  eta: 1:21:53    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2400/27988]  eta: 1:21:42    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2450/27988]  eta: 1:21:33    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2500/27988]  eta: 1:21:23    time: 0.1921  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2550/27988]  eta: 1:21:13    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2600/27988]  eta: 1:21:04    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2650/27988]  eta: 1:20:54    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2700/27988]  eta: 1:20:44    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2750/27988]  eta: 1:20:34    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2800/27988]  eta: 1:20:24    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2850/27988]  eta: 1:20:14    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2900/27988]  eta: 1:20:04    time: 0.1899  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 2950/27988]  eta: 1:19:54    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3000/27988]  eta: 1:19:44    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3050/27988]  eta: 1:19:35    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3100/27988]  eta: 1:19:25    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3150/27988]  eta: 1:19:15    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3200/27988]  eta: 1:19:05    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3250/27988]  eta: 1:18:55    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3300/27988]  eta: 1:18:45    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3350/27988]  eta: 1:18:36    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3400/27988]  eta: 1:18:26    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3450/27988]  eta: 1:18:16    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3500/27988]  eta: 1:18:07    time: 0.1932  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [ 3550/27988]  eta: 1:17:58    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3600/27988]  eta: 1:17:48    time: 0.1898  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3650/27988]  eta: 1:17:38    time: 0.1901  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3700/27988]  eta: 1:17:28    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3750/27988]  eta: 1:17:19    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3800/27988]  eta: 1:17:09    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3850/27988]  eta: 1:17:00    time: 0.1922  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3900/27988]  eta: 1:16:50    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 3950/27988]  eta: 1:16:41    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4000/27988]  eta: 1:16:31    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4050/27988]  eta: 1:16:21    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4100/27988]  eta: 1:16:11    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4150/27988]  eta: 1:16:02    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4200/27988]  eta: 1:15:52    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4250/27988]  eta: 1:15:43    time: 0.1931  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [ 4300/27988]  eta: 1:15:33    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4350/27988]  eta: 1:15:24    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4400/27988]  eta: 1:15:15    time: 0.1924  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [ 4450/27988]  eta: 1:15:06    time: 0.1926  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4500/27988]  eta: 1:14:56    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4550/27988]  eta: 1:14:47    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4600/27988]  eta: 1:14:37    time: 0.1925  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4650/27988]  eta: 1:14:28    time: 0.1936  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [ 4700/27988]  eta: 1:14:18    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4750/27988]  eta: 1:14:08    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4800/27988]  eta: 1:13:59    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4850/27988]  eta: 1:13:49    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4900/27988]  eta: 1:13:39    time: 0.1901  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 4950/27988]  eta: 1:13:30    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5000/27988]  eta: 1:13:20    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5050/27988]  eta: 1:13:10    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5100/27988]  eta: 1:13:01    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5150/27988]  eta: 1:12:51    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5200/27988]  eta: 1:12:42    time: 0.1899  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5250/27988]  eta: 1:12:32    time: 0.1926  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5300/27988]  eta: 1:12:22    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5350/27988]  eta: 1:12:13    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5400/27988]  eta: 1:12:03    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5450/27988]  eta: 1:11:53    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5500/27988]  eta: 1:11:44    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5550/27988]  eta: 1:11:34    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5600/27988]  eta: 1:11:25    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5650/27988]  eta: 1:11:15    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5700/27988]  eta: 1:11:05    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5750/27988]  eta: 1:10:56    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5800/27988]  eta: 1:10:46    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5850/27988]  eta: 1:10:37    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5900/27988]  eta: 1:10:27    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 5950/27988]  eta: 1:10:17    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6000/27988]  eta: 1:10:07    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6050/27988]  eta: 1:09:58    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6100/27988]  eta: 1:09:48    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6150/27988]  eta: 1:09:38    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6200/27988]  eta: 1:09:29    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6250/27988]  eta: 1:09:19    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6300/27988]  eta: 1:09:09    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6350/27988]  eta: 1:09:00    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6400/27988]  eta: 1:08:50    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6450/27988]  eta: 1:08:41    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6500/27988]  eta: 1:08:31    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6550/27988]  eta: 1:08:21    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6600/27988]  eta: 1:08:12    time: 0.1900  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6650/27988]  eta: 1:08:02    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6700/27988]  eta: 1:07:52    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6750/27988]  eta: 1:07:43    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6800/27988]  eta: 1:07:33    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6850/27988]  eta: 1:07:23    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6900/27988]  eta: 1:07:14    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 6950/27988]  eta: 1:07:04    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7000/27988]  eta: 1:06:54    time: 0.1899  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7050/27988]  eta: 1:06:45    time: 0.1901  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7100/27988]  eta: 1:06:35    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7150/27988]  eta: 1:06:25    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7200/27988]  eta: 1:06:16    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7250/27988]  eta: 1:06:06    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7300/27988]  eta: 1:05:57    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7350/27988]  eta: 1:05:47    time: 0.1952  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [ 7400/27988]  eta: 1:05:38    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7450/27988]  eta: 1:05:28    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7500/27988]  eta: 1:05:19    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7550/27988]  eta: 1:05:09    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7600/27988]  eta: 1:04:59    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7650/27988]  eta: 1:04:50    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7700/27988]  eta: 1:04:40    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7750/27988]  eta: 1:04:31    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7800/27988]  eta: 1:04:21    time: 0.1921  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7850/27988]  eta: 1:04:12    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7900/27988]  eta: 1:04:02    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 7950/27988]  eta: 1:03:53    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8000/27988]  eta: 1:03:43    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8050/27988]  eta: 1:03:33    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8100/27988]  eta: 1:03:24    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8150/27988]  eta: 1:03:14    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8200/27988]  eta: 1:03:05    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8250/27988]  eta: 1:02:55    time: 0.1926  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8300/27988]  eta: 1:02:46    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8350/27988]  eta: 1:02:36    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8400/27988]  eta: 1:02:26    time: 0.1922  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8450/27988]  eta: 1:02:17    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8500/27988]  eta: 1:02:07    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8550/27988]  eta: 1:01:58    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8600/27988]  eta: 1:01:48    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8650/27988]  eta: 1:01:39    time: 0.1946  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [ 8700/27988]  eta: 1:01:29    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8750/27988]  eta: 1:01:20    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8800/27988]  eta: 1:01:10    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8850/27988]  eta: 1:01:01    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8900/27988]  eta: 1:00:51    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 8950/27988]  eta: 1:00:42    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9000/27988]  eta: 1:00:32    time: 0.1901  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9050/27988]  eta: 1:00:22    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9100/27988]  eta: 1:00:13    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9150/27988]  eta: 1:00:03    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9200/27988]  eta: 0:59:54    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9250/27988]  eta: 0:59:44    time: 0.1926  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [ 9300/27988]  eta: 0:59:35    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9350/27988]  eta: 0:59:25    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9400/27988]  eta: 0:59:16    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9450/27988]  eta: 0:59:06    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9500/27988]  eta: 0:58:57    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9550/27988]  eta: 0:58:47    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9600/27988]  eta: 0:58:37    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9650/27988]  eta: 0:58:28    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9700/27988]  eta: 0:58:18    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9750/27988]  eta: 0:58:09    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9800/27988]  eta: 0:57:59    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9850/27988]  eta: 0:57:50    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9900/27988]  eta: 0:57:40    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [ 9950/27988]  eta: 0:57:30    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10000/27988]  eta: 0:57:21    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10050/27988]  eta: 0:57:11    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10100/27988]  eta: 0:57:02    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10150/27988]  eta: 0:56:52    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10200/27988]  eta: 0:56:43    time: 0.1925  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10250/27988]  eta: 0:56:33    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10300/27988]  eta: 0:56:23    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10350/27988]  eta: 0:56:14    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10400/27988]  eta: 0:56:04    time: 0.1922  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10450/27988]  eta: 0:55:55    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10500/27988]  eta: 0:55:45    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10550/27988]  eta: 0:55:36    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10600/27988]  eta: 0:55:26    time: 0.1940  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [10650/27988]  eta: 0:55:17    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10700/27988]  eta: 0:55:07    time: 0.1898  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10750/27988]  eta: 0:54:57    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10800/27988]  eta: 0:54:48    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10850/27988]  eta: 0:54:38    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10900/27988]  eta: 0:54:28    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [10950/27988]  eta: 0:54:19    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11000/27988]  eta: 0:54:09    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11050/27988]  eta: 0:54:00    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11100/27988]  eta: 0:53:50    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11150/27988]  eta: 0:53:41    time: 0.1893  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11200/27988]  eta: 0:53:31    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11250/27988]  eta: 0:53:21    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11300/27988]  eta: 0:53:12    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11350/27988]  eta: 0:53:02    time: 0.1919  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [11400/27988]  eta: 0:52:53    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11450/27988]  eta: 0:52:43    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11500/27988]  eta: 0:52:34    time: 0.1921  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11550/27988]  eta: 0:52:24    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11600/27988]  eta: 0:52:14    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11650/27988]  eta: 0:52:05    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11700/27988]  eta: 0:51:55    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11750/27988]  eta: 0:51:46    time: 0.1923  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11800/27988]  eta: 0:51:36    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11850/27988]  eta: 0:51:27    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11900/27988]  eta: 0:51:17    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [11950/27988]  eta: 0:51:07    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12000/27988]  eta: 0:50:58    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12050/27988]  eta: 0:50:48    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12100/27988]  eta: 0:50:39    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12150/27988]  eta: 0:50:29    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12200/27988]  eta: 0:50:19    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12250/27988]  eta: 0:50:10    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12300/27988]  eta: 0:50:00    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12350/27988]  eta: 0:49:51    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12400/27988]  eta: 0:49:41    time: 0.1901  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12450/27988]  eta: 0:49:32    time: 0.1930  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [12500/27988]  eta: 0:49:22    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12550/27988]  eta: 0:49:12    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12600/27988]  eta: 0:49:03    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12650/27988]  eta: 0:48:53    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12700/27988]  eta: 0:48:44    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12750/27988]  eta: 0:48:34    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12800/27988]  eta: 0:48:24    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12850/27988]  eta: 0:48:15    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12900/27988]  eta: 0:48:05    time: 0.1921  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [12950/27988]  eta: 0:47:56    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13000/27988]  eta: 0:47:46    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13050/27988]  eta: 0:47:37    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13100/27988]  eta: 0:47:27    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13150/27988]  eta: 0:47:18    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13200/27988]  eta: 0:47:08    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13250/27988]  eta: 0:46:58    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13300/27988]  eta: 0:46:49    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13350/27988]  eta: 0:46:39    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13400/27988]  eta: 0:46:30    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13450/27988]  eta: 0:46:20    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13500/27988]  eta: 0:46:11    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13550/27988]  eta: 0:46:01    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13600/27988]  eta: 0:45:51    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13650/27988]  eta: 0:45:42    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13700/27988]  eta: 0:45:32    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13750/27988]  eta: 0:45:23    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13800/27988]  eta: 0:45:13    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13850/27988]  eta: 0:45:03    time: 0.1937  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [13900/27988]  eta: 0:44:54    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [13950/27988]  eta: 0:44:44    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14000/27988]  eta: 0:44:35    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14050/27988]  eta: 0:44:25    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14100/27988]  eta: 0:44:16    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14150/27988]  eta: 0:44:06    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14200/27988]  eta: 0:43:56    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14250/27988]  eta: 0:43:47    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14300/27988]  eta: 0:43:37    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14350/27988]  eta: 0:43:28    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14400/27988]  eta: 0:43:18    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14450/27988]  eta: 0:43:09    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14500/27988]  eta: 0:42:59    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14550/27988]  eta: 0:42:49    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14600/27988]  eta: 0:42:40    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14650/27988]  eta: 0:42:30    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14700/27988]  eta: 0:42:21    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14750/27988]  eta: 0:42:11    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14800/27988]  eta: 0:42:02    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14850/27988]  eta: 0:41:52    time: 0.1932  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [14900/27988]  eta: 0:41:43    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [14950/27988]  eta: 0:41:33    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15000/27988]  eta: 0:41:23    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15050/27988]  eta: 0:41:14    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15100/27988]  eta: 0:41:04    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15150/27988]  eta: 0:40:55    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15200/27988]  eta: 0:40:45    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15250/27988]  eta: 0:40:36    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15300/27988]  eta: 0:40:26    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15350/27988]  eta: 0:40:16    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15400/27988]  eta: 0:40:07    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15450/27988]  eta: 0:39:57    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15500/27988]  eta: 0:39:48    time: 0.1900  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15550/27988]  eta: 0:39:38    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15600/27988]  eta: 0:39:29    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15650/27988]  eta: 0:39:19    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15700/27988]  eta: 0:39:09    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15750/27988]  eta: 0:39:00    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15800/27988]  eta: 0:38:50    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15850/27988]  eta: 0:38:41    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15900/27988]  eta: 0:38:31    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [15950/27988]  eta: 0:38:22    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16000/27988]  eta: 0:38:12    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16050/27988]  eta: 0:38:02    time: 0.1901  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16100/27988]  eta: 0:37:53    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16150/27988]  eta: 0:37:43    time: 0.1901  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16200/27988]  eta: 0:37:34    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16250/27988]  eta: 0:37:24    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16300/27988]  eta: 0:37:15    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16350/27988]  eta: 0:37:05    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16400/27988]  eta: 0:36:56    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16450/27988]  eta: 0:36:46    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16500/27988]  eta: 0:36:36    time: 0.1921  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16550/27988]  eta: 0:36:27    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16600/27988]  eta: 0:36:17    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16650/27988]  eta: 0:36:08    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16700/27988]  eta: 0:35:58    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16750/27988]  eta: 0:35:49    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16800/27988]  eta: 0:35:39    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16850/27988]  eta: 0:35:29    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16900/27988]  eta: 0:35:20    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [16950/27988]  eta: 0:35:10    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17000/27988]  eta: 0:35:01    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17050/27988]  eta: 0:34:51    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17100/27988]  eta: 0:34:42    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17150/27988]  eta: 0:34:32    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17200/27988]  eta: 0:34:22    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17250/27988]  eta: 0:34:13    time: 0.1925  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17300/27988]  eta: 0:34:03    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17350/27988]  eta: 0:33:54    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17400/27988]  eta: 0:33:44    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17450/27988]  eta: 0:33:35    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17500/27988]  eta: 0:33:25    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17550/27988]  eta: 0:33:16    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17600/27988]  eta: 0:33:06    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17650/27988]  eta: 0:32:56    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17700/27988]  eta: 0:32:47    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17750/27988]  eta: 0:32:37    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17800/27988]  eta: 0:32:28    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17850/27988]  eta: 0:32:18    time: 0.1926  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17900/27988]  eta: 0:32:09    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [17950/27988]  eta: 0:31:59    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18000/27988]  eta: 0:31:49    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18050/27988]  eta: 0:31:40    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18100/27988]  eta: 0:31:30    time: 0.1898  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18150/27988]  eta: 0:31:21    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18200/27988]  eta: 0:31:11    time: 0.1896  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18250/27988]  eta: 0:31:02    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18300/27988]  eta: 0:30:52    time: 0.1922  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18350/27988]  eta: 0:30:42    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18400/27988]  eta: 0:30:33    time: 0.1932  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [18450/27988]  eta: 0:30:23    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18500/27988]  eta: 0:30:14    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18550/27988]  eta: 0:30:04    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18600/27988]  eta: 0:29:55    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18650/27988]  eta: 0:29:45    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18700/27988]  eta: 0:29:36    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18750/27988]  eta: 0:29:26    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18800/27988]  eta: 0:29:16    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18850/27988]  eta: 0:29:07    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18900/27988]  eta: 0:28:57    time: 0.1925  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [18950/27988]  eta: 0:28:48    time: 0.1934  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [19000/27988]  eta: 0:28:38    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19050/27988]  eta: 0:28:29    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19100/27988]  eta: 0:28:19    time: 0.1900  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19150/27988]  eta: 0:28:10    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19200/27988]  eta: 0:28:00    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19250/27988]  eta: 0:27:50    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19300/27988]  eta: 0:27:41    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19350/27988]  eta: 0:27:31    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19400/27988]  eta: 0:27:22    time: 0.1900  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19450/27988]  eta: 0:27:12    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19500/27988]  eta: 0:27:03    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19550/27988]  eta: 0:26:53    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19600/27988]  eta: 0:26:43    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19650/27988]  eta: 0:26:34    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19700/27988]  eta: 0:26:24    time: 0.1923  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19750/27988]  eta: 0:26:15    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19800/27988]  eta: 0:26:05    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19850/27988]  eta: 0:25:56    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19900/27988]  eta: 0:25:46    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [19950/27988]  eta: 0:25:36    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20000/27988]  eta: 0:25:27    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20050/27988]  eta: 0:25:17    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20100/27988]  eta: 0:25:08    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20150/27988]  eta: 0:24:58    time: 0.1922  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20200/27988]  eta: 0:24:49    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20250/27988]  eta: 0:24:39    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20300/27988]  eta: 0:24:29    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20350/27988]  eta: 0:24:20    time: 0.1936  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [20400/27988]  eta: 0:24:10    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20450/27988]  eta: 0:24:01    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20500/27988]  eta: 0:23:51    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20550/27988]  eta: 0:23:42    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20600/27988]  eta: 0:23:32    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20650/27988]  eta: 0:23:23    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20700/27988]  eta: 0:23:13    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20750/27988]  eta: 0:23:03    time: 0.1922  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [20800/27988]  eta: 0:22:54    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20850/27988]  eta: 0:22:44    time: 0.1923  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20900/27988]  eta: 0:22:35    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [20950/27988]  eta: 0:22:25    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21000/27988]  eta: 0:22:16    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21050/27988]  eta: 0:22:06    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21100/27988]  eta: 0:21:57    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21150/27988]  eta: 0:21:47    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21200/27988]  eta: 0:21:37    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21250/27988]  eta: 0:21:28    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21300/27988]  eta: 0:21:18    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21350/27988]  eta: 0:21:09    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21400/27988]  eta: 0:20:59    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21450/27988]  eta: 0:20:50    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21500/27988]  eta: 0:20:40    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21550/27988]  eta: 0:20:31    time: 0.1922  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21600/27988]  eta: 0:20:21    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21650/27988]  eta: 0:20:11    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21700/27988]  eta: 0:20:02    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21750/27988]  eta: 0:19:52    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21800/27988]  eta: 0:19:43    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21850/27988]  eta: 0:19:33    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21900/27988]  eta: 0:19:24    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [21950/27988]  eta: 0:19:14    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22000/27988]  eta: 0:19:04    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22050/27988]  eta: 0:18:55    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22100/27988]  eta: 0:18:45    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22150/27988]  eta: 0:18:36    time: 0.1921  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22200/27988]  eta: 0:18:26    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22250/27988]  eta: 0:18:17    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22300/27988]  eta: 0:18:07    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22350/27988]  eta: 0:17:58    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22400/27988]  eta: 0:17:48    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22450/27988]  eta: 0:17:38    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22500/27988]  eta: 0:17:29    time: 0.1898  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22550/27988]  eta: 0:17:19    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22600/27988]  eta: 0:17:10    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22650/27988]  eta: 0:17:00    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22700/27988]  eta: 0:16:51    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22750/27988]  eta: 0:16:41    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22800/27988]  eta: 0:16:31    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22850/27988]  eta: 0:16:22    time: 0.1922  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22900/27988]  eta: 0:16:12    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [22950/27988]  eta: 0:16:03    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23000/27988]  eta: 0:15:53    time: 0.1927  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23050/27988]  eta: 0:15:44    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23100/27988]  eta: 0:15:34    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23150/27988]  eta: 0:15:25    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23200/27988]  eta: 0:15:15    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23250/27988]  eta: 0:15:05    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23300/27988]  eta: 0:14:56    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23350/27988]  eta: 0:14:46    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23400/27988]  eta: 0:14:37    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23450/27988]  eta: 0:14:27    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23500/27988]  eta: 0:14:18    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23550/27988]  eta: 0:14:08    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23600/27988]  eta: 0:13:58    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23650/27988]  eta: 0:13:49    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23700/27988]  eta: 0:13:39    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23750/27988]  eta: 0:13:30    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23800/27988]  eta: 0:13:20    time: 0.1957  data: 0.0004  max mem: 14940\n","Generate VQA test result:  [23850/27988]  eta: 0:13:11    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23900/27988]  eta: 0:13:01    time: 0.1899  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [23950/27988]  eta: 0:12:52    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24000/27988]  eta: 0:12:42    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24050/27988]  eta: 0:12:32    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24100/27988]  eta: 0:12:23    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24150/27988]  eta: 0:12:13    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24200/27988]  eta: 0:12:04    time: 0.1902  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24250/27988]  eta: 0:11:54    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24300/27988]  eta: 0:11:45    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24350/27988]  eta: 0:11:35    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24400/27988]  eta: 0:11:26    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24450/27988]  eta: 0:11:16    time: 0.1904  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24500/27988]  eta: 0:11:06    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24550/27988]  eta: 0:10:57    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24600/27988]  eta: 0:10:47    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24650/27988]  eta: 0:10:38    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24700/27988]  eta: 0:10:28    time: 0.1901  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24750/27988]  eta: 0:10:19    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24800/27988]  eta: 0:10:09    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24850/27988]  eta: 0:09:59    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24900/27988]  eta: 0:09:50    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [24950/27988]  eta: 0:09:40    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25000/27988]  eta: 0:09:31    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25050/27988]  eta: 0:09:21    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25100/27988]  eta: 0:09:12    time: 0.1947  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [25150/27988]  eta: 0:09:02    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25200/27988]  eta: 0:08:53    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25250/27988]  eta: 0:08:43    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25300/27988]  eta: 0:08:33    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25350/27988]  eta: 0:08:24    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25400/27988]  eta: 0:08:14    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25450/27988]  eta: 0:08:05    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25500/27988]  eta: 0:07:55    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25550/27988]  eta: 0:07:46    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25600/27988]  eta: 0:07:36    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25650/27988]  eta: 0:07:27    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25700/27988]  eta: 0:07:17    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25750/27988]  eta: 0:07:07    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25800/27988]  eta: 0:06:58    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25850/27988]  eta: 0:06:48    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25900/27988]  eta: 0:06:39    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [25950/27988]  eta: 0:06:29    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26000/27988]  eta: 0:06:20    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26050/27988]  eta: 0:06:10    time: 0.1913  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [26100/27988]  eta: 0:06:00    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26150/27988]  eta: 0:05:51    time: 0.1920  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26200/27988]  eta: 0:05:41    time: 0.1943  data: 0.0003  max mem: 14940\n","Generate VQA test result:  [26250/27988]  eta: 0:05:32    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26300/27988]  eta: 0:05:22    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26350/27988]  eta: 0:05:13    time: 0.1900  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26400/27988]  eta: 0:05:03    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26450/27988]  eta: 0:04:54    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26500/27988]  eta: 0:04:44    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26550/27988]  eta: 0:04:34    time: 0.1899  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26600/27988]  eta: 0:04:25    time: 0.1909  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26650/27988]  eta: 0:04:15    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26700/27988]  eta: 0:04:06    time: 0.1905  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26750/27988]  eta: 0:03:56    time: 0.1919  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26800/27988]  eta: 0:03:47    time: 0.1913  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26850/27988]  eta: 0:03:37    time: 0.1907  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26900/27988]  eta: 0:03:28    time: 0.1906  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [26950/27988]  eta: 0:03:18    time: 0.1924  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27000/27988]  eta: 0:03:08    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27050/27988]  eta: 0:02:59    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27100/27988]  eta: 0:02:49    time: 0.1918  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27150/27988]  eta: 0:02:40    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27200/27988]  eta: 0:02:30    time: 0.1908  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27250/27988]  eta: 0:02:21    time: 0.1917  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27300/27988]  eta: 0:02:11    time: 0.1903  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27350/27988]  eta: 0:02:01    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27400/27988]  eta: 0:01:52    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27450/27988]  eta: 0:01:42    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27500/27988]  eta: 0:01:33    time: 0.1921  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27550/27988]  eta: 0:01:23    time: 0.1929  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27600/27988]  eta: 0:01:14    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27650/27988]  eta: 0:01:04    time: 0.1912  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27700/27988]  eta: 0:00:55    time: 0.1911  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27750/27988]  eta: 0:00:45    time: 0.1910  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27800/27988]  eta: 0:00:35    time: 0.1925  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27850/27988]  eta: 0:00:26    time: 0.1914  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27900/27988]  eta: 0:00:16    time: 0.1915  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27950/27988]  eta: 0:00:07    time: 0.1916  data: 0.0002  max mem: 14940\n","Generate VQA test result:  [27987/27988]  eta: 0:00:00    time: 0.1840  data: 0.0002  max mem: 14940\n","Generate VQA test result: Total time: 1:29:12 (0.1912 s / it)\n"]},{"output_type":"error","ename":"ValueError","evalue":"Default process group has not been initialized, please make sure to call init_process_group.","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)","\u001b[0;32m<ipython-input-28-87ed0f9cbe2a>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m    127\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    128\u001b[0m \u001b[0mvqa_result\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mevaluation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_loader\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtokenizer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdevice\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mconfig\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 129\u001b[0;31m \u001b[0mresult_file\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msave_result\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mvqa_result\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mresult_dir\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'vqa_result_epoch%d'\u001b[0m\u001b[0;34m%\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    130\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    131\u001b[0m \u001b[0mtotal_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mstart_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/content/dataset/utils.py\u001b[0m in \u001b[0;36msave_result\u001b[0;34m(result, result_dir, filename, is_json, is_list)\u001b[0m\n\u001b[1;32m    117\u001b[0m         \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mresult_file\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 119\u001b[0;31m     \u001b[0mdist\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbarrier\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    120\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    121\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mutils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mis_main_process\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/c10d_logger.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     79\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mwrapper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0m_P\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0m_T\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     80\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 81\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     82\u001b[0m         \u001b[0;32mexcept\u001b[0m \u001b[0mException\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0merror\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     83\u001b[0m             \u001b[0mmsg_dict\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_get_msg_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__name__\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36mbarrier\u001b[0;34m(group, async_op, device_ids)\u001b[0m\n\u001b[1;32m   4539\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4540\u001b[0m     \u001b[0mopts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mBarrierOptions\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 4541\u001b[0;31m     \u001b[0mopts\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdevice\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0m_get_object_coll_device\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   4542\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mdevice_ids\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   4543\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevice_ids\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlist\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_get_object_coll_device\u001b[0;34m(group)\u001b[0m\n\u001b[1;32m    793\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    794\u001b[0m     \"\"\"\n\u001b[0;32m--> 795\u001b[0;31m     \u001b[0mgroup\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgroup\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0m_get_default_group\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    796\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    797\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mgroup\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mProcessGroup\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.11/dist-packages/torch/distributed/distributed_c10d.py\u001b[0m in \u001b[0;36m_get_default_group\u001b[0;34m()\u001b[0m\n\u001b[1;32m   1300\u001b[0m     \u001b[0;34m\"\"\"Get the default process group created by init_process_group.\"\"\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1301\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0mis_initialized\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1302\u001b[0;31m         raise ValueError(\n\u001b[0m\u001b[1;32m   1303\u001b[0m             \u001b[0;34m\"Default process group has not been initialized, \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1304\u001b[0m             \u001b[0;34m\"please make sure to call init_process_group.\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mValueError\u001b[0m: Default process group has not been initialized, please make sure to call init_process_group."]}],"source":["utils.init_distributed_mode(args)\n","\n","device = torch.device(args.device)\n","\n","# fix the seed for reproducibility\n","seed = args.seed + utils.get_rank()\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","cudnn.benchmark = True\n","\n","start_epoch = 0\n","max_epoch = config['schedular']['epochs']\n","warmup_steps = config['schedular']['warmup_epochs']\n","\n","\n","#### Dataset ####\n","print(\"Creating vqa datasets\")\n","datasets = create_dataset('vqa', config)\n","\n","if args.distributed:\n","    num_tasks = utils.get_world_size()\n","    global_rank = utils.get_rank()\n","    samplers = create_sampler(datasets, [True, False], num_tasks, global_rank)\n","else:\n","    samplers = [None, None]\n","\n","train_loader, test_loader = create_loader(datasets,samplers,\n","                                          batch_size=[config['batch_size_train'],config['batch_size_test']],\n","                                          num_workers=[4,4],is_trains=[True, False],\n","                                          collate_fns=[vqa_collate_fn,None])\n","\n","tokenizer = BertTokenizer.from_pretrained(args.text_encoder)\n","\n","#### Model ####\n","print(\"Creating model\")\n","model = ALBEF(config=config, text_encoder=args.text_encoder, text_decoder=args.text_decoder, tokenizer=tokenizer)\n","model = model.to(device)\n","\n","arg_opt = utils.AttrDict(config['optimizer'])\n","optimizer = create_optimizer(arg_opt, model)\n","arg_sche = utils.AttrDict(config['schedular'])\n","lr_scheduler, _ = create_scheduler(arg_sche, optimizer)\n","\n","if args.checkpoint:\n","    checkpoint = torch.load(args.checkpoint, map_location='cpu')\n","    if args.evaluate:\n","        state_dict = checkpoint\n","    else:\n","        state_dict = checkpoint['model']\n","\n","    # reshape positional embedding to accomodate for image resolution change\n","    pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder.pos_embed'],model.visual_encoder)\n","    state_dict['visual_encoder.pos_embed'] = pos_embed_reshaped\n","\n","    if not args.evaluate:\n","        if config['distill']:\n","            m_pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder_m.pos_embed'],model.visual_encoder_m)\n","            state_dict['visual_encoder_m.pos_embed'] = m_pos_embed_reshaped\n","\n","        for key in list(state_dict.keys()):\n","            if 'bert' in key:\n","                encoder_key = key.replace('bert.','')\n","                state_dict[encoder_key] = state_dict[key]\n","            # intialize text decoder as multimodal encoder (last 6 layers of model.text_encoder)\n","            if 'text_encoder' in key:\n","                if 'layer' in key:\n","                    encoder_keys = key.split('.')\n","                    layer_num = int(encoder_keys[4])\n","                    if layer_num<6:\n","                        del state_dict[key]\n","                        continue\n","                    else:\n","                        decoder_layer_num = (layer_num-6)\n","                        encoder_keys[4] = str(decoder_layer_num)\n","                        encoder_key = '.'.join(encoder_keys)\n","                else:\n","                    encoder_key = key\n","                decoder_key = encoder_key.replace('text_encoder','text_decoder')\n","                state_dict[decoder_key] = state_dict[key]\n","\n","                del state_dict[key]\n","\n","    msg = model.load_state_dict(state_dict,strict=False)\n","    print('load checkpoint from %s'%args.checkpoint)\n","    print(msg)\n","\n","\n","model_without_ddp = model\n","if args.distributed:\n","    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n","    model_without_ddp = model.module\n","\n","\n","print(\"Start training\")\n","start_time = time.time()\n","\n","for epoch in range(start_epoch, max_epoch):\n","    if epoch>0:\n","        lr_scheduler.step(epoch+warmup_steps)\n","\n","    if not args.evaluate:\n","        if args.distributed:\n","            train_loader.sampler.set_epoch(epoch)\n","\n","        train_stats = train(model, train_loader, optimizer, tokenizer, epoch, warmup_steps, device, lr_scheduler, config)\n","\n","    if args.evaluate:\n","        break\n","\n","    if utils.is_main_process():\n","        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n","                      'epoch': epoch,\n","                    }\n","        with open(os.path.join(args.output_dir, \"log.txt\"),\"a\") as f:\n","            f.write(json.dumps(log_stats) + \"\\n\")\n","\n","        save_obj = {\n","            'model': model_without_ddp.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'lr_scheduler': lr_scheduler.state_dict(),\n","            'config': config,\n","            'epoch': epoch,\n","        }\n","        torch.save(save_obj, os.path.join(args.output_dir, 'checkpoint_%02d.pth'%epoch))\n","        subprocess.run(['cp', os.path.join(args.output_dir, 'checkpoint_%02d.pth'%epoch), 'drive/MyDrive/ALBEF'])\n","\n","vqa_result = evaluation(model, test_loader, tokenizer, device, config)\n","result_file = save_result(vqa_result, args.result_dir, 'vqa_result_epoch%d'%epoch)\n","\n","total_time = time.time() - start_time\n","total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n","print('Training time {}'.format(total_time_str))"]},{"cell_type":"code","source":["result_file = save_result(vqa_result, args.result_dir, 'vqa_result_epoch%d'%epoch)\n","\n","total_time = time.time() - start_time\n","total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n","print('Training time {}'.format(total_time_str))"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"PxKMKgUHzfcD","executionInfo":{"status":"ok","timestamp":1745062073857,"user_tz":360,"elapsed":3454,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"}},"outputId":"9e412200-6981-416d-a13d-e7f9fba8f356"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stdout","text":["result file saved to ./output/vqa/result/vqa_result_epoch7.json\n","Training time 16:10:15\n"]}]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLJMHFEhQeuG"},"outputs":[],"source":["!cp -r output drive/MyDrive/ALBEF/"]},{"cell_type":"code","source":[],"metadata":{"id":"-fyiAvq-3aHF"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNbXHOwW1WLlmowbkVtRgjX"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}