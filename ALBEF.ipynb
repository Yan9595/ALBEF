{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":13203,"status":"ok","timestamp":1744912483829,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"BOlAMw9uJGeC","outputId":"c4ac9caa-8c98-4535-8585-824dae41f177"},"outputs":[{"name":"stdout","output_type":"stream","text":["Mounted at /content/drive\n"]}],"source":["from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"BbGhbM4-JWWS"},"outputs":[],"source":["%cp -r drive/MyDrive/ALBEF/* ."]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":3,"status":"ok","timestamp":1744913590241,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"Entc5pcg46dn","outputId":"95e64da7-8459-48bb-dd79-5966881d672a"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content/data\n"]}],"source":["%cd /content/data"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"dmHBrOd99IpD"},"outputs":[],"source":["!unzip -q train2014.zip & unzip -q test2015.zip"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":9,"status":"ok","timestamp":1744913822825,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"uABHbZCa9-PJ","outputId":"c44de39d-6951-40b0-e1e4-6972c04facf3"},"outputs":[{"name":"stdout","output_type":"stream","text":["/content\n"]}],"source":["%cd /content"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":722},"executionInfo":{"elapsed":8256,"status":"ok","timestamp":1744914397323,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"AzYHF4kTAIqc","outputId":"d3033638-02f2-418e-aff3-417a9d0834b8"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting transformers==4.25.1\n","  Downloading transformers-4.25.1-py3-none-any.whl.metadata (93 kB)\n","\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/93.9 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m93.9/93.9 kB\u001b[0m \u001b[31m2.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hRequirement already satisfied: filelock in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (3.18.0)\n","Requirement already satisfied: huggingface-hub<1.0,>=0.10.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (0.30.2)\n","Requirement already satisfied: numpy>=1.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.0.2)\n","Requirement already satisfied: packaging>=20.0 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (24.2)\n","Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (6.0.2)\n","Requirement already satisfied: regex!=2019.12.17 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2024.11.6)\n","Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (2.32.3)\n","Collecting tokenizers!=0.11.3,<0.14,>=0.11.1 (from transformers==4.25.1)\n","  Downloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n","Requirement already satisfied: tqdm>=4.27 in /usr/local/lib/python3.11/dist-packages (from transformers==4.25.1) (4.67.1)\n","Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (2025.3.2)\n","Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface-hub<1.0,>=0.10.0->transformers==4.25.1) (4.13.1)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.4.1)\n","Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (3.10)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2.3.0)\n","Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->transformers==4.25.1) (2025.1.31)\n","Downloading transformers-4.25.1-py3-none-any.whl (5.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.8/5.8 MB\u001b[0m \u001b[31m62.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hDownloading tokenizers-0.13.3-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (7.8 MB)\n","\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m7.8/7.8 MB\u001b[0m \u001b[31m127.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: tokenizers, transformers\n","  Attempting uninstall: tokenizers\n","    Found existing installation: tokenizers 0.21.1\n","    Uninstalling tokenizers-0.21.1:\n","      Successfully uninstalled tokenizers-0.21.1\n","  Attempting uninstall: transformers\n","    Found existing installation: transformers 4.51.1\n","    Uninstalling transformers-4.51.1:\n","      Successfully uninstalled transformers-4.51.1\n","\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n","sentence-transformers 3.4.1 requires transformers<5.0.0,>=4.41.0, but you have transformers 4.25.1 which is incompatible.\u001b[0m\u001b[31m\n","\u001b[0mSuccessfully installed tokenizers-0.13.3 transformers-4.25.1\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"43f1aa924e774279b9b86bec0af7fc7f","pip_warning":{"packages":["tokenizers","transformers"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install transformers==4.25.1"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/","height":305},"executionInfo":{"elapsed":2984,"status":"ok","timestamp":1744915104229,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"HsSwP8RyCTX6","outputId":"ca8ae9e9-d2fe-4ee7-dc0a-220c10766093"},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting ruamel.yaml==0.17.*\n","  Downloading ruamel.yaml-0.17.40-py3-none-any.whl.metadata (19 kB)\n","Requirement already satisfied: ruamel.yaml.clib>=0.2.7 in /usr/local/lib/python3.11/dist-packages (from ruamel.yaml==0.17.*) (0.2.12)\n","Downloading ruamel.yaml-0.17.40-py3-none-any.whl (113 kB)\n","\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/113.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m113.7/113.7 kB\u001b[0m \u001b[31m3.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n","\u001b[?25hInstalling collected packages: ruamel.yaml\n","  Attempting uninstall: ruamel.yaml\n","    Found existing installation: ruamel.yaml 0.18.10\n","    Uninstalling ruamel.yaml-0.18.10:\n","      Successfully uninstalled ruamel.yaml-0.18.10\n","Successfully installed ruamel.yaml-0.17.40\n"]},{"data":{"application/vnd.colab-display-data+json":{"id":"5e9db613992448c5ae30daa8b8b3a546","pip_warning":{"packages":["ruamel"]}}},"metadata":{},"output_type":"display_data"}],"source":["!pip install ruamel.yaml==0.17.*"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":7827,"status":"ok","timestamp":1744937079509,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"U4aO73sdK9xE","outputId":"c52974a6-2cb5-4bd9-8c5c-3a14f023ddb7"},"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/timm/models/registry.py:4: FutureWarning: Importing from timm.models.registry is deprecated, please import via timm.models\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.models\", FutureWarning)\n","/usr/local/lib/python3.11/dist-packages/timm/models/layers/__init__.py:48: FutureWarning: Importing from timm.models.layers is deprecated, please import via timm.layers\n","  warnings.warn(f\"Importing from {__name__} is deprecated, please import via timm.layers\", FutureWarning)\n"]}],"source":["import argparse\n","import os\n","import ruamel.yaml as yaml\n","import numpy as np\n","import random\n","import time\n","import datetime\n","import json\n","from pathlib import Path\n","\n","import torch\n","import torch.nn as nn\n","import torch.nn.functional as F\n","from torch.utils.data import DataLoader\n","import torch.backends.cudnn as cudnn\n","import torch.distributed as dist\n","\n","from models.model_vqa import ALBEF\n","from models.vit import interpolate_pos_embed\n","from models.tokenization_bert import BertTokenizer\n","\n","import utils\n","from dataset.utils import save_result\n","from dataset import create_dataset, create_sampler, create_loader, vqa_collate_fn\n","\n","from scheduler import create_scheduler\n","from optim import create_optimizer"]},{"cell_type":"code","execution_count":2,"metadata":{"executionInfo":{"elapsed":60,"status":"ok","timestamp":1744937488615,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"NJqXs_yTBK7C"},"outputs":[],"source":["%load_ext autoreload\n","%autoreload 2"]},{"cell_type":"code","execution_count":9,"metadata":{"executionInfo":{"elapsed":64,"status":"ok","timestamp":1744938147092,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"3A3XLl-ALYDG"},"outputs":[],"source":["def train(model, data_loader, optimizer, tokenizer, epoch, warmup_steps, device, scheduler, config):\n","    # train\n","    model.train()\n","\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    metric_logger.add_meter('lr', utils.SmoothedValue(window_size=1, fmt='{value:.6f}'))\n","    metric_logger.add_meter('loss', utils.SmoothedValue(window_size=1, fmt='{value:.4f}'))\n","\n","    header = 'Train Epoch: [{}]'.format(epoch)\n","    print_freq = 50\n","    step_size = 100\n","    warmup_iterations = warmup_steps*step_size\n","\n","    for i,(image, question, answer, weights, n) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n","        image, weights = image.to(device,non_blocking=True), weights.to(device,non_blocking=True)\n","        question_input = tokenizer(question, padding='longest', truncation=True, max_length=25, return_tensors=\"pt\").to(device)\n","        answer_input = tokenizer(answer, padding='longest', return_tensors=\"pt\").to(device)\n","\n","        if epoch>0 or not config['warm_up']:\n","            alpha = config['alpha']\n","        else:\n","            alpha = config['alpha']*min(1,i/len(data_loader))\n","\n","        loss = model(image, question_input, answer_input, train=True, alpha=alpha, k=n, weights=weights)\n","\n","        optimizer.zero_grad()\n","        loss.backward()\n","        optimizer.step()\n","\n","        metric_logger.update(loss=loss.item())\n","        metric_logger.update(lr=optimizer.param_groups[0][\"lr\"])\n","\n","        if epoch==0 and i%step_size==0 and i<=warmup_iterations:\n","            scheduler.step(i//step_size)\n","\n","    # gather the stats from all processes\n","    metric_logger.synchronize_between_processes()\n","    print(\"Averaged stats:\", metric_logger.global_avg())\n","    return {k: \"{:.3f}\".format(meter.global_avg) for k, meter in metric_logger.meters.items()}"]},{"cell_type":"code","execution_count":10,"metadata":{"executionInfo":{"elapsed":51,"status":"ok","timestamp":1744938173124,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"d5ug9dufNECg"},"outputs":[],"source":["@torch.no_grad()\n","def evaluation(model, data_loader, tokenizer, device, config) :\n","    # test\n","    model.eval()\n","\n","    metric_logger = utils.MetricLogger(delimiter=\"  \")\n","    header = 'Generate VQA test result:'\n","    print_freq = 50\n","\n","    result = []\n","\n","    answer_list = [answer+config['eos'] for answer in data_loader.dataset.answer_list]\n","    answer_input = tokenizer(answer_list, padding='longest', return_tensors='pt').to(device)\n","\n","    for n, (image, question, question_id) in enumerate(metric_logger.log_every(data_loader, print_freq, header)):\n","        image = image.to(device,non_blocking=True)\n","        question_input = tokenizer(question, padding='longest', return_tensors=\"pt\").to(device)\n","\n","        topk_ids, topk_probs = model(image, question_input, answer_input, train=False, k=config['k_test'])\n","\n","        for ques_id, topk_id, topk_prob in zip(question_id, topk_ids, topk_probs):\n","            ques_id = int(ques_id.item())\n","            _, pred = topk_prob.max(dim=0)\n","            result.append({\"question_id\":ques_id, \"answer\":data_loader.dataset.answer_list[topk_id[pred]]})\n","\n","    return result"]},{"cell_type":"code","execution_count":24,"metadata":{"executionInfo":{"elapsed":72,"status":"ok","timestamp":1744938525357,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"WF3LfY8KNrb5"},"outputs":[],"source":["args = argparse.Namespace()\n","args.config = './configs/VQA.yaml'\n","args.checkpoint = './ALBEF_4M.pth'\n","args.output_dir = './output/vqa'\n","args.evaluate = False\n","args.text_encoder = 'bert-base-uncased'\n","args.text_decoder = 'bert-base-uncased'\n","args.device = 'cuda'\n","args.seed = 42\n","args.distributed = False\n","\n","config = yaml.load(open(args.config, 'r'), Loader=yaml.Loader)"]},{"cell_type":"code","execution_count":25,"metadata":{"executionInfo":{"elapsed":67,"status":"ok","timestamp":1744938526348,"user":{"displayName":"Yifei Lin","userId":"07646204989924994124"},"user_tz":360},"id":"X6X0AQ1kQbMA"},"outputs":[],"source":["args.result_dir = os.path.join(args.output_dir, 'result')\n","\n","Path(args.output_dir).mkdir(parents=True, exist_ok=True)\n","Path(args.result_dir).mkdir(parents=True, exist_ok=True)\n","\n","yaml.dump(config, open(os.path.join(args.output_dir, 'config.yaml'), 'w'))"]},{"cell_type":"code","execution_count":null,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"t6hxLvhha5jF","outputId":"bb94acf3-60e9-42fd-f192-890948c305d3"},"outputs":[{"output_type":"stream","name":"stdout","text":["Not using distributed mode\n","Creating vqa datasets\n","Creating model\n","reshape position embedding from 256 to 576\n","reshape position embedding from 256 to 576\n","load checkpoint from ./ALBEF_4M.pth\n","_IncompatibleKeys(missing_keys=[], unexpected_keys=['temp', 'image_queue', 'text_queue', 'queue_ptr', 'vision_proj.weight', 'vision_proj.bias', 'text_proj.weight', 'text_proj.bias', 'itm_head.weight', 'itm_head.bias', 'vision_proj_m.weight', 'vision_proj_m.bias', 'text_proj_m.weight', 'text_proj_m.bias'])\n","Start training\n"]},{"output_type":"stream","name":"stderr","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n","/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [0]  [    0/20565]  eta: 1 day, 0:37:25  lr: 0.000010  loss: 33.0242  time: 4.3105  data: 1.7437  max mem: 21051\n"]},{"output_type":"stream","name":"stderr","text":["/content/dataset/randaugment.py:31: RuntimeWarning: overflow encountered in scalar negative\n","  offset = -low * scale\n"]},{"output_type":"stream","name":"stdout","text":["Train Epoch: [0]  [   50/20565]  eta: 7:11:10  lr: 0.000010  loss: 8.6795  time: 1.2001  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  100/20565]  eta: 6:59:30  lr: 0.000010  loss: 10.0048  time: 1.1946  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  150/20565]  eta: 6:54:29  lr: 0.000013  loss: 4.9152  time: 1.1959  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  200/20565]  eta: 6:51:35  lr: 0.000013  loss: 5.1180  time: 1.1951  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  250/20565]  eta: 6:49:43  lr: 0.000015  loss: 5.6894  time: 1.1994  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  300/20565]  eta: 6:47:58  lr: 0.000015  loss: 4.1441  time: 1.1970  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  350/20565]  eta: 6:46:37  lr: 0.000018  loss: 4.5695  time: 1.2001  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  400/20565]  eta: 6:45:09  lr: 0.000018  loss: 5.1097  time: 1.1953  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  450/20565]  eta: 6:43:52  lr: 0.000020  loss: 4.3007  time: 1.2009  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  500/20565]  eta: 6:42:39  lr: 0.000020  loss: 4.6360  time: 1.1987  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  550/20565]  eta: 6:41:33  lr: 0.000020  loss: 5.6625  time: 1.2030  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  600/20565]  eta: 6:40:25  lr: 0.000020  loss: 5.4400  time: 1.1985  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  650/20565]  eta: 6:39:11  lr: 0.000020  loss: 4.9016  time: 1.1935  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  700/20565]  eta: 6:38:07  lr: 0.000020  loss: 4.9918  time: 1.2007  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  750/20565]  eta: 6:37:01  lr: 0.000020  loss: 5.3039  time: 1.1992  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  800/20565]  eta: 6:35:55  lr: 0.000020  loss: 3.9255  time: 1.1965  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  850/20565]  eta: 6:34:50  lr: 0.000020  loss: 2.7260  time: 1.1967  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  900/20565]  eta: 6:33:48  lr: 0.000020  loss: 4.2060  time: 1.1976  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [  950/20565]  eta: 6:32:45  lr: 0.000020  loss: 3.5213  time: 1.1983  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1000/20565]  eta: 6:31:42  lr: 0.000020  loss: 3.5539  time: 1.1968  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1050/20565]  eta: 6:30:38  lr: 0.000020  loss: 3.8791  time: 1.1965  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1100/20565]  eta: 6:29:34  lr: 0.000020  loss: 4.1960  time: 1.1961  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1150/20565]  eta: 6:28:29  lr: 0.000020  loss: 5.6591  time: 1.1944  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1200/20565]  eta: 6:27:26  lr: 0.000020  loss: 4.5637  time: 1.1976  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1250/20565]  eta: 6:26:25  lr: 0.000020  loss: 2.2433  time: 1.2011  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1300/20565]  eta: 6:25:23  lr: 0.000020  loss: 4.1646  time: 1.1984  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1350/20565]  eta: 6:24:22  lr: 0.000020  loss: 4.1064  time: 1.1948  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1400/20565]  eta: 6:23:20  lr: 0.000020  loss: 2.6051  time: 1.1954  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1450/20565]  eta: 6:22:19  lr: 0.000020  loss: 3.9098  time: 1.1997  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1500/20565]  eta: 6:21:18  lr: 0.000020  loss: 3.3685  time: 1.2011  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1550/20565]  eta: 6:20:16  lr: 0.000020  loss: 4.0644  time: 1.1938  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1600/20565]  eta: 6:19:14  lr: 0.000020  loss: 4.7570  time: 1.1959  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1650/20565]  eta: 6:18:11  lr: 0.000020  loss: 2.5728  time: 1.1951  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1700/20565]  eta: 6:17:10  lr: 0.000020  loss: 2.6383  time: 1.2004  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1750/20565]  eta: 6:16:10  lr: 0.000020  loss: 3.0205  time: 1.1965  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1800/20565]  eta: 6:15:08  lr: 0.000020  loss: 2.2769  time: 1.1949  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1850/20565]  eta: 6:14:07  lr: 0.000020  loss: 3.3912  time: 1.1951  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 1900/20565]  eta: 6:13:07  lr: 0.000020  loss: 2.6100  time: 1.2015  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 1950/20565]  eta: 6:12:08  lr: 0.000020  loss: 4.4484  time: 1.2040  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 2000/20565]  eta: 6:11:07  lr: 0.000020  loss: 3.6872  time: 1.1972  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 2050/20565]  eta: 6:10:06  lr: 0.000020  loss: 1.7244  time: 1.2003  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 2100/20565]  eta: 6:09:06  lr: 0.000020  loss: 3.3165  time: 1.1976  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2150/20565]  eta: 6:08:05  lr: 0.000020  loss: 3.0742  time: 1.1993  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 2200/20565]  eta: 6:07:04  lr: 0.000020  loss: 3.4777  time: 1.1960  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 2250/20565]  eta: 6:06:03  lr: 0.000020  loss: 3.4307  time: 1.1974  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2300/20565]  eta: 6:05:03  lr: 0.000020  loss: 3.0366  time: 1.2000  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2350/20565]  eta: 6:04:03  lr: 0.000020  loss: 3.9710  time: 1.1992  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 2400/20565]  eta: 6:03:02  lr: 0.000020  loss: 2.5697  time: 1.1977  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2450/20565]  eta: 6:02:02  lr: 0.000020  loss: 2.5931  time: 1.1982  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2500/20565]  eta: 6:01:02  lr: 0.000020  loss: 3.1395  time: 1.1987  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2550/20565]  eta: 6:00:01  lr: 0.000020  loss: 3.0926  time: 1.1972  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 2600/20565]  eta: 5:59:01  lr: 0.000020  loss: 3.1487  time: 1.1987  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2650/20565]  eta: 5:58:01  lr: 0.000020  loss: 4.2307  time: 1.1934  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2700/20565]  eta: 5:57:00  lr: 0.000020  loss: 3.1908  time: 1.1964  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 2750/20565]  eta: 5:55:59  lr: 0.000020  loss: 5.2149  time: 1.2003  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2800/20565]  eta: 5:54:58  lr: 0.000020  loss: 3.7150  time: 1.1904  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2850/20565]  eta: 5:53:58  lr: 0.000020  loss: 1.6046  time: 1.1941  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 2900/20565]  eta: 5:52:57  lr: 0.000020  loss: 3.5543  time: 1.1947  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 2950/20565]  eta: 5:51:57  lr: 0.000020  loss: 2.4453  time: 1.1996  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3000/20565]  eta: 5:50:56  lr: 0.000020  loss: 3.3845  time: 1.1915  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3050/20565]  eta: 5:49:55  lr: 0.000020  loss: 3.1652  time: 1.1965  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3100/20565]  eta: 5:48:55  lr: 0.000020  loss: 3.8105  time: 1.1968  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3150/20565]  eta: 5:47:55  lr: 0.000020  loss: 2.7413  time: 1.1988  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 3200/20565]  eta: 5:46:54  lr: 0.000020  loss: 4.3734  time: 1.1951  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3250/20565]  eta: 5:45:54  lr: 0.000020  loss: 2.3446  time: 1.2021  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 3300/20565]  eta: 5:44:54  lr: 0.000020  loss: 2.8505  time: 1.1993  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3350/20565]  eta: 5:43:54  lr: 0.000020  loss: 4.2831  time: 1.1992  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3400/20565]  eta: 5:42:53  lr: 0.000020  loss: 3.0806  time: 1.1981  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3450/20565]  eta: 5:41:54  lr: 0.000020  loss: 4.0237  time: 1.1960  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3500/20565]  eta: 5:40:53  lr: 0.000020  loss: 3.1567  time: 1.1954  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3550/20565]  eta: 5:39:53  lr: 0.000020  loss: 3.0750  time: 1.1990  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3600/20565]  eta: 5:38:53  lr: 0.000020  loss: 3.2234  time: 1.1996  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3650/20565]  eta: 5:37:54  lr: 0.000020  loss: 3.0209  time: 1.1987  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 3700/20565]  eta: 5:36:54  lr: 0.000020  loss: 3.5090  time: 1.2017  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 3750/20565]  eta: 5:35:54  lr: 0.000020  loss: 3.4978  time: 1.1966  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 3800/20565]  eta: 5:34:53  lr: 0.000020  loss: 3.4197  time: 1.1927  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 3850/20565]  eta: 5:33:52  lr: 0.000020  loss: 2.9741  time: 1.1944  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3900/20565]  eta: 5:32:53  lr: 0.000020  loss: 2.5931  time: 1.2014  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 3950/20565]  eta: 5:31:53  lr: 0.000020  loss: 2.4187  time: 1.2000  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 4000/20565]  eta: 5:30:53  lr: 0.000020  loss: 3.2291  time: 1.1991  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 4050/20565]  eta: 5:29:53  lr: 0.000020  loss: 3.5149  time: 1.1967  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 4100/20565]  eta: 5:28:52  lr: 0.000020  loss: 2.0838  time: 1.1958  data: 0.0003  max mem: 25548\n","Train Epoch: [0]  [ 4150/20565]  eta: 5:27:51  lr: 0.000020  loss: 2.6065  time: 1.1968  data: 0.0002  max mem: 25548\n","Train Epoch: [0]  [ 4200/20565]  eta: 5:26:51  lr: 0.000020  loss: 1.9717  time: 1.1960  data: 0.0003  max mem: 25548\n"]}],"source":["utils.init_distributed_mode(args)\n","\n","device = torch.device(args.device)\n","\n","# fix the seed for reproducibility\n","seed = args.seed + utils.get_rank()\n","torch.manual_seed(seed)\n","np.random.seed(seed)\n","random.seed(seed)\n","cudnn.benchmark = True\n","\n","start_epoch = 0\n","max_epoch = config['schedular']['epochs']\n","warmup_steps = config['schedular']['warmup_epochs']\n","\n","\n","#### Dataset ####\n","print(\"Creating vqa datasets\")\n","datasets = create_dataset('vqa', config)\n","\n","if args.distributed:\n","    num_tasks = utils.get_world_size()\n","    global_rank = utils.get_rank()\n","    samplers = create_sampler(datasets, [True, False], num_tasks, global_rank)\n","else:\n","    samplers = [None, None]\n","\n","train_loader, test_loader = create_loader(datasets,samplers,\n","                                          batch_size=[config['batch_size_train'],config['batch_size_test']],\n","                                          num_workers=[4,4],is_trains=[True, False],\n","                                          collate_fns=[vqa_collate_fn,None])\n","\n","tokenizer = BertTokenizer.from_pretrained(args.text_encoder)\n","\n","#### Model ####\n","print(\"Creating model\")\n","model = ALBEF(config=config, text_encoder=args.text_encoder, text_decoder=args.text_decoder, tokenizer=tokenizer)\n","model = model.to(device)\n","\n","arg_opt = utils.AttrDict(config['optimizer'])\n","optimizer = create_optimizer(arg_opt, model)\n","arg_sche = utils.AttrDict(config['schedular'])\n","lr_scheduler, _ = create_scheduler(arg_sche, optimizer)\n","\n","if args.checkpoint:\n","    checkpoint = torch.load(args.checkpoint, map_location='cpu')\n","    if args.evaluate:\n","        state_dict = checkpoint\n","    else:\n","        state_dict = checkpoint['model']\n","\n","    # reshape positional embedding to accomodate for image resolution change\n","    pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder.pos_embed'],model.visual_encoder)\n","    state_dict['visual_encoder.pos_embed'] = pos_embed_reshaped\n","\n","    if not args.evaluate:\n","        if config['distill']:\n","            m_pos_embed_reshaped = interpolate_pos_embed(state_dict['visual_encoder_m.pos_embed'],model.visual_encoder_m)\n","            state_dict['visual_encoder_m.pos_embed'] = m_pos_embed_reshaped\n","\n","        for key in list(state_dict.keys()):\n","            if 'bert' in key:\n","                encoder_key = key.replace('bert.','')\n","                state_dict[encoder_key] = state_dict[key]\n","            # intialize text decoder as multimodal encoder (last 6 layers of model.text_encoder)\n","            if 'text_encoder' in key:\n","                if 'layer' in key:\n","                    encoder_keys = key.split('.')\n","                    layer_num = int(encoder_keys[4])\n","                    if layer_num<6:\n","                        del state_dict[key]\n","                        continue\n","                    else:\n","                        decoder_layer_num = (layer_num-6)\n","                        encoder_keys[4] = str(decoder_layer_num)\n","                        encoder_key = '.'.join(encoder_keys)\n","                else:\n","                    encoder_key = key\n","                decoder_key = encoder_key.replace('text_encoder','text_decoder')\n","                state_dict[decoder_key] = state_dict[key]\n","\n","                del state_dict[key]\n","\n","    msg = model.load_state_dict(state_dict,strict=False)\n","    print('load checkpoint from %s'%args.checkpoint)\n","    print(msg)\n","\n","\n","model_without_ddp = model\n","if args.distributed:\n","    model = torch.nn.parallel.DistributedDataParallel(model, device_ids=[args.gpu])\n","    model_without_ddp = model.module\n","\n","\n","print(\"Start training\")\n","start_time = time.time()\n","\n","for epoch in range(start_epoch, max_epoch):\n","    if epoch>0:\n","        lr_scheduler.step(epoch+warmup_steps)\n","\n","    if not args.evaluate:\n","        if args.distributed:\n","            train_loader.sampler.set_epoch(epoch)\n","\n","        train_stats = train(model, train_loader, optimizer, tokenizer, epoch, warmup_steps, device, lr_scheduler, config)\n","\n","    if args.evaluate:\n","        break\n","\n","    if utils.is_main_process():\n","        log_stats = {**{f'train_{k}': v for k, v in train_stats.items()},\n","                      'epoch': epoch,\n","                    }\n","        with open(os.path.join(args.output_dir, \"log.txt\"),\"a\") as f:\n","            f.write(json.dumps(log_stats) + \"\\n\")\n","\n","        save_obj = {\n","            'model': model_without_ddp.state_dict(),\n","            'optimizer': optimizer.state_dict(),\n","            'lr_scheduler': lr_scheduler.state_dict(),\n","            'config': config,\n","            'epoch': epoch,\n","        }\n","        torch.save(save_obj, os.path.join(args.output_dir, 'checkpoint_%02d.pth'%epoch))\n","\n","    dist.barrier()\n","\n","vqa_result = evaluation(model, test_loader, tokenizer, device, config)\n","result_file = save_result(vqa_result, args.result_dir, 'vqa_result_epoch%d'%epoch)\n","\n","total_time = time.time() - start_time\n","total_time_str = str(datetime.timedelta(seconds=int(total_time)))\n","print('Training time {}'.format(total_time_str))"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"uLJMHFEhQeuG"},"outputs":[],"source":["!cp -r output drive/MyDrive/ALBEF/"]},{"cell_type":"code","source":[],"metadata":{"id":"WHpzQDBDbvTF"},"execution_count":null,"outputs":[]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"A100","machine_shape":"hm","provenance":[],"authorship_tag":"ABX9TyNL37E0rMCp0stuIqwdEJNl"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}